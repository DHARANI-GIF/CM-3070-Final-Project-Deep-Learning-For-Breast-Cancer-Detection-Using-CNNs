{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvvZaf6Qmkmf",
        "outputId": "d20c5849-543d-44bf-c29c-eaabd76fe066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# === Mount Google Drive and Prepare the Dataset ===\n",
        "# Import the 'drive' module from Google Colab to access Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to the Colab environment at the specified path\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataset ZIP file from Google Drive to the local environment\n",
        "!cp \"/content/drive/My Drive/FYP_Project/CBIS_DDSM.zip\" .\n",
        "# Unzip the dataset quietly (suppress output)\n",
        "!unzip -qq CBIS_DDSM.zip\n",
        "# Remove the ZIP file after extraction to save storage space\n",
        "!rm CBIS_DDSM.zip\n",
        "# Set the dataset directory path\n",
        "cbis_path = 'CBIS_DDSM'\n"
      ],
      "metadata": {
        "id": "YIIhP_f57J3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Install Required Libraries ===\n",
        "# Install TensorFlow\n",
        "!pip install tensorflow -qq"
      ],
      "metadata": {
        "id": "aSbo9HkKM9a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta, Adagrad, Adamax, Nadam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import plot_model\n"
      ],
      "metadata": {
        "id": "oHL2-mv5iNzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training():\n",
        "    \"\"\"\n",
        "    Load the training set (excluding baseline patches)\n",
        "    \"\"\"\n",
        "    images = np.load(os.path.join(cbis_path, 'numpy data', 'train_tensor.npy'))[1::2]\n",
        "    labels = np.load(os.path.join(cbis_path, 'numpy data', 'train_labels.npy'))[1::2]\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def load_testing():\n",
        "    \"\"\"\n",
        "    Load the test set (abnormalities patches and labels, no baseline)\n",
        "    \"\"\"\n",
        "    images = np.load(os.path.join(cbis_path, 'numpy data', 'public_test_tensor.npy'))[1::2]\n",
        "    labels = np.load(os.path.join(cbis_path, 'numpy data', 'public_test_labels.npy'))[1::2]\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def remap_label(l):\n",
        "    \"\"\"\n",
        "    Remap the labels to 0->benign 1->malignant\n",
        "    \"\"\"\n",
        "    if l == 1 or l == 3:\n",
        "        return 0\n",
        "    elif l == 2 or l == 4:\n",
        "        return 1\n",
        "    else:\n",
        "        print(\"[WARN] Unrecognized label (%d)\" % l)\n",
        "        return None"
      ],
      "metadata": {
        "id": "YyVwLQGliNyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and test images (abnormalities only, no baseline)\n",
        "train_images, train_labels= load_training()\n",
        "test_images, test_labels= load_testing()\n",
        "\n",
        "# Number of images\n",
        "n_train_img = train_images.shape[0]\n",
        "n_test_img = test_images.shape[0]\n",
        "print(\"Train size: %d \\t Test size: %d\" % (n_train_img, n_test_img))\n",
        "\n",
        "# Compute width and height of images\n",
        "img_w = train_images.shape[1]\n",
        "img_h = train_images.shape[2]\n",
        "print(\"Image size: %dx%d\" % (img_w, img_h))\n",
        "\n",
        "# Remap labels\n",
        "train_labels = np.array([remap_label(l) for l in train_labels])\n",
        "test_labels = np.array([remap_label(l) for l in test_labels])\n",
        "\n",
        "# Create a new dimension for color in the images arrays\n",
        "train_images = train_images.reshape((n_train_img, img_w, img_h, 1))\n",
        "test_images = test_images.reshape((n_test_img, img_w, img_h, 1))\n",
        "\n",
        "# Convert from 16-bit (0-65535) to float (0-1)\n",
        "train_images = train_images.astype('uint16') / 65535\n",
        "test_images = test_images.astype('uint16') / 65535\n",
        "\n",
        "# Shuffle the training set (originally sorted by label)\n",
        "perm = np.random.permutation(n_train_img)\n",
        "train_images = train_images[perm]\n",
        "train_labels = train_labels[perm]\n",
        "\n",
        "# Create a generator for training images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rotation_range=180,\n",
        "    shear_range=10,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='reflect'\n",
        ")\n",
        "\n",
        "# Fit the generator with some images\n",
        "train_datagen.fit(train_images)\n",
        "\n",
        "# Split train images into actual training and validation\n",
        "train_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='training')\n",
        "validation_generator = train_datagen.flow(train_images, train_labels, batch_size=128, subset='validation')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJEuqwH57deV",
        "outputId": "5b88c849-64ea-4c11-f9bc-e9015b31ac0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 2676 \t Test size: 336\n",
            "Image size: 150x150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Visualize a Sample Image ===\n",
        "# Select an image index to visualize\n",
        "idx = 0\n",
        "\n",
        "# Display the image (grayscale, so only one channel)\n",
        "plt.imshow(train_images[idx][:, :, 0], cmap='gray')\n",
        "plt.title(f\"Sample Image at Index {idx}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Print the corresponding label (0 = benign, 1 = malignant)\n",
        "print(\"Label:\", train_labels[idx])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "y8dQr4pxjsxo",
        "outputId": "f27a6246-ca32-421d-8383-80881fbfbd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "model_1 = models.Sequential()\n",
        "\n",
        "# Use the Input layer directly\n",
        "model_1.add(layers.Input(shape=(150, 150, 1)))\n",
        "\n",
        "# First convolutional block\n",
        "model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second convolutional block\n",
        "model_1.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Third convolutional block\n",
        "model_1.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model_1.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Fully connected layers\n",
        "model_1.add(layers.Flatten())\n",
        "model_1.add(layers.Dense(64, activation='relu'))\n",
        "model_1.add(layers.Dropout(0.5))\n",
        "model_1.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Show model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "caUbPDgajsu7",
        "outputId": "9a48be50-6926-4bfb-fbe2-b4d96cc22d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m640\u001b[0m \n",
              "\n",
              " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m73,856\u001b[0m \n",
              "\n",
              " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m295,168\u001b[0m \n",
              "\n",
              " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73984\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m4,735,040\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m65\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \n",
              "\n",
              " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
              "\n",
              " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
              "\n",
              " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73984</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,040</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,104,769\u001b[0m (19.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,104,769</span> (19.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,104,769\u001b[0m (19.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,104,769</span> (19.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping (stop training after the validation loss reaches the minimum)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=80, verbose=1)\n",
        "\n",
        "# Callback for checkpointing\n",
        "checkpoint = ModelCheckpoint('model_1_benmal_best.keras',\n",
        "        monitor='val_loss', mode='min', verbose=1,\n",
        "        save_best_only=True, save_freq='epoch'\n",
        ")\n",
        "# Custom decay function to match RMSprop's decay behavior\n",
        "def lr_decay(epoch, lr):\n",
        "    initial_lr = 0.001  # Your initial learning rate\n",
        "    decay_rate = 1e-3  # Same decay as in RMSprop\n",
        "    return initial_lr * (1 / (1 + decay_rate * epoch))\n",
        "\n",
        "# Use the custom decay in the LearningRateScheduler\n",
        "lr_scheduler = LearningRateScheduler(lr_decay)\n",
        "\n",
        "# Compile the model with the updated optimizer using the learning rate schedule\n",
        "model_1.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the generator\n",
        "history_1 = model_1.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(0.8 * n_train_img) // 128,\n",
        "        epochs=500,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[checkpoint, earlystopping, lr_scheduler],  # Include earlystopping here\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        initial_epoch=0\n",
        ")\n",
        "\n",
        "# Save the final model after training\n",
        "model_1.save('model_1_benmal_end.keras')\n",
        "\n",
        "# Optionally copy the model to Google Drive\n",
        "!cp model* \"/content/drive/My Drive/FYP_Project/models/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjeJhW2HjssS",
        "outputId": "d9c1c346-4b72-4d6a-e61d-e82e6bcfb14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.5520 - loss: 0.7562\n",
            "Epoch 1: val_loss improved from inf to 0.68606, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 739ms/step - accuracy: 0.5532 - loss: 0.7534 - val_accuracy: 0.5720 - val_loss: 0.6861 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6094 - loss: 0.6676"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss did not improve from 0.68606\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6094 - loss: 0.6676 - val_accuracy: 0.5720 - val_loss: 0.6988 - learning_rate: 9.9900e-04\n",
            "Epoch 3/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6014 - loss: 0.6834\n",
            "Epoch 3: val_loss improved from 0.68606 to 0.67842, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.6006 - loss: 0.6833 - val_accuracy: 0.5720 - val_loss: 0.6784 - learning_rate: 9.9800e-04\n",
            "Epoch 4/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6777\n",
            "Epoch 4: val_loss improved from 0.67842 to 0.67658, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6094 - loss: 0.6777 - val_accuracy: 0.5944 - val_loss: 0.6766 - learning_rate: 9.9701e-04\n",
            "Epoch 5/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.5771 - loss: 0.6841\n",
            "Epoch 5: val_loss did not improve from 0.67658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.5771 - loss: 0.6841 - val_accuracy: 0.5720 - val_loss: 0.6796 - learning_rate: 9.9602e-04\n",
            "Epoch 6/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6723\n",
            "Epoch 6: val_loss did not improve from 0.67658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6016 - loss: 0.6723 - val_accuracy: 0.5720 - val_loss: 0.6847 - learning_rate: 9.9502e-04\n",
            "Epoch 7/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5990 - loss: 0.6722\n",
            "Epoch 7: val_loss did not improve from 0.67658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.5984 - loss: 0.6727 - val_accuracy: 0.5720 - val_loss: 0.6772 - learning_rate: 9.9404e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6752\n",
            "Epoch 8: val_loss improved from 0.67658 to 0.67477, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.5859 - loss: 0.6752 - val_accuracy: 0.5720 - val_loss: 0.6748 - learning_rate: 9.9305e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5936 - loss: 0.6800\n",
            "Epoch 9: val_loss improved from 0.67477 to 0.67287, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.5936 - loss: 0.6801 - val_accuracy: 0.5944 - val_loss: 0.6729 - learning_rate: 9.9206e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6694\n",
            "Epoch 10: val_loss improved from 0.67287 to 0.66885, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.6250 - loss: 0.6694 - val_accuracy: 0.5888 - val_loss: 0.6689 - learning_rate: 9.9108e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5888 - loss: 0.6752\n",
            "Epoch 11: val_loss improved from 0.66885 to 0.66823, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.5893 - loss: 0.6750 - val_accuracy: 0.5794 - val_loss: 0.6682 - learning_rate: 9.9010e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.7118\n",
            "Epoch 12: val_loss did not improve from 0.66823\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.7118 - val_accuracy: 0.5009 - val_loss: 0.6915 - learning_rate: 9.8912e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5957 - loss: 0.6688\n",
            "Epoch 13: val_loss improved from 0.66823 to 0.66507, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.5961 - loss: 0.6688 - val_accuracy: 0.5850 - val_loss: 0.6651 - learning_rate: 9.8814e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6502\n",
            "Epoch 14: val_loss did not improve from 0.66507\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6502 - val_accuracy: 0.5720 - val_loss: 0.6881 - learning_rate: 9.8717e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6013 - loss: 0.6694\n",
            "Epoch 15: val_loss improved from 0.66507 to 0.66424, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6011 - loss: 0.6695 - val_accuracy: 0.6112 - val_loss: 0.6642 - learning_rate: 9.8619e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6725\n",
            "Epoch 16: val_loss did not improve from 0.66424\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5859 - loss: 0.6725 - val_accuracy: 0.5981 - val_loss: 0.6644 - learning_rate: 9.8522e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5947 - loss: 0.6718\n",
            "Epoch 17: val_loss did not improve from 0.66424\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.5955 - loss: 0.6716 - val_accuracy: 0.5720 - val_loss: 0.6807 - learning_rate: 9.8425e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6769\n",
            "Epoch 18: val_loss did not improve from 0.66424\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6769 - val_accuracy: 0.5888 - val_loss: 0.6654 - learning_rate: 9.8328e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6128 - loss: 0.6697\n",
            "Epoch 19: val_loss did not improve from 0.66424\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6128 - loss: 0.6696 - val_accuracy: 0.5832 - val_loss: 0.6643 - learning_rate: 9.8232e-04\n",
            "Epoch 20/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5703 - loss: 0.6570\n",
            "Epoch 20: val_loss improved from 0.66424 to 0.65771, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5703 - loss: 0.6570 - val_accuracy: 0.6187 - val_loss: 0.6577 - learning_rate: 9.8135e-04\n",
            "Epoch 21/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6156 - loss: 0.6571\n",
            "Epoch 21: val_loss did not improve from 0.65771\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6147 - loss: 0.6572 - val_accuracy: 0.5720 - val_loss: 0.6669 - learning_rate: 9.8039e-04\n",
            "Epoch 22/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5391 - loss: 0.6865\n",
            "Epoch 22: val_loss did not improve from 0.65771\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5391 - loss: 0.6865 - val_accuracy: 0.6112 - val_loss: 0.6635 - learning_rate: 9.7943e-04\n",
            "Epoch 23/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6201 - loss: 0.6594\n",
            "Epoch 23: val_loss improved from 0.65771 to 0.65637, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.6194 - loss: 0.6594 - val_accuracy: 0.6336 - val_loss: 0.6564 - learning_rate: 9.7847e-04\n",
            "Epoch 24/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6509\n",
            "Epoch 24: val_loss did not improve from 0.65637\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6509 - val_accuracy: 0.5944 - val_loss: 0.6574 - learning_rate: 9.7752e-04\n",
            "Epoch 25/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6099 - loss: 0.6541\n",
            "Epoch 25: val_loss improved from 0.65637 to 0.65547, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6103 - loss: 0.6543 - val_accuracy: 0.6318 - val_loss: 0.6555 - learning_rate: 9.7656e-04\n",
            "Epoch 26/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.6218\n",
            "Epoch 26: val_loss improved from 0.65547 to 0.65449, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7031 - loss: 0.6218 - val_accuracy: 0.6075 - val_loss: 0.6545 - learning_rate: 9.7561e-04\n",
            "Epoch 27/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6113 - loss: 0.6539\n",
            "Epoch 27: val_loss did not improve from 0.65449\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6118 - loss: 0.6539 - val_accuracy: 0.5794 - val_loss: 0.6610 - learning_rate: 9.7466e-04\n",
            "Epoch 28/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6685\n",
            "Epoch 28: val_loss improved from 0.65449 to 0.65139, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5781 - loss: 0.6685 - val_accuracy: 0.6318 - val_loss: 0.6514 - learning_rate: 9.7371e-04\n",
            "Epoch 29/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6229 - loss: 0.6577\n",
            "Epoch 29: val_loss did not improve from 0.65139\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6235 - loss: 0.6574 - val_accuracy: 0.5981 - val_loss: 0.6566 - learning_rate: 9.7276e-04\n",
            "Epoch 30/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6580\n",
            "Epoch 30: val_loss did not improve from 0.65139\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6172 - loss: 0.6580 - val_accuracy: 0.6393 - val_loss: 0.6535 - learning_rate: 9.7182e-04\n",
            "Epoch 31/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6619 - loss: 0.6445\n",
            "Epoch 31: val_loss improved from 0.65139 to 0.65044, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - accuracy: 0.6606 - loss: 0.6448 - val_accuracy: 0.6056 - val_loss: 0.6504 - learning_rate: 9.7087e-04\n",
            "Epoch 32/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6308\n",
            "Epoch 32: val_loss improved from 0.65044 to 0.64833, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6172 - loss: 0.6308 - val_accuracy: 0.6075 - val_loss: 0.6483 - learning_rate: 9.6993e-04\n",
            "Epoch 33/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6298 - loss: 0.6417\n",
            "Epoch 33: val_loss improved from 0.64833 to 0.64514, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6300 - loss: 0.6417 - val_accuracy: 0.6056 - val_loss: 0.6451 - learning_rate: 9.6899e-04\n",
            "Epoch 34/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6159\n",
            "Epoch 34: val_loss did not improve from 0.64514\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6797 - loss: 0.6159 - val_accuracy: 0.6037 - val_loss: 0.6563 - learning_rate: 9.6805e-04\n",
            "Epoch 35/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6445 - loss: 0.6487\n",
            "Epoch 35: val_loss did not improve from 0.64514\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6435 - loss: 0.6490 - val_accuracy: 0.6355 - val_loss: 0.6456 - learning_rate: 9.6712e-04\n",
            "Epoch 36/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5703 - loss: 0.6742\n",
            "Epoch 36: val_loss did not improve from 0.64514\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5703 - loss: 0.6742 - val_accuracy: 0.6187 - val_loss: 0.6491 - learning_rate: 9.6618e-04\n",
            "Epoch 37/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6156 - loss: 0.6437\n",
            "Epoch 37: val_loss did not improve from 0.64514\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6159 - loss: 0.6435 - val_accuracy: 0.6299 - val_loss: 0.6468 - learning_rate: 9.6525e-04\n",
            "Epoch 38/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.6145\n",
            "Epoch 38: val_loss did not improve from 0.64514\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.6145 - val_accuracy: 0.5813 - val_loss: 0.6720 - learning_rate: 9.6432e-04\n",
            "Epoch 39/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6190 - loss: 0.6485\n",
            "Epoch 39: val_loss did not improve from 0.64514\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6193 - loss: 0.6484 - val_accuracy: 0.6224 - val_loss: 0.6455 - learning_rate: 9.6339e-04\n",
            "Epoch 40/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6130\n",
            "Epoch 40: val_loss did not improve from 0.64514\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.6130 - val_accuracy: 0.6393 - val_loss: 0.6469 - learning_rate: 9.6246e-04\n",
            "Epoch 41/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6226 - loss: 0.6516\n",
            "Epoch 41: val_loss improved from 0.64514 to 0.64283, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6233 - loss: 0.6512 - val_accuracy: 0.6131 - val_loss: 0.6428 - learning_rate: 9.6154e-04\n",
            "Epoch 42/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6591\n",
            "Epoch 42: val_loss did not improve from 0.64283\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6591 - val_accuracy: 0.5832 - val_loss: 0.6550 - learning_rate: 9.6061e-04\n",
            "Epoch 43/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6321 - loss: 0.6421\n",
            "Epoch 43: val_loss did not improve from 0.64283\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6312 - loss: 0.6426 - val_accuracy: 0.6243 - val_loss: 0.6514 - learning_rate: 9.5969e-04\n",
            "Epoch 44/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6953 - loss: 0.6279\n",
            "Epoch 44: val_loss did not improve from 0.64283\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.6279 - val_accuracy: 0.6093 - val_loss: 0.6468 - learning_rate: 9.5877e-04\n",
            "Epoch 45/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6448 - loss: 0.6326\n",
            "Epoch 45: val_loss did not improve from 0.64283\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6444 - loss: 0.6328 - val_accuracy: 0.5813 - val_loss: 0.7132 - learning_rate: 9.5785e-04\n",
            "Epoch 46/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5469 - loss: 0.7464\n",
            "Epoch 46: val_loss did not improve from 0.64283\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5469 - loss: 0.7464 - val_accuracy: 0.5645 - val_loss: 0.6879 - learning_rate: 9.5694e-04\n",
            "Epoch 47/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6192 - loss: 0.6548\n",
            "Epoch 47: val_loss improved from 0.64283 to 0.63847, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.6201 - loss: 0.6544 - val_accuracy: 0.6299 - val_loss: 0.6385 - learning_rate: 9.5602e-04\n",
            "Epoch 48/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6084\n",
            "Epoch 48: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6084 - val_accuracy: 0.6187 - val_loss: 0.6438 - learning_rate: 9.5511e-04\n",
            "Epoch 49/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6256 - loss: 0.6503\n",
            "Epoch 49: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6262 - loss: 0.6499 - val_accuracy: 0.6299 - val_loss: 0.6472 - learning_rate: 9.5420e-04\n",
            "Epoch 50/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.6032\n",
            "Epoch 50: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.6032 - val_accuracy: 0.6187 - val_loss: 0.6564 - learning_rate: 9.5329e-04\n",
            "Epoch 51/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6411 - loss: 0.6397\n",
            "Epoch 51: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6408 - loss: 0.6397 - val_accuracy: 0.6449 - val_loss: 0.6396 - learning_rate: 9.5238e-04\n",
            "Epoch 52/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6307\n",
            "Epoch 52: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6307 - val_accuracy: 0.6262 - val_loss: 0.6414 - learning_rate: 9.5147e-04\n",
            "Epoch 53/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6314 - loss: 0.6492\n",
            "Epoch 53: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6318 - loss: 0.6490 - val_accuracy: 0.5888 - val_loss: 0.6590 - learning_rate: 9.5057e-04\n",
            "Epoch 54/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6443\n",
            "Epoch 54: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.6443 - val_accuracy: 0.6280 - val_loss: 0.6412 - learning_rate: 9.4967e-04\n",
            "Epoch 55/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6417 - loss: 0.6304\n",
            "Epoch 55: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6411 - loss: 0.6308 - val_accuracy: 0.6206 - val_loss: 0.6389 - learning_rate: 9.4877e-04\n",
            "Epoch 56/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5625 - loss: 0.6743\n",
            "Epoch 56: val_loss did not improve from 0.63847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5625 - loss: 0.6743 - val_accuracy: 0.6374 - val_loss: 0.6436 - learning_rate: 9.4787e-04\n",
            "Epoch 57/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6628 - loss: 0.6379\n",
            "Epoch 57: val_loss improved from 0.63847 to 0.63542, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.6624 - loss: 0.6377 - val_accuracy: 0.6374 - val_loss: 0.6354 - learning_rate: 9.4697e-04\n",
            "Epoch 58/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6455\n",
            "Epoch 58: val_loss did not improve from 0.63542\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6455 - val_accuracy: 0.6299 - val_loss: 0.6410 - learning_rate: 9.4607e-04\n",
            "Epoch 59/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6451 - loss: 0.6372\n",
            "Epoch 59: val_loss did not improve from 0.63542\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6447 - loss: 0.6372 - val_accuracy: 0.6411 - val_loss: 0.6400 - learning_rate: 9.4518e-04\n",
            "Epoch 60/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6797 - loss: 0.6459\n",
            "Epoch 60: val_loss did not improve from 0.63542\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.6459 - val_accuracy: 0.5925 - val_loss: 0.6487 - learning_rate: 9.4429e-04\n",
            "Epoch 61/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6489 - loss: 0.6332\n",
            "Epoch 61: val_loss did not improve from 0.63542\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6485 - loss: 0.6336 - val_accuracy: 0.6243 - val_loss: 0.6376 - learning_rate: 9.4340e-04\n",
            "Epoch 62/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6034\n",
            "Epoch 62: val_loss did not improve from 0.63542\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6034 - val_accuracy: 0.6187 - val_loss: 0.6382 - learning_rate: 9.4251e-04\n",
            "Epoch 63/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6398 - loss: 0.6347\n",
            "Epoch 63: val_loss did not improve from 0.63542\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6393 - loss: 0.6348 - val_accuracy: 0.6262 - val_loss: 0.6388 - learning_rate: 9.4162e-04\n",
            "Epoch 64/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6603\n",
            "Epoch 64: val_loss did not improve from 0.63542\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6603 - val_accuracy: 0.6280 - val_loss: 0.6384 - learning_rate: 9.4073e-04\n",
            "Epoch 65/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6404 - loss: 0.6364\n",
            "Epoch 65: val_loss improved from 0.63542 to 0.63132, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.6404 - loss: 0.6366 - val_accuracy: 0.6393 - val_loss: 0.6313 - learning_rate: 9.3985e-04\n",
            "Epoch 66/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6311\n",
            "Epoch 66: val_loss did not improve from 0.63132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6311 - val_accuracy: 0.6355 - val_loss: 0.6358 - learning_rate: 9.3897e-04\n",
            "Epoch 67/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6288 - loss: 0.6327\n",
            "Epoch 67: val_loss did not improve from 0.63132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6293 - loss: 0.6328 - val_accuracy: 0.6299 - val_loss: 0.6351 - learning_rate: 9.3809e-04\n",
            "Epoch 68/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6064\n",
            "Epoch 68: val_loss did not improve from 0.63132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6064 - val_accuracy: 0.6336 - val_loss: 0.6318 - learning_rate: 9.3721e-04\n",
            "Epoch 69/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6491 - loss: 0.6305\n",
            "Epoch 69: val_loss did not improve from 0.63132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6486 - loss: 0.6307 - val_accuracy: 0.6037 - val_loss: 0.6597 - learning_rate: 9.3633e-04\n",
            "Epoch 70/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5469 - loss: 0.6834\n",
            "Epoch 70: val_loss did not improve from 0.63132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5469 - loss: 0.6834 - val_accuracy: 0.6393 - val_loss: 0.6358 - learning_rate: 9.3545e-04\n",
            "Epoch 71/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6534 - loss: 0.6304\n",
            "Epoch 71: val_loss did not improve from 0.63132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6533 - loss: 0.6304 - val_accuracy: 0.6355 - val_loss: 0.6315 - learning_rate: 9.3458e-04\n",
            "Epoch 72/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6194\n",
            "Epoch 72: val_loss did not improve from 0.63132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6194 - val_accuracy: 0.6262 - val_loss: 0.6331 - learning_rate: 9.3371e-04\n",
            "Epoch 73/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6452 - loss: 0.6371\n",
            "Epoch 73: val_loss improved from 0.63132 to 0.63123, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.6451 - loss: 0.6369 - val_accuracy: 0.6486 - val_loss: 0.6312 - learning_rate: 9.3284e-04\n",
            "Epoch 74/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6410\n",
            "Epoch 74: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6406 - loss: 0.6410 - val_accuracy: 0.6075 - val_loss: 0.6471 - learning_rate: 9.3197e-04\n",
            "Epoch 75/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6498 - loss: 0.6279\n",
            "Epoch 75: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6497 - loss: 0.6281 - val_accuracy: 0.6449 - val_loss: 0.6355 - learning_rate: 9.3110e-04\n",
            "Epoch 76/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6328 - loss: 0.6383\n",
            "Epoch 76: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6383 - val_accuracy: 0.5963 - val_loss: 0.6497 - learning_rate: 9.3023e-04\n",
            "Epoch 77/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6352 - loss: 0.6382\n",
            "Epoch 77: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6358 - loss: 0.6378 - val_accuracy: 0.6336 - val_loss: 0.6351 - learning_rate: 9.2937e-04\n",
            "Epoch 78/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5781 - loss: 0.6479\n",
            "Epoch 78: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5781 - loss: 0.6479 - val_accuracy: 0.6355 - val_loss: 0.6327 - learning_rate: 9.2851e-04\n",
            "Epoch 79/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6383 - loss: 0.6295\n",
            "Epoch 79: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6379 - loss: 0.6294 - val_accuracy: 0.6411 - val_loss: 0.6345 - learning_rate: 9.2764e-04\n",
            "Epoch 80/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6606\n",
            "Epoch 80: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6606 - val_accuracy: 0.6393 - val_loss: 0.6316 - learning_rate: 9.2678e-04\n",
            "Epoch 81/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6274 - loss: 0.6359\n",
            "Epoch 81: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6282 - loss: 0.6359 - val_accuracy: 0.6056 - val_loss: 0.6402 - learning_rate: 9.2593e-04\n",
            "Epoch 82/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.6098\n",
            "Epoch 82: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6098 - val_accuracy: 0.6262 - val_loss: 0.6402 - learning_rate: 9.2507e-04\n",
            "Epoch 83/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6491 - loss: 0.6225\n",
            "Epoch 83: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6490 - loss: 0.6226 - val_accuracy: 0.6000 - val_loss: 0.6646 - learning_rate: 9.2421e-04\n",
            "Epoch 84/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6927\n",
            "Epoch 84: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5781 - loss: 0.6927 - val_accuracy: 0.6299 - val_loss: 0.6318 - learning_rate: 9.2336e-04\n",
            "Epoch 85/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6301 - loss: 0.6340\n",
            "Epoch 85: val_loss did not improve from 0.63123\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6307 - loss: 0.6338 - val_accuracy: 0.6299 - val_loss: 0.6367 - learning_rate: 9.2251e-04\n",
            "Epoch 86/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6491\n",
            "Epoch 86: val_loss improved from 0.63123 to 0.62850, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6641 - loss: 0.6491 - val_accuracy: 0.6336 - val_loss: 0.6285 - learning_rate: 9.2166e-04\n",
            "Epoch 87/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6516 - loss: 0.6262\n",
            "Epoch 87: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6507 - loss: 0.6270 - val_accuracy: 0.6355 - val_loss: 0.6348 - learning_rate: 9.2081e-04\n",
            "Epoch 88/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5825\n",
            "Epoch 88: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5825 - val_accuracy: 0.6393 - val_loss: 0.6311 - learning_rate: 9.1996e-04\n",
            "Epoch 89/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6491 - loss: 0.6239\n",
            "Epoch 89: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6494 - loss: 0.6241 - val_accuracy: 0.6187 - val_loss: 0.6369 - learning_rate: 9.1912e-04\n",
            "Epoch 90/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6105\n",
            "Epoch 90: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6105 - val_accuracy: 0.6243 - val_loss: 0.6319 - learning_rate: 9.1827e-04\n",
            "Epoch 91/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6623 - loss: 0.6020\n",
            "Epoch 91: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6615 - loss: 0.6029 - val_accuracy: 0.6336 - val_loss: 0.6433 - learning_rate: 9.1743e-04\n",
            "Epoch 92/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6797 - loss: 0.6463\n",
            "Epoch 92: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.6463 - val_accuracy: 0.6374 - val_loss: 0.6314 - learning_rate: 9.1659e-04\n",
            "Epoch 93/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6502 - loss: 0.6174\n",
            "Epoch 93: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6494 - loss: 0.6179 - val_accuracy: 0.6299 - val_loss: 0.6305 - learning_rate: 9.1575e-04\n",
            "Epoch 94/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6302\n",
            "Epoch 94: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6302 - val_accuracy: 0.6355 - val_loss: 0.6285 - learning_rate: 9.1491e-04\n",
            "Epoch 95/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6495 - loss: 0.6397\n",
            "Epoch 95: val_loss did not improve from 0.62850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6493 - loss: 0.6391 - val_accuracy: 0.6168 - val_loss: 0.6322 - learning_rate: 9.1408e-04\n",
            "Epoch 96/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6084\n",
            "Epoch 96: val_loss improved from 0.62850 to 0.62530, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6797 - loss: 0.6084 - val_accuracy: 0.6355 - val_loss: 0.6253 - learning_rate: 9.1324e-04\n",
            "Epoch 97/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6485 - loss: 0.6375\n",
            "Epoch 97: val_loss did not improve from 0.62530\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6485 - loss: 0.6372 - val_accuracy: 0.6243 - val_loss: 0.6330 - learning_rate: 9.1241e-04\n",
            "Epoch 98/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5923\n",
            "Epoch 98: val_loss did not improve from 0.62530\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5923 - val_accuracy: 0.6280 - val_loss: 0.6378 - learning_rate: 9.1158e-04\n",
            "Epoch 99/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6533 - loss: 0.6186\n",
            "Epoch 99: val_loss did not improve from 0.62530\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6527 - loss: 0.6189 - val_accuracy: 0.6224 - val_loss: 0.6317 - learning_rate: 9.1075e-04\n",
            "Epoch 100/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.5993\n",
            "Epoch 100: val_loss did not improve from 0.62530\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.5993 - val_accuracy: 0.6467 - val_loss: 0.6257 - learning_rate: 9.0992e-04\n",
            "Epoch 101/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6714 - loss: 0.6197\n",
            "Epoch 101: val_loss did not improve from 0.62530\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6701 - loss: 0.6201 - val_accuracy: 0.6430 - val_loss: 0.6269 - learning_rate: 9.0909e-04\n",
            "Epoch 102/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6432\n",
            "Epoch 102: val_loss did not improve from 0.62530\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6432 - val_accuracy: 0.6206 - val_loss: 0.6354 - learning_rate: 9.0827e-04\n",
            "Epoch 103/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6525 - loss: 0.6268\n",
            "Epoch 103: val_loss did not improve from 0.62530\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6519 - loss: 0.6271 - val_accuracy: 0.6336 - val_loss: 0.6335 - learning_rate: 9.0744e-04\n",
            "Epoch 104/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6079\n",
            "Epoch 104: val_loss improved from 0.62530 to 0.62508, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6719 - loss: 0.6079 - val_accuracy: 0.6467 - val_loss: 0.6251 - learning_rate: 9.0662e-04\n",
            "Epoch 105/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6548 - loss: 0.6178\n",
            "Epoch 105: val_loss improved from 0.62508 to 0.62309, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.6541 - loss: 0.6180 - val_accuracy: 0.6486 - val_loss: 0.6231 - learning_rate: 9.0580e-04\n",
            "Epoch 106/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6111\n",
            "Epoch 106: val_loss improved from 0.62309 to 0.61797, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.6641 - loss: 0.6111 - val_accuracy: 0.6374 - val_loss: 0.6180 - learning_rate: 9.0498e-04\n",
            "Epoch 107/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6366 - loss: 0.6251\n",
            "Epoch 107: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6368 - loss: 0.6252 - val_accuracy: 0.6280 - val_loss: 0.6310 - learning_rate: 9.0416e-04\n",
            "Epoch 108/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6100\n",
            "Epoch 108: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6100 - val_accuracy: 0.6280 - val_loss: 0.6277 - learning_rate: 9.0334e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6322 - loss: 0.6425\n",
            "Epoch 109: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6328 - loss: 0.6417 - val_accuracy: 0.6187 - val_loss: 0.6376 - learning_rate: 9.0253e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6256\n",
            "Epoch 110: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6328 - loss: 0.6256 - val_accuracy: 0.6505 - val_loss: 0.6312 - learning_rate: 9.0171e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6462 - loss: 0.6294\n",
            "Epoch 111: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6462 - loss: 0.6290 - val_accuracy: 0.6449 - val_loss: 0.6258 - learning_rate: 9.0090e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6420\n",
            "Epoch 112: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6562 - loss: 0.6420 - val_accuracy: 0.6374 - val_loss: 0.6256 - learning_rate: 9.0009e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6678 - loss: 0.6177\n",
            "Epoch 113: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6668 - loss: 0.6180 - val_accuracy: 0.6430 - val_loss: 0.6256 - learning_rate: 8.9928e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6500\n",
            "Epoch 114: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6500 - val_accuracy: 0.6280 - val_loss: 0.6272 - learning_rate: 8.9847e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6361 - loss: 0.6235\n",
            "Epoch 115: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6365 - loss: 0.6235 - val_accuracy: 0.6336 - val_loss: 0.6192 - learning_rate: 8.9767e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6404\n",
            "Epoch 116: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5938 - loss: 0.6404 - val_accuracy: 0.6374 - val_loss: 0.6236 - learning_rate: 8.9686e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6298 - loss: 0.6280\n",
            "Epoch 117: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6306 - loss: 0.6277 - val_accuracy: 0.6393 - val_loss: 0.6253 - learning_rate: 8.9606e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6346\n",
            "Epoch 118: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6346 - val_accuracy: 0.6299 - val_loss: 0.6288 - learning_rate: 8.9526e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6567 - loss: 0.6277\n",
            "Epoch 119: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6565 - loss: 0.6278 - val_accuracy: 0.6262 - val_loss: 0.6341 - learning_rate: 8.9445e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6102\n",
            "Epoch 120: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6102 - val_accuracy: 0.6168 - val_loss: 0.6327 - learning_rate: 8.9366e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6497 - loss: 0.6270\n",
            "Epoch 121: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6494 - loss: 0.6270 - val_accuracy: 0.6393 - val_loss: 0.6250 - learning_rate: 8.9286e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5814\n",
            "Epoch 122: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5814 - val_accuracy: 0.6168 - val_loss: 0.6218 - learning_rate: 8.9206e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6462 - loss: 0.6241\n",
            "Epoch 123: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6462 - loss: 0.6240 - val_accuracy: 0.6318 - val_loss: 0.6206 - learning_rate: 8.9127e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6389\n",
            "Epoch 124: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6484 - loss: 0.6389 - val_accuracy: 0.5907 - val_loss: 0.6449 - learning_rate: 8.9047e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6322 - loss: 0.6267\n",
            "Epoch 125: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6326 - loss: 0.6264 - val_accuracy: 0.6355 - val_loss: 0.6241 - learning_rate: 8.8968e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6135\n",
            "Epoch 126: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6135 - val_accuracy: 0.6486 - val_loss: 0.6243 - learning_rate: 8.8889e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6440 - loss: 0.6258\n",
            "Epoch 127: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6447 - loss: 0.6257 - val_accuracy: 0.6187 - val_loss: 0.6402 - learning_rate: 8.8810e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6016 - loss: 0.6462\n",
            "Epoch 128: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6016 - loss: 0.6462 - val_accuracy: 0.6523 - val_loss: 0.6208 - learning_rate: 8.8731e-04\n",
            "Epoch 129/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6272 - loss: 0.6273\n",
            "Epoch 129: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6281 - loss: 0.6270 - val_accuracy: 0.6187 - val_loss: 0.6317 - learning_rate: 8.8652e-04\n",
            "Epoch 130/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6379\n",
            "Epoch 130: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.6379 - val_accuracy: 0.6374 - val_loss: 0.6211 - learning_rate: 8.8574e-04\n",
            "Epoch 131/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6350 - loss: 0.6238\n",
            "Epoch 131: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6357 - loss: 0.6233 - val_accuracy: 0.6523 - val_loss: 0.6257 - learning_rate: 8.8496e-04\n",
            "Epoch 132/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5918\n",
            "Epoch 132: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5918 - val_accuracy: 0.6411 - val_loss: 0.6270 - learning_rate: 8.8417e-04\n",
            "Epoch 133/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6557 - loss: 0.6197\n",
            "Epoch 133: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6551 - loss: 0.6200 - val_accuracy: 0.6542 - val_loss: 0.6270 - learning_rate: 8.8339e-04\n",
            "Epoch 134/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6335\n",
            "Epoch 134: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5938 - loss: 0.6335 - val_accuracy: 0.6467 - val_loss: 0.6258 - learning_rate: 8.8261e-04\n",
            "Epoch 135/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6488 - loss: 0.6201\n",
            "Epoch 135: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6487 - loss: 0.6205 - val_accuracy: 0.6280 - val_loss: 0.6264 - learning_rate: 8.8183e-04\n",
            "Epoch 136/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5801\n",
            "Epoch 136: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5801 - val_accuracy: 0.6449 - val_loss: 0.6229 - learning_rate: 8.8106e-04\n",
            "Epoch 137/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6624 - loss: 0.6079\n",
            "Epoch 137: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6616 - loss: 0.6088 - val_accuracy: 0.6542 - val_loss: 0.6228 - learning_rate: 8.8028e-04\n",
            "Epoch 138/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6019\n",
            "Epoch 138: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6019 - val_accuracy: 0.6374 - val_loss: 0.6225 - learning_rate: 8.7951e-04\n",
            "Epoch 139/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6373 - loss: 0.6208\n",
            "Epoch 139: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6380 - loss: 0.6208 - val_accuracy: 0.6075 - val_loss: 0.6373 - learning_rate: 8.7873e-04\n",
            "Epoch 140/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5677\n",
            "Epoch 140: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5677 - val_accuracy: 0.6393 - val_loss: 0.6398 - learning_rate: 8.7796e-04\n",
            "Epoch 141/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6423 - loss: 0.6278\n",
            "Epoch 141: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6426 - loss: 0.6271 - val_accuracy: 0.6486 - val_loss: 0.6225 - learning_rate: 8.7719e-04\n",
            "Epoch 142/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5950\n",
            "Epoch 142: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5950 - val_accuracy: 0.6187 - val_loss: 0.6266 - learning_rate: 8.7642e-04\n",
            "Epoch 143/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6225 - loss: 0.6362\n",
            "Epoch 143: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6235 - loss: 0.6353 - val_accuracy: 0.6355 - val_loss: 0.6331 - learning_rate: 8.7566e-04\n",
            "Epoch 144/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5975\n",
            "Epoch 144: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5975 - val_accuracy: 0.6467 - val_loss: 0.6242 - learning_rate: 8.7489e-04\n",
            "Epoch 145/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6712 - loss: 0.6150\n",
            "Epoch 145: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6698 - loss: 0.6155 - val_accuracy: 0.6299 - val_loss: 0.6267 - learning_rate: 8.7413e-04\n",
            "Epoch 146/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6128\n",
            "Epoch 146: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6128 - val_accuracy: 0.6131 - val_loss: 0.6271 - learning_rate: 8.7336e-04\n",
            "Epoch 147/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6462 - loss: 0.6200\n",
            "Epoch 147: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6469 - loss: 0.6197 - val_accuracy: 0.6430 - val_loss: 0.6219 - learning_rate: 8.7260e-04\n",
            "Epoch 148/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6174\n",
            "Epoch 148: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6174 - val_accuracy: 0.6598 - val_loss: 0.6224 - learning_rate: 8.7184e-04\n",
            "Epoch 149/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6573 - loss: 0.6250\n",
            "Epoch 149: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6568 - loss: 0.6248 - val_accuracy: 0.6262 - val_loss: 0.6201 - learning_rate: 8.7108e-04\n",
            "Epoch 150/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5969\n",
            "Epoch 150: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5969 - val_accuracy: 0.6280 - val_loss: 0.6223 - learning_rate: 8.7032e-04\n",
            "Epoch 151/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6380 - loss: 0.6136\n",
            "Epoch 151: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6383 - loss: 0.6136 - val_accuracy: 0.6411 - val_loss: 0.6249 - learning_rate: 8.6957e-04\n",
            "Epoch 152/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6247\n",
            "Epoch 152: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6247 - val_accuracy: 0.6299 - val_loss: 0.6257 - learning_rate: 8.6881e-04\n",
            "Epoch 153/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6534 - loss: 0.6113\n",
            "Epoch 153: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6530 - loss: 0.6116 - val_accuracy: 0.6224 - val_loss: 0.6237 - learning_rate: 8.6806e-04\n",
            "Epoch 154/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6310\n",
            "Epoch 154: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6310 - val_accuracy: 0.6374 - val_loss: 0.6180 - learning_rate: 8.6730e-04\n",
            "Epoch 155/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6346 - loss: 0.6117\n",
            "Epoch 155: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6348 - loss: 0.6117 - val_accuracy: 0.6262 - val_loss: 0.6214 - learning_rate: 8.6655e-04\n",
            "Epoch 156/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6273\n",
            "Epoch 156: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6273 - val_accuracy: 0.6243 - val_loss: 0.6260 - learning_rate: 8.6580e-04\n",
            "Epoch 157/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6425 - loss: 0.6228\n",
            "Epoch 157: val_loss did not improve from 0.61797\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6430 - loss: 0.6225 - val_accuracy: 0.6112 - val_loss: 0.6236 - learning_rate: 8.6505e-04\n",
            "Epoch 158/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.6013\n",
            "Epoch 158: val_loss improved from 0.61797 to 0.61699, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6953 - loss: 0.6013 - val_accuracy: 0.6467 - val_loss: 0.6170 - learning_rate: 8.6430e-04\n",
            "Epoch 159/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6573 - loss: 0.6184\n",
            "Epoch 159: val_loss improved from 0.61699 to 0.61628, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6569 - loss: 0.6182 - val_accuracy: 0.6411 - val_loss: 0.6163 - learning_rate: 8.6356e-04\n",
            "Epoch 160/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5861\n",
            "Epoch 160: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5861 - val_accuracy: 0.6299 - val_loss: 0.6212 - learning_rate: 8.6281e-04\n",
            "Epoch 161/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6514 - loss: 0.6161\n",
            "Epoch 161: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6514 - loss: 0.6158 - val_accuracy: 0.6449 - val_loss: 0.6220 - learning_rate: 8.6207e-04\n",
            "Epoch 162/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6248\n",
            "Epoch 162: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6248 - val_accuracy: 0.6318 - val_loss: 0.6238 - learning_rate: 8.6133e-04\n",
            "Epoch 163/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6674 - loss: 0.6113\n",
            "Epoch 163: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6666 - loss: 0.6115 - val_accuracy: 0.6150 - val_loss: 0.6279 - learning_rate: 8.6059e-04\n",
            "Epoch 164/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6602\n",
            "Epoch 164: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6602 - val_accuracy: 0.6019 - val_loss: 0.6297 - learning_rate: 8.5985e-04\n",
            "Epoch 165/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6420 - loss: 0.6171\n",
            "Epoch 165: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6426 - loss: 0.6169 - val_accuracy: 0.6411 - val_loss: 0.6181 - learning_rate: 8.5911e-04\n",
            "Epoch 166/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6030\n",
            "Epoch 166: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.6030 - val_accuracy: 0.6224 - val_loss: 0.6186 - learning_rate: 8.5837e-04\n",
            "Epoch 167/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6492 - loss: 0.6193\n",
            "Epoch 167: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6497 - loss: 0.6187 - val_accuracy: 0.6505 - val_loss: 0.6184 - learning_rate: 8.5763e-04\n",
            "Epoch 168/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6203\n",
            "Epoch 168: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6203 - val_accuracy: 0.6505 - val_loss: 0.6171 - learning_rate: 8.5690e-04\n",
            "Epoch 169/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6555 - loss: 0.6080\n",
            "Epoch 169: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6552 - loss: 0.6082 - val_accuracy: 0.6318 - val_loss: 0.6194 - learning_rate: 8.5616e-04\n",
            "Epoch 170/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6162\n",
            "Epoch 170: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6162 - val_accuracy: 0.6187 - val_loss: 0.6237 - learning_rate: 8.5543e-04\n",
            "Epoch 171/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6667 - loss: 0.6049\n",
            "Epoch 171: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6659 - loss: 0.6054 - val_accuracy: 0.6336 - val_loss: 0.6171 - learning_rate: 8.5470e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6016 - loss: 0.6333\n",
            "Epoch 172: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6333 - val_accuracy: 0.6374 - val_loss: 0.6214 - learning_rate: 8.5397e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6591 - loss: 0.6066\n",
            "Epoch 173: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6590 - loss: 0.6068 - val_accuracy: 0.6336 - val_loss: 0.6191 - learning_rate: 8.5324e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7419 - loss: 0.5577\n",
            "Epoch 174: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7419 - loss: 0.5577 - val_accuracy: 0.6168 - val_loss: 0.6463 - learning_rate: 8.5251e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6605 - loss: 0.5968\n",
            "Epoch 175: val_loss did not improve from 0.61628\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6603 - loss: 0.5971 - val_accuracy: 0.6262 - val_loss: 0.6190 - learning_rate: 8.5179e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6328 - loss: 0.6511\n",
            "Epoch 176: val_loss improved from 0.61628 to 0.61577, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6328 - loss: 0.6511 - val_accuracy: 0.6299 - val_loss: 0.6158 - learning_rate: 8.5106e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6441 - loss: 0.6077\n",
            "Epoch 177: val_loss did not improve from 0.61577\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6442 - loss: 0.6080 - val_accuracy: 0.6187 - val_loss: 0.6242 - learning_rate: 8.5034e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6274\n",
            "Epoch 178: val_loss improved from 0.61577 to 0.61067, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6641 - loss: 0.6274 - val_accuracy: 0.6374 - val_loss: 0.6107 - learning_rate: 8.4962e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6403 - loss: 0.6099\n",
            "Epoch 179: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6409 - loss: 0.6098 - val_accuracy: 0.6393 - val_loss: 0.6175 - learning_rate: 8.4890e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.5950\n",
            "Epoch 180: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5950 - val_accuracy: 0.6355 - val_loss: 0.6193 - learning_rate: 8.4818e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6645 - loss: 0.5909\n",
            "Epoch 181: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6640 - loss: 0.5918 - val_accuracy: 0.6505 - val_loss: 0.6185 - learning_rate: 8.4746e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5845\n",
            "Epoch 182: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5845 - val_accuracy: 0.6243 - val_loss: 0.6277 - learning_rate: 8.4674e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6474 - loss: 0.6143\n",
            "Epoch 183: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6479 - loss: 0.6140 - val_accuracy: 0.6262 - val_loss: 0.6272 - learning_rate: 8.4602e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6473\n",
            "Epoch 184: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6473 - val_accuracy: 0.6411 - val_loss: 0.6171 - learning_rate: 8.4531e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6438 - loss: 0.6097\n",
            "Epoch 185: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6437 - loss: 0.6095 - val_accuracy: 0.6449 - val_loss: 0.6184 - learning_rate: 8.4459e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6797 - loss: 0.5870\n",
            "Epoch 186: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5870 - val_accuracy: 0.6355 - val_loss: 0.6130 - learning_rate: 8.4388e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6557 - loss: 0.5931\n",
            "Epoch 187: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6552 - loss: 0.5936 - val_accuracy: 0.6355 - val_loss: 0.6201 - learning_rate: 8.4317e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5625 - loss: 0.6439\n",
            "Epoch 188: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5625 - loss: 0.6439 - val_accuracy: 0.6355 - val_loss: 0.6156 - learning_rate: 8.4246e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6552 - loss: 0.5999\n",
            "Epoch 189: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6553 - loss: 0.5997 - val_accuracy: 0.6411 - val_loss: 0.6147 - learning_rate: 8.4175e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6091\n",
            "Epoch 190: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6091 - val_accuracy: 0.6336 - val_loss: 0.6162 - learning_rate: 8.4104e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6297 - loss: 0.6228\n",
            "Epoch 191: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6312 - loss: 0.6219 - val_accuracy: 0.6411 - val_loss: 0.6158 - learning_rate: 8.4034e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6117\n",
            "Epoch 192: val_loss did not improve from 0.61067\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6117 - val_accuracy: 0.6243 - val_loss: 0.6260 - learning_rate: 8.3963e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6623 - loss: 0.6070\n",
            "Epoch 193: val_loss improved from 0.61067 to 0.61020, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 283ms/step - accuracy: 0.6617 - loss: 0.6070 - val_accuracy: 0.6542 - val_loss: 0.6102 - learning_rate: 8.3893e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6233\n",
            "Epoch 194: val_loss did not improve from 0.61020\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6233 - val_accuracy: 0.6056 - val_loss: 0.6217 - learning_rate: 8.3822e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6615 - loss: 0.6004\n",
            "Epoch 195: val_loss did not improve from 0.61020\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6613 - loss: 0.6006 - val_accuracy: 0.6280 - val_loss: 0.6251 - learning_rate: 8.3752e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.6509\n",
            "Epoch 196: val_loss did not improve from 0.61020\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6509 - val_accuracy: 0.6206 - val_loss: 0.6205 - learning_rate: 8.3682e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6592 - loss: 0.6040\n",
            "Epoch 197: val_loss did not improve from 0.61020\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6592 - loss: 0.6041 - val_accuracy: 0.6449 - val_loss: 0.6123 - learning_rate: 8.3612e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5274\n",
            "Epoch 198: val_loss improved from 0.61020 to 0.60866, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6953 - loss: 0.5274 - val_accuracy: 0.6355 - val_loss: 0.6087 - learning_rate: 8.3542e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6738 - loss: 0.5888\n",
            "Epoch 199: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6735 - loss: 0.5891 - val_accuracy: 0.6168 - val_loss: 0.6207 - learning_rate: 8.3472e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6396\n",
            "Epoch 200: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6396 - val_accuracy: 0.6393 - val_loss: 0.6144 - learning_rate: 8.3403e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6501 - loss: 0.5962\n",
            "Epoch 201: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6506 - loss: 0.5962 - val_accuracy: 0.6430 - val_loss: 0.6131 - learning_rate: 8.3333e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6172 - loss: 0.6326\n",
            "Epoch 202: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6326 - val_accuracy: 0.6299 - val_loss: 0.6172 - learning_rate: 8.3264e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6642 - loss: 0.5985\n",
            "Epoch 203: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6645 - loss: 0.5983 - val_accuracy: 0.6262 - val_loss: 0.6220 - learning_rate: 8.3195e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6953 - loss: 0.5898\n",
            "Epoch 204: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5898 - val_accuracy: 0.6374 - val_loss: 0.6104 - learning_rate: 8.3126e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6529 - loss: 0.5980\n",
            "Epoch 205: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6530 - loss: 0.5982 - val_accuracy: 0.6224 - val_loss: 0.6272 - learning_rate: 8.3056e-04\n",
            "Epoch 206/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5644\n",
            "Epoch 206: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5644 - val_accuracy: 0.6280 - val_loss: 0.6151 - learning_rate: 8.2988e-04\n",
            "Epoch 207/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6591 - loss: 0.6024\n",
            "Epoch 207: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6588 - loss: 0.6024 - val_accuracy: 0.6280 - val_loss: 0.6195 - learning_rate: 8.2919e-04\n",
            "Epoch 208/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5494\n",
            "Epoch 208: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5494 - val_accuracy: 0.6393 - val_loss: 0.6117 - learning_rate: 8.2850e-04\n",
            "Epoch 209/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6464 - loss: 0.6075\n",
            "Epoch 209: val_loss did not improve from 0.60866\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6471 - loss: 0.6073 - val_accuracy: 0.6523 - val_loss: 0.6142 - learning_rate: 8.2781e-04\n",
            "Epoch 210/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5902\n",
            "Epoch 210: val_loss improved from 0.60866 to 0.60840, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6797 - loss: 0.5902 - val_accuracy: 0.6336 - val_loss: 0.6084 - learning_rate: 8.2713e-04\n",
            "Epoch 211/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6642 - loss: 0.5880\n",
            "Epoch 211: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6641 - loss: 0.5883 - val_accuracy: 0.6598 - val_loss: 0.6135 - learning_rate: 8.2645e-04\n",
            "Epoch 212/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6022\n",
            "Epoch 212: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6022 - val_accuracy: 0.6523 - val_loss: 0.6157 - learning_rate: 8.2576e-04\n",
            "Epoch 213/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6675 - loss: 0.5891\n",
            "Epoch 213: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6672 - loss: 0.5891 - val_accuracy: 0.6430 - val_loss: 0.6227 - learning_rate: 8.2508e-04\n",
            "Epoch 214/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5312 - loss: 0.6551\n",
            "Epoch 214: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5312 - loss: 0.6551 - val_accuracy: 0.6262 - val_loss: 0.6156 - learning_rate: 8.2440e-04\n",
            "Epoch 215/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6770 - loss: 0.5864\n",
            "Epoch 215: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6765 - loss: 0.5870 - val_accuracy: 0.6561 - val_loss: 0.6104 - learning_rate: 8.2372e-04\n",
            "Epoch 216/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6559 - loss: 0.5843\n",
            "Epoch 216: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6559 - loss: 0.5843 - val_accuracy: 0.6561 - val_loss: 0.6089 - learning_rate: 8.2305e-04\n",
            "Epoch 217/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6749 - loss: 0.6054\n",
            "Epoch 217: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6744 - loss: 0.6050 - val_accuracy: 0.6019 - val_loss: 0.6207 - learning_rate: 8.2237e-04\n",
            "Epoch 218/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6989 - loss: 0.5605\n",
            "Epoch 218: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6989 - loss: 0.5605 - val_accuracy: 0.6000 - val_loss: 0.6283 - learning_rate: 8.2169e-04\n",
            "Epoch 219/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6527 - loss: 0.6111\n",
            "Epoch 219: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6530 - loss: 0.6104 - val_accuracy: 0.6486 - val_loss: 0.6178 - learning_rate: 8.2102e-04\n",
            "Epoch 220/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6882 - loss: 0.5750\n",
            "Epoch 220: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6882 - loss: 0.5750 - val_accuracy: 0.6430 - val_loss: 0.6133 - learning_rate: 8.2034e-04\n",
            "Epoch 221/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6560 - loss: 0.5988\n",
            "Epoch 221: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6565 - loss: 0.5987 - val_accuracy: 0.6449 - val_loss: 0.6231 - learning_rate: 8.1967e-04\n",
            "Epoch 222/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6189\n",
            "Epoch 222: val_loss did not improve from 0.60840\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6189 - val_accuracy: 0.6131 - val_loss: 0.6179 - learning_rate: 8.1900e-04\n",
            "Epoch 223/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6646 - loss: 0.6013\n",
            "Epoch 223: val_loss improved from 0.60840 to 0.60795, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6645 - loss: 0.6012 - val_accuracy: 0.6523 - val_loss: 0.6080 - learning_rate: 8.1833e-04\n",
            "Epoch 224/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5596\n",
            "Epoch 224: val_loss did not improve from 0.60795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5596 - val_accuracy: 0.6168 - val_loss: 0.6201 - learning_rate: 8.1766e-04\n",
            "Epoch 225/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6744 - loss: 0.5976\n",
            "Epoch 225: val_loss did not improve from 0.60795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6735 - loss: 0.5977 - val_accuracy: 0.6411 - val_loss: 0.6101 - learning_rate: 8.1699e-04\n",
            "Epoch 226/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5943\n",
            "Epoch 226: val_loss did not improve from 0.60795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5943 - val_accuracy: 0.6131 - val_loss: 0.6188 - learning_rate: 8.1633e-04\n",
            "Epoch 227/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6659 - loss: 0.5919\n",
            "Epoch 227: val_loss did not improve from 0.60795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6659 - loss: 0.5921 - val_accuracy: 0.6673 - val_loss: 0.6131 - learning_rate: 8.1566e-04\n",
            "Epoch 228/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6452 - loss: 0.6047\n",
            "Epoch 228: val_loss did not improve from 0.60795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6452 - loss: 0.6047 - val_accuracy: 0.6299 - val_loss: 0.6130 - learning_rate: 8.1500e-04\n",
            "Epoch 229/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6490 - loss: 0.6030\n",
            "Epoch 229: val_loss did not improve from 0.60795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6495 - loss: 0.6028 - val_accuracy: 0.6374 - val_loss: 0.6168 - learning_rate: 8.1433e-04\n",
            "Epoch 230/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6190\n",
            "Epoch 230: val_loss did not improve from 0.60795\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.6190 - val_accuracy: 0.5963 - val_loss: 0.6253 - learning_rate: 8.1367e-04\n",
            "Epoch 231/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6547 - loss: 0.5921\n",
            "Epoch 231: val_loss improved from 0.60795 to 0.60524, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6545 - loss: 0.5922 - val_accuracy: 0.6411 - val_loss: 0.6052 - learning_rate: 8.1301e-04\n",
            "Epoch 232/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6140\n",
            "Epoch 232: val_loss improved from 0.60524 to 0.60510, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6875 - loss: 0.6140 - val_accuracy: 0.6523 - val_loss: 0.6051 - learning_rate: 8.1235e-04\n",
            "Epoch 233/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6788 - loss: 0.5872\n",
            "Epoch 233: val_loss did not improve from 0.60510\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6787 - loss: 0.5876 - val_accuracy: 0.6449 - val_loss: 0.6092 - learning_rate: 8.1169e-04\n",
            "Epoch 234/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5926\n",
            "Epoch 234: val_loss improved from 0.60510 to 0.60448, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6641 - loss: 0.5926 - val_accuracy: 0.6654 - val_loss: 0.6045 - learning_rate: 8.1103e-04\n",
            "Epoch 235/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6703 - loss: 0.5998\n",
            "Epoch 235: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6700 - loss: 0.5998 - val_accuracy: 0.6579 - val_loss: 0.6140 - learning_rate: 8.1037e-04\n",
            "Epoch 236/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6238\n",
            "Epoch 236: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6238 - val_accuracy: 0.6056 - val_loss: 0.6280 - learning_rate: 8.0972e-04\n",
            "Epoch 237/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6658 - loss: 0.5863\n",
            "Epoch 237: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6654 - loss: 0.5866 - val_accuracy: 0.6336 - val_loss: 0.6111 - learning_rate: 8.0906e-04\n",
            "Epoch 238/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6235\n",
            "Epoch 238: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5859 - loss: 0.6235 - val_accuracy: 0.6355 - val_loss: 0.6100 - learning_rate: 8.0841e-04\n",
            "Epoch 239/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6615 - loss: 0.5909\n",
            "Epoch 239: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6616 - loss: 0.5910 - val_accuracy: 0.6411 - val_loss: 0.6123 - learning_rate: 8.0775e-04\n",
            "Epoch 240/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5411\n",
            "Epoch 240: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5411 - val_accuracy: 0.6523 - val_loss: 0.6110 - learning_rate: 8.0710e-04\n",
            "Epoch 241/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6653 - loss: 0.5851\n",
            "Epoch 241: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6651 - loss: 0.5857 - val_accuracy: 0.6411 - val_loss: 0.6129 - learning_rate: 8.0645e-04\n",
            "Epoch 242/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5793\n",
            "Epoch 242: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5793 - val_accuracy: 0.6374 - val_loss: 0.6128 - learning_rate: 8.0580e-04\n",
            "Epoch 243/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6921 - loss: 0.5815\n",
            "Epoch 243: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6910 - loss: 0.5820 - val_accuracy: 0.6374 - val_loss: 0.6378 - learning_rate: 8.0515e-04\n",
            "Epoch 244/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6215\n",
            "Epoch 244: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6215 - val_accuracy: 0.6280 - val_loss: 0.6128 - learning_rate: 8.0451e-04\n",
            "Epoch 245/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6590 - loss: 0.6012\n",
            "Epoch 245: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6597 - loss: 0.6005 - val_accuracy: 0.6579 - val_loss: 0.6060 - learning_rate: 8.0386e-04\n",
            "Epoch 246/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6882 - loss: 0.6127\n",
            "Epoch 246: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6882 - loss: 0.6127 - val_accuracy: 0.6673 - val_loss: 0.6049 - learning_rate: 8.0321e-04\n",
            "Epoch 247/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6679 - loss: 0.6030\n",
            "Epoch 247: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6679 - loss: 0.6027 - val_accuracy: 0.6542 - val_loss: 0.6054 - learning_rate: 8.0257e-04\n",
            "Epoch 248/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.5507\n",
            "Epoch 248: val_loss did not improve from 0.60448\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5507 - val_accuracy: 0.6374 - val_loss: 0.6049 - learning_rate: 8.0192e-04\n",
            "Epoch 249/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6569 - loss: 0.5963\n",
            "Epoch 249: val_loss improved from 0.60448 to 0.60235, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6571 - loss: 0.5962 - val_accuracy: 0.6449 - val_loss: 0.6024 - learning_rate: 8.0128e-04\n",
            "Epoch 250/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5903\n",
            "Epoch 250: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5903 - val_accuracy: 0.6523 - val_loss: 0.6090 - learning_rate: 8.0064e-04\n",
            "Epoch 251/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6976 - loss: 0.5893\n",
            "Epoch 251: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6970 - loss: 0.5893 - val_accuracy: 0.6579 - val_loss: 0.6065 - learning_rate: 8.0000e-04\n",
            "Epoch 252/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6344 - loss: 0.5814\n",
            "Epoch 252: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6344 - loss: 0.5814 - val_accuracy: 0.6486 - val_loss: 0.6045 - learning_rate: 7.9936e-04\n",
            "Epoch 253/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6755 - loss: 0.5937\n",
            "Epoch 253: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6756 - loss: 0.5935 - val_accuracy: 0.6224 - val_loss: 0.6146 - learning_rate: 7.9872e-04\n",
            "Epoch 254/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6284\n",
            "Epoch 254: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6284 - val_accuracy: 0.6355 - val_loss: 0.6128 - learning_rate: 7.9808e-04\n",
            "Epoch 255/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6712 - loss: 0.5739\n",
            "Epoch 255: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6703 - loss: 0.5750 - val_accuracy: 0.6523 - val_loss: 0.6080 - learning_rate: 7.9745e-04\n",
            "Epoch 256/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5920\n",
            "Epoch 256: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5920 - val_accuracy: 0.6523 - val_loss: 0.6057 - learning_rate: 7.9681e-04\n",
            "Epoch 257/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6712 - loss: 0.5805\n",
            "Epoch 257: val_loss did not improve from 0.60235\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6705 - loss: 0.5810 - val_accuracy: 0.6411 - val_loss: 0.6093 - learning_rate: 7.9618e-04\n",
            "Epoch 258/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5533\n",
            "Epoch 258: val_loss improved from 0.60235 to 0.60071, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7266 - loss: 0.5533 - val_accuracy: 0.6467 - val_loss: 0.6007 - learning_rate: 7.9554e-04\n",
            "Epoch 259/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6516 - loss: 0.5940\n",
            "Epoch 259: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6518 - loss: 0.5940 - val_accuracy: 0.6449 - val_loss: 0.6064 - learning_rate: 7.9491e-04\n",
            "Epoch 260/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5136\n",
            "Epoch 260: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7344 - loss: 0.5136 - val_accuracy: 0.6598 - val_loss: 0.6089 - learning_rate: 7.9428e-04\n",
            "Epoch 261/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6660 - loss: 0.5995\n",
            "Epoch 261: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6659 - loss: 0.5994 - val_accuracy: 0.6019 - val_loss: 0.6307 - learning_rate: 7.9365e-04\n",
            "Epoch 262/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.5708\n",
            "Epoch 262: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5708 - val_accuracy: 0.6131 - val_loss: 0.6196 - learning_rate: 7.9302e-04\n",
            "Epoch 263/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6800 - loss: 0.5738\n",
            "Epoch 263: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6789 - loss: 0.5745 - val_accuracy: 0.6430 - val_loss: 0.6154 - learning_rate: 7.9239e-04\n",
            "Epoch 264/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5469 - loss: 0.6317\n",
            "Epoch 264: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5469 - loss: 0.6317 - val_accuracy: 0.6280 - val_loss: 0.6130 - learning_rate: 7.9177e-04\n",
            "Epoch 265/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6873 - loss: 0.5880\n",
            "Epoch 265: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6858 - loss: 0.5883 - val_accuracy: 0.6579 - val_loss: 0.6064 - learning_rate: 7.9114e-04\n",
            "Epoch 266/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6023\n",
            "Epoch 266: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6023 - val_accuracy: 0.6654 - val_loss: 0.6076 - learning_rate: 7.9051e-04\n",
            "Epoch 267/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6796 - loss: 0.5757\n",
            "Epoch 267: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6788 - loss: 0.5764 - val_accuracy: 0.6710 - val_loss: 0.6067 - learning_rate: 7.8989e-04\n",
            "Epoch 268/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5859 - loss: 0.6590\n",
            "Epoch 268: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5859 - loss: 0.6590 - val_accuracy: 0.6374 - val_loss: 0.6133 - learning_rate: 7.8927e-04\n",
            "Epoch 269/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6587 - loss: 0.5866\n",
            "Epoch 269: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 283ms/step - accuracy: 0.6592 - loss: 0.5863 - val_accuracy: 0.6860 - val_loss: 0.6053 - learning_rate: 7.8864e-04\n",
            "Epoch 270/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5376 - loss: 0.6628\n",
            "Epoch 270: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5376 - loss: 0.6628 - val_accuracy: 0.6187 - val_loss: 0.6147 - learning_rate: 7.8802e-04\n",
            "Epoch 271/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6671 - loss: 0.5853\n",
            "Epoch 271: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6674 - loss: 0.5851 - val_accuracy: 0.6449 - val_loss: 0.6065 - learning_rate: 7.8740e-04\n",
            "Epoch 272/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6102\n",
            "Epoch 272: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6102 - val_accuracy: 0.6449 - val_loss: 0.6123 - learning_rate: 7.8678e-04\n",
            "Epoch 273/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6763 - loss: 0.5738\n",
            "Epoch 273: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6757 - loss: 0.5745 - val_accuracy: 0.6579 - val_loss: 0.6024 - learning_rate: 7.8616e-04\n",
            "Epoch 274/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.6170\n",
            "Epoch 274: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6170 - val_accuracy: 0.6411 - val_loss: 0.6052 - learning_rate: 7.8555e-04\n",
            "Epoch 275/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6794 - loss: 0.5833\n",
            "Epoch 275: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6789 - loss: 0.5834 - val_accuracy: 0.6299 - val_loss: 0.6106 - learning_rate: 7.8493e-04\n",
            "Epoch 276/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6289\n",
            "Epoch 276: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6289 - val_accuracy: 0.6523 - val_loss: 0.6064 - learning_rate: 7.8431e-04\n",
            "Epoch 277/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6702 - loss: 0.5918\n",
            "Epoch 277: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6702 - loss: 0.5918 - val_accuracy: 0.6654 - val_loss: 0.6007 - learning_rate: 7.8370e-04\n",
            "Epoch 278/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5738\n",
            "Epoch 278: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5738 - val_accuracy: 0.6598 - val_loss: 0.6045 - learning_rate: 7.8309e-04\n",
            "Epoch 279/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6735 - loss: 0.5798\n",
            "Epoch 279: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6735 - loss: 0.5802 - val_accuracy: 0.6654 - val_loss: 0.6036 - learning_rate: 7.8247e-04\n",
            "Epoch 280/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6344 - loss: 0.6103\n",
            "Epoch 280: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6344 - loss: 0.6103 - val_accuracy: 0.6206 - val_loss: 0.6125 - learning_rate: 7.8186e-04\n",
            "Epoch 281/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6832 - loss: 0.5682\n",
            "Epoch 281: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6821 - loss: 0.5692 - val_accuracy: 0.6449 - val_loss: 0.6247 - learning_rate: 7.8125e-04\n",
            "Epoch 282/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.6104\n",
            "Epoch 282: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7031 - loss: 0.6104 - val_accuracy: 0.6617 - val_loss: 0.6131 - learning_rate: 7.8064e-04\n",
            "Epoch 283/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6823 - loss: 0.5784\n",
            "Epoch 283: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6816 - loss: 0.5785 - val_accuracy: 0.6561 - val_loss: 0.6064 - learning_rate: 7.8003e-04\n",
            "Epoch 284/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6154\n",
            "Epoch 284: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6154 - val_accuracy: 0.6467 - val_loss: 0.6054 - learning_rate: 7.7942e-04\n",
            "Epoch 285/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6590 - loss: 0.5841\n",
            "Epoch 285: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6597 - loss: 0.5840 - val_accuracy: 0.6729 - val_loss: 0.6026 - learning_rate: 7.7882e-04\n",
            "Epoch 286/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7188 - loss: 0.5712\n",
            "Epoch 286: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5712 - val_accuracy: 0.6692 - val_loss: 0.6036 - learning_rate: 7.7821e-04\n",
            "Epoch 287/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6787 - loss: 0.5856\n",
            "Epoch 287: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6784 - loss: 0.5857 - val_accuracy: 0.6710 - val_loss: 0.6045 - learning_rate: 7.7760e-04\n",
            "Epoch 288/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5881\n",
            "Epoch 288: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5881 - val_accuracy: 0.6766 - val_loss: 0.6030 - learning_rate: 7.7700e-04\n",
            "Epoch 289/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6785 - loss: 0.5811\n",
            "Epoch 289: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6781 - loss: 0.5815 - val_accuracy: 0.6449 - val_loss: 0.6034 - learning_rate: 7.7640e-04\n",
            "Epoch 290/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6774 - loss: 0.5763\n",
            "Epoch 290: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6774 - loss: 0.5763 - val_accuracy: 0.6243 - val_loss: 0.6183 - learning_rate: 7.7580e-04\n",
            "Epoch 291/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6658 - loss: 0.5864\n",
            "Epoch 291: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6662 - loss: 0.5861 - val_accuracy: 0.6561 - val_loss: 0.6035 - learning_rate: 7.7519e-04\n",
            "Epoch 292/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5736\n",
            "Epoch 292: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5736 - val_accuracy: 0.6168 - val_loss: 0.6275 - learning_rate: 7.7459e-04\n",
            "Epoch 293/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6676 - loss: 0.5907\n",
            "Epoch 293: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6677 - loss: 0.5906 - val_accuracy: 0.6374 - val_loss: 0.6107 - learning_rate: 7.7399e-04\n",
            "Epoch 294/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6069\n",
            "Epoch 294: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6069 - val_accuracy: 0.6748 - val_loss: 0.6037 - learning_rate: 7.7340e-04\n",
            "Epoch 295/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6868 - loss: 0.5851\n",
            "Epoch 295: val_loss did not improve from 0.60071\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6860 - loss: 0.5854 - val_accuracy: 0.6467 - val_loss: 0.6087 - learning_rate: 7.7280e-04\n",
            "Epoch 296/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5500\n",
            "Epoch 296: val_loss improved from 0.60071 to 0.59952, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6797 - loss: 0.5500 - val_accuracy: 0.6673 - val_loss: 0.5995 - learning_rate: 7.7220e-04\n",
            "Epoch 297/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6792 - loss: 0.5828\n",
            "Epoch 297: val_loss did not improve from 0.59952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6783 - loss: 0.5833 - val_accuracy: 0.6766 - val_loss: 0.6030 - learning_rate: 7.7160e-04\n",
            "Epoch 298/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.5902\n",
            "Epoch 298: val_loss did not improve from 0.59952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.5902 - val_accuracy: 0.6598 - val_loss: 0.6026 - learning_rate: 7.7101e-04\n",
            "Epoch 299/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6677 - loss: 0.5820\n",
            "Epoch 299: val_loss did not improve from 0.59952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6675 - loss: 0.5826 - val_accuracy: 0.6467 - val_loss: 0.6031 - learning_rate: 7.7042e-04\n",
            "Epoch 300/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7527 - loss: 0.5424\n",
            "Epoch 300: val_loss did not improve from 0.59952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7527 - loss: 0.5424 - val_accuracy: 0.6168 - val_loss: 0.6168 - learning_rate: 7.6982e-04\n",
            "Epoch 301/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6620 - loss: 0.5897\n",
            "Epoch 301: val_loss did not improve from 0.59952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6625 - loss: 0.5896 - val_accuracy: 0.6785 - val_loss: 0.6015 - learning_rate: 7.6923e-04\n",
            "Epoch 302/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5578\n",
            "Epoch 302: val_loss did not improve from 0.59952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5578 - val_accuracy: 0.6168 - val_loss: 0.6094 - learning_rate: 7.6864e-04\n",
            "Epoch 303/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6588 - loss: 0.5869\n",
            "Epoch 303: val_loss improved from 0.59952 to 0.59945, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.6593 - loss: 0.5868 - val_accuracy: 0.6598 - val_loss: 0.5994 - learning_rate: 7.6805e-04\n",
            "Epoch 304/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7527 - loss: 0.5092\n",
            "Epoch 304: val_loss did not improve from 0.59945\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7527 - loss: 0.5092 - val_accuracy: 0.6336 - val_loss: 0.6157 - learning_rate: 7.6746e-04\n",
            "Epoch 305/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6708 - loss: 0.5813\n",
            "Epoch 305: val_loss did not improve from 0.59945\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6705 - loss: 0.5813 - val_accuracy: 0.6505 - val_loss: 0.6064 - learning_rate: 7.6687e-04\n",
            "Epoch 306/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.6230\n",
            "Epoch 306: val_loss did not improve from 0.59945\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6230 - val_accuracy: 0.6430 - val_loss: 0.6072 - learning_rate: 7.6628e-04\n",
            "Epoch 307/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6857 - loss: 0.5748\n",
            "Epoch 307: val_loss improved from 0.59945 to 0.59801, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6850 - loss: 0.5757 - val_accuracy: 0.6598 - val_loss: 0.5980 - learning_rate: 7.6570e-04\n",
            "Epoch 308/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5445\n",
            "Epoch 308: val_loss did not improve from 0.59801\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5445 - val_accuracy: 0.6467 - val_loss: 0.6034 - learning_rate: 7.6511e-04\n",
            "Epoch 309/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6639 - loss: 0.5856\n",
            "Epoch 309: val_loss did not improve from 0.59801\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6641 - loss: 0.5856 - val_accuracy: 0.6187 - val_loss: 0.6246 - learning_rate: 7.6453e-04\n",
            "Epoch 310/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6127\n",
            "Epoch 310: val_loss did not improve from 0.59801\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6127 - val_accuracy: 0.6729 - val_loss: 0.6044 - learning_rate: 7.6394e-04\n",
            "Epoch 311/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6784 - loss: 0.5827\n",
            "Epoch 311: val_loss did not improve from 0.59801\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6780 - loss: 0.5829 - val_accuracy: 0.6617 - val_loss: 0.6067 - learning_rate: 7.6336e-04\n",
            "Epoch 312/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5622\n",
            "Epoch 312: val_loss improved from 0.59801 to 0.59710, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6562 - loss: 0.5622 - val_accuracy: 0.6710 - val_loss: 0.5971 - learning_rate: 7.6278e-04\n",
            "Epoch 313/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6549 - loss: 0.5904\n",
            "Epoch 313: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6548 - loss: 0.5901 - val_accuracy: 0.6355 - val_loss: 0.6068 - learning_rate: 7.6220e-04\n",
            "Epoch 314/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7419 - loss: 0.5580\n",
            "Epoch 314: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7419 - loss: 0.5580 - val_accuracy: 0.6467 - val_loss: 0.6039 - learning_rate: 7.6161e-04\n",
            "Epoch 315/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6719 - loss: 0.5758\n",
            "Epoch 315: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6717 - loss: 0.5762 - val_accuracy: 0.6579 - val_loss: 0.6023 - learning_rate: 7.6104e-04\n",
            "Epoch 316/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6016 - loss: 0.6657\n",
            "Epoch 316: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6657 - val_accuracy: 0.6411 - val_loss: 0.6064 - learning_rate: 7.6046e-04\n",
            "Epoch 317/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6545 - loss: 0.5952\n",
            "Epoch 317: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6554 - loss: 0.5947 - val_accuracy: 0.6822 - val_loss: 0.5986 - learning_rate: 7.5988e-04\n",
            "Epoch 318/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5312\n",
            "Epoch 318: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7266 - loss: 0.5312 - val_accuracy: 0.6579 - val_loss: 0.6114 - learning_rate: 7.5930e-04\n",
            "Epoch 319/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6688 - loss: 0.5860\n",
            "Epoch 319: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6692 - loss: 0.5858 - val_accuracy: 0.6879 - val_loss: 0.6043 - learning_rate: 7.5873e-04\n",
            "Epoch 320/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.6174\n",
            "Epoch 320: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6174 - val_accuracy: 0.6598 - val_loss: 0.6077 - learning_rate: 7.5815e-04\n",
            "Epoch 321/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6563 - loss: 0.5868\n",
            "Epoch 321: val_loss did not improve from 0.59710\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6576 - loss: 0.5864 - val_accuracy: 0.6729 - val_loss: 0.6019 - learning_rate: 7.5758e-04\n",
            "Epoch 322/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5283\n",
            "Epoch 322: val_loss improved from 0.59710 to 0.59346, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7188 - loss: 0.5283 - val_accuracy: 0.6841 - val_loss: 0.5935 - learning_rate: 7.5700e-04\n",
            "Epoch 323/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6945 - loss: 0.5733\n",
            "Epoch 323: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6935 - loss: 0.5738 - val_accuracy: 0.6411 - val_loss: 0.6016 - learning_rate: 7.5643e-04\n",
            "Epoch 324/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7578 - loss: 0.5190\n",
            "Epoch 324: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7578 - loss: 0.5190 - val_accuracy: 0.6280 - val_loss: 0.6049 - learning_rate: 7.5586e-04\n",
            "Epoch 325/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6856 - loss: 0.5724\n",
            "Epoch 325: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6851 - loss: 0.5728 - val_accuracy: 0.6505 - val_loss: 0.6107 - learning_rate: 7.5529e-04\n",
            "Epoch 326/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.5943\n",
            "Epoch 326: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.5943 - val_accuracy: 0.6729 - val_loss: 0.5993 - learning_rate: 7.5472e-04\n",
            "Epoch 327/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6712 - loss: 0.5639\n",
            "Epoch 327: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6711 - loss: 0.5645 - val_accuracy: 0.6579 - val_loss: 0.6035 - learning_rate: 7.5415e-04\n",
            "Epoch 328/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5536\n",
            "Epoch 328: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5536 - val_accuracy: 0.6467 - val_loss: 0.5998 - learning_rate: 7.5358e-04\n",
            "Epoch 329/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6765 - loss: 0.5758\n",
            "Epoch 329: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6763 - loss: 0.5760 - val_accuracy: 0.6804 - val_loss: 0.5993 - learning_rate: 7.5301e-04\n",
            "Epoch 330/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5894\n",
            "Epoch 330: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5894 - val_accuracy: 0.6374 - val_loss: 0.6038 - learning_rate: 7.5245e-04\n",
            "Epoch 331/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6731 - loss: 0.5709\n",
            "Epoch 331: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6728 - loss: 0.5716 - val_accuracy: 0.6710 - val_loss: 0.5970 - learning_rate: 7.5188e-04\n",
            "Epoch 332/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5675\n",
            "Epoch 332: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5675 - val_accuracy: 0.6430 - val_loss: 0.6037 - learning_rate: 7.5131e-04\n",
            "Epoch 333/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6749 - loss: 0.5903\n",
            "Epoch 333: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6746 - loss: 0.5899 - val_accuracy: 0.6617 - val_loss: 0.5973 - learning_rate: 7.5075e-04\n",
            "Epoch 334/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5446\n",
            "Epoch 334: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5446 - val_accuracy: 0.6617 - val_loss: 0.6015 - learning_rate: 7.5019e-04\n",
            "Epoch 335/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6799 - loss: 0.5894\n",
            "Epoch 335: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6798 - loss: 0.5888 - val_accuracy: 0.6804 - val_loss: 0.6017 - learning_rate: 7.4963e-04\n",
            "Epoch 336/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.5629\n",
            "Epoch 336: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6406 - loss: 0.5629 - val_accuracy: 0.6542 - val_loss: 0.6121 - learning_rate: 7.4906e-04\n",
            "Epoch 337/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6825 - loss: 0.5716\n",
            "Epoch 337: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6820 - loss: 0.5722 - val_accuracy: 0.6486 - val_loss: 0.6018 - learning_rate: 7.4850e-04\n",
            "Epoch 338/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6103\n",
            "Epoch 338: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6103 - val_accuracy: 0.6393 - val_loss: 0.6045 - learning_rate: 7.4794e-04\n",
            "Epoch 339/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6708 - loss: 0.5671\n",
            "Epoch 339: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6706 - loss: 0.5676 - val_accuracy: 0.6692 - val_loss: 0.5949 - learning_rate: 7.4738e-04\n",
            "Epoch 340/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.5918\n",
            "Epoch 340: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.5918 - val_accuracy: 0.6804 - val_loss: 0.5946 - learning_rate: 7.4683e-04\n",
            "Epoch 341/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6916 - loss: 0.5641\n",
            "Epoch 341: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6907 - loss: 0.5646 - val_accuracy: 0.6598 - val_loss: 0.6063 - learning_rate: 7.4627e-04\n",
            "Epoch 342/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.6329\n",
            "Epoch 342: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6329 - val_accuracy: 0.6617 - val_loss: 0.6013 - learning_rate: 7.4571e-04\n",
            "Epoch 343/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6789 - loss: 0.5696\n",
            "Epoch 343: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6786 - loss: 0.5700 - val_accuracy: 0.6449 - val_loss: 0.6059 - learning_rate: 7.4516e-04\n",
            "Epoch 344/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5703 - loss: 0.5986\n",
            "Epoch 344: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5703 - loss: 0.5986 - val_accuracy: 0.6729 - val_loss: 0.6000 - learning_rate: 7.4460e-04\n",
            "Epoch 345/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6800 - loss: 0.5706\n",
            "Epoch 345: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6800 - loss: 0.5705 - val_accuracy: 0.6617 - val_loss: 0.6037 - learning_rate: 7.4405e-04\n",
            "Epoch 346/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5881\n",
            "Epoch 346: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5881 - val_accuracy: 0.6654 - val_loss: 0.6085 - learning_rate: 7.4349e-04\n",
            "Epoch 347/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6808 - loss: 0.5571\n",
            "Epoch 347: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6809 - loss: 0.5581 - val_accuracy: 0.6710 - val_loss: 0.5995 - learning_rate: 7.4294e-04\n",
            "Epoch 348/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7031 - loss: 0.5387\n",
            "Epoch 348: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5387 - val_accuracy: 0.6579 - val_loss: 0.6011 - learning_rate: 7.4239e-04\n",
            "Epoch 349/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6603 - loss: 0.5766\n",
            "Epoch 349: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6604 - loss: 0.5768 - val_accuracy: 0.6299 - val_loss: 0.6097 - learning_rate: 7.4184e-04\n",
            "Epoch 350/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6452 - loss: 0.5697\n",
            "Epoch 350: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6452 - loss: 0.5697 - val_accuracy: 0.6579 - val_loss: 0.5991 - learning_rate: 7.4129e-04\n",
            "Epoch 351/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6676 - loss: 0.5824\n",
            "Epoch 351: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6679 - loss: 0.5821 - val_accuracy: 0.6523 - val_loss: 0.6036 - learning_rate: 7.4074e-04\n",
            "Epoch 352/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6272\n",
            "Epoch 352: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5859 - loss: 0.6272 - val_accuracy: 0.6617 - val_loss: 0.6028 - learning_rate: 7.4019e-04\n",
            "Epoch 353/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6812 - loss: 0.5745\n",
            "Epoch 353: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6809 - loss: 0.5745 - val_accuracy: 0.6579 - val_loss: 0.6054 - learning_rate: 7.3964e-04\n",
            "Epoch 354/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.5891\n",
            "Epoch 354: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.5891 - val_accuracy: 0.6692 - val_loss: 0.5969 - learning_rate: 7.3910e-04\n",
            "Epoch 355/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6575 - loss: 0.5947\n",
            "Epoch 355: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6582 - loss: 0.5941 - val_accuracy: 0.6729 - val_loss: 0.5975 - learning_rate: 7.3855e-04\n",
            "Epoch 356/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5784\n",
            "Epoch 356: val_loss did not improve from 0.59346\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5784 - val_accuracy: 0.6561 - val_loss: 0.6083 - learning_rate: 7.3801e-04\n",
            "Epoch 357/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6866 - loss: 0.5673\n",
            "Epoch 357: val_loss improved from 0.59346 to 0.59188, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 284ms/step - accuracy: 0.6862 - loss: 0.5677 - val_accuracy: 0.6579 - val_loss: 0.5919 - learning_rate: 7.3746e-04\n",
            "Epoch 358/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6169\n",
            "Epoch 358: val_loss did not improve from 0.59188\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.6169 - val_accuracy: 0.6654 - val_loss: 0.5963 - learning_rate: 7.3692e-04\n",
            "Epoch 359/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6965 - loss: 0.5585\n",
            "Epoch 359: val_loss did not improve from 0.59188\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6961 - loss: 0.5595 - val_accuracy: 0.6075 - val_loss: 0.6249 - learning_rate: 7.3638e-04\n",
            "Epoch 360/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6569\n",
            "Epoch 360: val_loss did not improve from 0.59188\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5859 - loss: 0.6569 - val_accuracy: 0.6748 - val_loss: 0.6007 - learning_rate: 7.3584e-04\n",
            "Epoch 361/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6615 - loss: 0.5881\n",
            "Epoch 361: val_loss did not improve from 0.59188\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6619 - loss: 0.5882 - val_accuracy: 0.6673 - val_loss: 0.5984 - learning_rate: 7.3529e-04\n",
            "Epoch 362/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5473\n",
            "Epoch 362: val_loss did not improve from 0.59188\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5473 - val_accuracy: 0.6561 - val_loss: 0.6022 - learning_rate: 7.3475e-04\n",
            "Epoch 363/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6674 - loss: 0.5736\n",
            "Epoch 363: val_loss did not improve from 0.59188\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6675 - loss: 0.5738 - val_accuracy: 0.6636 - val_loss: 0.6051 - learning_rate: 7.3421e-04\n",
            "Epoch 364/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5558\n",
            "Epoch 364: val_loss improved from 0.59188 to 0.59057, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6875 - loss: 0.5558 - val_accuracy: 0.6822 - val_loss: 0.5906 - learning_rate: 7.3368e-04\n",
            "Epoch 365/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6595 - loss: 0.5776\n",
            "Epoch 365: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6594 - loss: 0.5778 - val_accuracy: 0.6841 - val_loss: 0.5974 - learning_rate: 7.3314e-04\n",
            "Epoch 366/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5033\n",
            "Epoch 366: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5033 - val_accuracy: 0.6542 - val_loss: 0.6076 - learning_rate: 7.3260e-04\n",
            "Epoch 367/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6614 - loss: 0.5830\n",
            "Epoch 367: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6614 - loss: 0.5826 - val_accuracy: 0.6785 - val_loss: 0.5964 - learning_rate: 7.3206e-04\n",
            "Epoch 368/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5591\n",
            "Epoch 368: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7344 - loss: 0.5591 - val_accuracy: 0.6710 - val_loss: 0.6006 - learning_rate: 7.3153e-04\n",
            "Epoch 369/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6701 - loss: 0.5827\n",
            "Epoch 369: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6704 - loss: 0.5822 - val_accuracy: 0.6393 - val_loss: 0.6087 - learning_rate: 7.3099e-04\n",
            "Epoch 370/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.5981\n",
            "Epoch 370: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.5981 - val_accuracy: 0.6505 - val_loss: 0.6068 - learning_rate: 7.3046e-04\n",
            "Epoch 371/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6878 - loss: 0.5682\n",
            "Epoch 371: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6873 - loss: 0.5687 - val_accuracy: 0.6579 - val_loss: 0.6155 - learning_rate: 7.2993e-04\n",
            "Epoch 372/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5557\n",
            "Epoch 372: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5557 - val_accuracy: 0.6710 - val_loss: 0.5981 - learning_rate: 7.2939e-04\n",
            "Epoch 373/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6579 - loss: 0.5820\n",
            "Epoch 373: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6592 - loss: 0.5814 - val_accuracy: 0.6523 - val_loss: 0.5981 - learning_rate: 7.2886e-04\n",
            "Epoch 374/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5810\n",
            "Epoch 374: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5810 - val_accuracy: 0.6636 - val_loss: 0.5967 - learning_rate: 7.2833e-04\n",
            "Epoch 375/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6705 - loss: 0.5842\n",
            "Epoch 375: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6714 - loss: 0.5836 - val_accuracy: 0.6785 - val_loss: 0.6027 - learning_rate: 7.2780e-04\n",
            "Epoch 376/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6018\n",
            "Epoch 376: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6018 - val_accuracy: 0.6785 - val_loss: 0.5906 - learning_rate: 7.2727e-04\n",
            "Epoch 377/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6724 - loss: 0.5734\n",
            "Epoch 377: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6722 - loss: 0.5736 - val_accuracy: 0.6430 - val_loss: 0.6036 - learning_rate: 7.2674e-04\n",
            "Epoch 378/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.5732\n",
            "Epoch 378: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.5732 - val_accuracy: 0.6654 - val_loss: 0.5947 - learning_rate: 7.2622e-04\n",
            "Epoch 379/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6610 - loss: 0.5780\n",
            "Epoch 379: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6612 - loss: 0.5779 - val_accuracy: 0.6822 - val_loss: 0.6012 - learning_rate: 7.2569e-04\n",
            "Epoch 380/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5985\n",
            "Epoch 380: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5985 - val_accuracy: 0.6318 - val_loss: 0.6092 - learning_rate: 7.2516e-04\n",
            "Epoch 381/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6712 - loss: 0.5747\n",
            "Epoch 381: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6719 - loss: 0.5747 - val_accuracy: 0.6729 - val_loss: 0.5958 - learning_rate: 7.2464e-04\n",
            "Epoch 382/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6703\n",
            "Epoch 382: val_loss did not improve from 0.59057\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6703 - val_accuracy: 0.6561 - val_loss: 0.6043 - learning_rate: 7.2411e-04\n",
            "Epoch 383/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6519 - loss: 0.5883\n",
            "Epoch 383: val_loss improved from 0.59057 to 0.58793, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6524 - loss: 0.5878 - val_accuracy: 0.6729 - val_loss: 0.5879 - learning_rate: 7.2359e-04\n",
            "Epoch 384/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7656 - loss: 0.4872\n",
            "Epoch 384: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7656 - loss: 0.4872 - val_accuracy: 0.6449 - val_loss: 0.6080 - learning_rate: 7.2307e-04\n",
            "Epoch 385/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6875 - loss: 0.5713\n",
            "Epoch 385: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6873 - loss: 0.5716 - val_accuracy: 0.6692 - val_loss: 0.6062 - learning_rate: 7.2254e-04\n",
            "Epoch 386/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5988\n",
            "Epoch 386: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6641 - loss: 0.5988 - val_accuracy: 0.6523 - val_loss: 0.6066 - learning_rate: 7.2202e-04\n",
            "Epoch 387/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6542 - loss: 0.5847\n",
            "Epoch 387: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6553 - loss: 0.5843 - val_accuracy: 0.6374 - val_loss: 0.6213 - learning_rate: 7.2150e-04\n",
            "Epoch 388/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5812\n",
            "Epoch 388: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5812 - val_accuracy: 0.6766 - val_loss: 0.6063 - learning_rate: 7.2098e-04\n",
            "Epoch 389/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6725 - loss: 0.5808\n",
            "Epoch 389: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6720 - loss: 0.5807 - val_accuracy: 0.6729 - val_loss: 0.6027 - learning_rate: 7.2046e-04\n",
            "Epoch 390/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7422 - loss: 0.5763\n",
            "Epoch 390: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5763 - val_accuracy: 0.6916 - val_loss: 0.5919 - learning_rate: 7.1994e-04\n",
            "Epoch 391/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6650 - loss: 0.5897\n",
            "Epoch 391: val_loss did not improve from 0.58793\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6657 - loss: 0.5890 - val_accuracy: 0.6467 - val_loss: 0.6133 - learning_rate: 7.1942e-04\n",
            "Epoch 392/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5535\n",
            "Epoch 392: val_loss improved from 0.58793 to 0.58675, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6641 - loss: 0.5535 - val_accuracy: 0.6860 - val_loss: 0.5868 - learning_rate: 7.1891e-04\n",
            "Epoch 393/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6946 - loss: 0.5586\n",
            "Epoch 393: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6935 - loss: 0.5592 - val_accuracy: 0.6449 - val_loss: 0.6171 - learning_rate: 7.1839e-04\n",
            "Epoch 394/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.5865\n",
            "Epoch 394: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.5865 - val_accuracy: 0.6617 - val_loss: 0.5939 - learning_rate: 7.1788e-04\n",
            "Epoch 395/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6837 - loss: 0.5803\n",
            "Epoch 395: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6835 - loss: 0.5803 - val_accuracy: 0.6748 - val_loss: 0.5973 - learning_rate: 7.1736e-04\n",
            "Epoch 396/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6328 - loss: 0.5931\n",
            "Epoch 396: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.5931 - val_accuracy: 0.6710 - val_loss: 0.5987 - learning_rate: 7.1685e-04\n",
            "Epoch 397/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6945 - loss: 0.5559\n",
            "Epoch 397: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6939 - loss: 0.5566 - val_accuracy: 0.6710 - val_loss: 0.5918 - learning_rate: 7.1633e-04\n",
            "Epoch 398/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6392\n",
            "Epoch 398: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6392 - val_accuracy: 0.6766 - val_loss: 0.5952 - learning_rate: 7.1582e-04\n",
            "Epoch 399/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6721 - loss: 0.5772\n",
            "Epoch 399: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6725 - loss: 0.5769 - val_accuracy: 0.6692 - val_loss: 0.6001 - learning_rate: 7.1531e-04\n",
            "Epoch 400/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6882 - loss: 0.6110\n",
            "Epoch 400: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6882 - loss: 0.6110 - val_accuracy: 0.6692 - val_loss: 0.5967 - learning_rate: 7.1480e-04\n",
            "Epoch 401/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6929 - loss: 0.5624\n",
            "Epoch 401: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6926 - loss: 0.5626 - val_accuracy: 0.6430 - val_loss: 0.6048 - learning_rate: 7.1429e-04\n",
            "Epoch 402/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5674\n",
            "Epoch 402: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5674 - val_accuracy: 0.6692 - val_loss: 0.5950 - learning_rate: 7.1378e-04\n",
            "Epoch 403/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6910 - loss: 0.5602\n",
            "Epoch 403: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6910 - loss: 0.5606 - val_accuracy: 0.6505 - val_loss: 0.6058 - learning_rate: 7.1327e-04\n",
            "Epoch 404/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6016 - loss: 0.6077\n",
            "Epoch 404: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6016 - loss: 0.6077 - val_accuracy: 0.6542 - val_loss: 0.6060 - learning_rate: 7.1276e-04\n",
            "Epoch 405/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7011 - loss: 0.5588\n",
            "Epoch 405: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.7006 - loss: 0.5591 - val_accuracy: 0.6505 - val_loss: 0.6113 - learning_rate: 7.1225e-04\n",
            "Epoch 406/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6004\n",
            "Epoch 406: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6004 - val_accuracy: 0.6673 - val_loss: 0.6004 - learning_rate: 7.1174e-04\n",
            "Epoch 407/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6841 - loss: 0.5621\n",
            "Epoch 407: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6832 - loss: 0.5633 - val_accuracy: 0.6636 - val_loss: 0.5931 - learning_rate: 7.1124e-04\n",
            "Epoch 408/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7109 - loss: 0.5292\n",
            "Epoch 408: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5292 - val_accuracy: 0.6785 - val_loss: 0.5930 - learning_rate: 7.1073e-04\n",
            "Epoch 409/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6799 - loss: 0.5698\n",
            "Epoch 409: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6805 - loss: 0.5697 - val_accuracy: 0.6804 - val_loss: 0.5992 - learning_rate: 7.1023e-04\n",
            "Epoch 410/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6344 - loss: 0.6003\n",
            "Epoch 410: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6344 - loss: 0.6003 - val_accuracy: 0.6561 - val_loss: 0.6070 - learning_rate: 7.0972e-04\n",
            "Epoch 411/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6852 - loss: 0.5682\n",
            "Epoch 411: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6853 - loss: 0.5681 - val_accuracy: 0.6467 - val_loss: 0.6142 - learning_rate: 7.0922e-04\n",
            "Epoch 412/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6094 - loss: 0.6599\n",
            "Epoch 412: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.6599 - val_accuracy: 0.6523 - val_loss: 0.6082 - learning_rate: 7.0872e-04\n",
            "Epoch 413/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6804 - loss: 0.5789\n",
            "Epoch 413: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6804 - loss: 0.5786 - val_accuracy: 0.6692 - val_loss: 0.5999 - learning_rate: 7.0822e-04\n",
            "Epoch 414/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5881\n",
            "Epoch 414: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5881 - val_accuracy: 0.6860 - val_loss: 0.5918 - learning_rate: 7.0771e-04\n",
            "Epoch 415/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6804 - loss: 0.5611\n",
            "Epoch 415: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6805 - loss: 0.5610 - val_accuracy: 0.6505 - val_loss: 0.6097 - learning_rate: 7.0721e-04\n",
            "Epoch 416/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6033\n",
            "Epoch 416: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6033 - val_accuracy: 0.6598 - val_loss: 0.6036 - learning_rate: 7.0671e-04\n",
            "Epoch 417/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6788 - loss: 0.5714\n",
            "Epoch 417: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6782 - loss: 0.5717 - val_accuracy: 0.6710 - val_loss: 0.6024 - learning_rate: 7.0621e-04\n",
            "Epoch 418/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6427\n",
            "Epoch 418: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.6427 - val_accuracy: 0.6972 - val_loss: 0.5921 - learning_rate: 7.0572e-04\n",
            "Epoch 419/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6780 - loss: 0.5821\n",
            "Epoch 419: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6782 - loss: 0.5812 - val_accuracy: 0.6598 - val_loss: 0.5947 - learning_rate: 7.0522e-04\n",
            "Epoch 420/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5339\n",
            "Epoch 420: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5339 - val_accuracy: 0.6822 - val_loss: 0.5967 - learning_rate: 7.0472e-04\n",
            "Epoch 421/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6846 - loss: 0.5745\n",
            "Epoch 421: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6843 - loss: 0.5745 - val_accuracy: 0.6598 - val_loss: 0.6065 - learning_rate: 7.0423e-04\n",
            "Epoch 422/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5831\n",
            "Epoch 422: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6484 - loss: 0.5831 - val_accuracy: 0.6879 - val_loss: 0.5891 - learning_rate: 7.0373e-04\n",
            "Epoch 423/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6733 - loss: 0.5745\n",
            "Epoch 423: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6735 - loss: 0.5745 - val_accuracy: 0.6748 - val_loss: 0.5966 - learning_rate: 7.0323e-04\n",
            "Epoch 424/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5288\n",
            "Epoch 424: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5288 - val_accuracy: 0.6766 - val_loss: 0.6027 - learning_rate: 7.0274e-04\n",
            "Epoch 425/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6868 - loss: 0.5578\n",
            "Epoch 425: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6866 - loss: 0.5584 - val_accuracy: 0.6673 - val_loss: 0.5955 - learning_rate: 7.0225e-04\n",
            "Epoch 426/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5587\n",
            "Epoch 426: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5587 - val_accuracy: 0.6729 - val_loss: 0.6059 - learning_rate: 7.0175e-04\n",
            "Epoch 427/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6707 - loss: 0.5793\n",
            "Epoch 427: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6707 - loss: 0.5791 - val_accuracy: 0.6766 - val_loss: 0.5989 - learning_rate: 7.0126e-04\n",
            "Epoch 428/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.5436\n",
            "Epoch 428: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.5436 - val_accuracy: 0.6654 - val_loss: 0.6002 - learning_rate: 7.0077e-04\n",
            "Epoch 429/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6917 - loss: 0.5665\n",
            "Epoch 429: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6911 - loss: 0.5667 - val_accuracy: 0.6336 - val_loss: 0.6299 - learning_rate: 7.0028e-04\n",
            "Epoch 430/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5846\n",
            "Epoch 430: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5846 - val_accuracy: 0.6692 - val_loss: 0.5973 - learning_rate: 6.9979e-04\n",
            "Epoch 431/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6802 - loss: 0.5552\n",
            "Epoch 431: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6800 - loss: 0.5559 - val_accuracy: 0.6430 - val_loss: 0.5966 - learning_rate: 6.9930e-04\n",
            "Epoch 432/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6355\n",
            "Epoch 432: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6355 - val_accuracy: 0.6766 - val_loss: 0.5888 - learning_rate: 6.9881e-04\n",
            "Epoch 433/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6888 - loss: 0.5706\n",
            "Epoch 433: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6883 - loss: 0.5705 - val_accuracy: 0.6804 - val_loss: 0.5954 - learning_rate: 6.9832e-04\n",
            "Epoch 434/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5946\n",
            "Epoch 434: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5946 - val_accuracy: 0.6804 - val_loss: 0.5983 - learning_rate: 6.9784e-04\n",
            "Epoch 435/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6764 - loss: 0.5774\n",
            "Epoch 435: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6770 - loss: 0.5767 - val_accuracy: 0.6692 - val_loss: 0.6000 - learning_rate: 6.9735e-04\n",
            "Epoch 436/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6038\n",
            "Epoch 436: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6038 - val_accuracy: 0.6355 - val_loss: 0.6240 - learning_rate: 6.9686e-04\n",
            "Epoch 437/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6951 - loss: 0.5634\n",
            "Epoch 437: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6944 - loss: 0.5634 - val_accuracy: 0.6617 - val_loss: 0.6211 - learning_rate: 6.9638e-04\n",
            "Epoch 438/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6196\n",
            "Epoch 438: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6196 - val_accuracy: 0.6785 - val_loss: 0.6051 - learning_rate: 6.9589e-04\n",
            "Epoch 439/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6707 - loss: 0.5811\n",
            "Epoch 439: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6716 - loss: 0.5802 - val_accuracy: 0.6897 - val_loss: 0.5952 - learning_rate: 6.9541e-04\n",
            "Epoch 440/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.5982\n",
            "Epoch 440: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5859 - loss: 0.5982 - val_accuracy: 0.6430 - val_loss: 0.6116 - learning_rate: 6.9493e-04\n",
            "Epoch 441/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6901 - loss: 0.5591\n",
            "Epoch 441: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6894 - loss: 0.5596 - val_accuracy: 0.6449 - val_loss: 0.5995 - learning_rate: 6.9444e-04\n",
            "Epoch 442/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6118\n",
            "Epoch 442: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5859 - loss: 0.6118 - val_accuracy: 0.6766 - val_loss: 0.5932 - learning_rate: 6.9396e-04\n",
            "Epoch 443/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6943 - loss: 0.5623\n",
            "Epoch 443: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6927 - loss: 0.5630 - val_accuracy: 0.6561 - val_loss: 0.5997 - learning_rate: 6.9348e-04\n",
            "Epoch 444/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5390\n",
            "Epoch 444: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7344 - loss: 0.5390 - val_accuracy: 0.6636 - val_loss: 0.6020 - learning_rate: 6.9300e-04\n",
            "Epoch 445/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6835 - loss: 0.5662\n",
            "Epoch 445: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6835 - loss: 0.5664 - val_accuracy: 0.6729 - val_loss: 0.6013 - learning_rate: 6.9252e-04\n",
            "Epoch 446/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.5510\n",
            "Epoch 446: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5510 - val_accuracy: 0.6729 - val_loss: 0.5921 - learning_rate: 6.9204e-04\n",
            "Epoch 447/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6885 - loss: 0.5530\n",
            "Epoch 447: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6876 - loss: 0.5540 - val_accuracy: 0.6710 - val_loss: 0.5949 - learning_rate: 6.9156e-04\n",
            "Epoch 448/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6003\n",
            "Epoch 448: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6003 - val_accuracy: 0.6579 - val_loss: 0.6038 - learning_rate: 6.9109e-04\n",
            "Epoch 449/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6763 - loss: 0.5676\n",
            "Epoch 449: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6769 - loss: 0.5674 - val_accuracy: 0.6673 - val_loss: 0.6004 - learning_rate: 6.9061e-04\n",
            "Epoch 450/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7204 - loss: 0.5753\n",
            "Epoch 450: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7204 - loss: 0.5753 - val_accuracy: 0.6710 - val_loss: 0.6029 - learning_rate: 6.9013e-04\n",
            "Epoch 451/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6710 - loss: 0.5725\n",
            "Epoch 451: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6720 - loss: 0.5723 - val_accuracy: 0.6785 - val_loss: 0.5991 - learning_rate: 6.8966e-04\n",
            "Epoch 452/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5979\n",
            "Epoch 452: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5979 - val_accuracy: 0.6467 - val_loss: 0.6046 - learning_rate: 6.8918e-04\n",
            "Epoch 453/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6904 - loss: 0.5585\n",
            "Epoch 453: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6900 - loss: 0.5588 - val_accuracy: 0.6505 - val_loss: 0.6057 - learning_rate: 6.8871e-04\n",
            "Epoch 454/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5603\n",
            "Epoch 454: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5603 - val_accuracy: 0.6748 - val_loss: 0.5912 - learning_rate: 6.8823e-04\n",
            "Epoch 455/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6821 - loss: 0.5676\n",
            "Epoch 455: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6824 - loss: 0.5676 - val_accuracy: 0.6991 - val_loss: 0.5884 - learning_rate: 6.8776e-04\n",
            "Epoch 456/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5524\n",
            "Epoch 456: val_loss did not improve from 0.58675\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5524 - val_accuracy: 0.6449 - val_loss: 0.5959 - learning_rate: 6.8729e-04\n",
            "Epoch 457/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6668 - loss: 0.5717\n",
            "Epoch 457: val_loss improved from 0.58675 to 0.58599, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6672 - loss: 0.5716 - val_accuracy: 0.6860 - val_loss: 0.5860 - learning_rate: 6.8681e-04\n",
            "Epoch 458/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5969\n",
            "Epoch 458: val_loss did not improve from 0.58599\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5969 - val_accuracy: 0.6579 - val_loss: 0.6068 - learning_rate: 6.8634e-04\n",
            "Epoch 459/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6928 - loss: 0.5630\n",
            "Epoch 459: val_loss did not improve from 0.58599\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6924 - loss: 0.5636 - val_accuracy: 0.6579 - val_loss: 0.5952 - learning_rate: 6.8587e-04\n",
            "Epoch 460/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.6017\n",
            "Epoch 460: val_loss did not improve from 0.58599\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6017 - val_accuracy: 0.6710 - val_loss: 0.5893 - learning_rate: 6.8540e-04\n",
            "Epoch 461/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6759 - loss: 0.5664\n",
            "Epoch 461: val_loss did not improve from 0.58599\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6761 - loss: 0.5662 - val_accuracy: 0.6841 - val_loss: 0.5999 - learning_rate: 6.8493e-04\n",
            "Epoch 462/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5765\n",
            "Epoch 462: val_loss did not improve from 0.58599\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5765 - val_accuracy: 0.6766 - val_loss: 0.5907 - learning_rate: 6.8446e-04\n",
            "Epoch 463/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6801 - loss: 0.5591\n",
            "Epoch 463: val_loss improved from 0.58599 to 0.58573, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.6800 - loss: 0.5596 - val_accuracy: 0.6673 - val_loss: 0.5857 - learning_rate: 6.8399e-04\n",
            "Epoch 464/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5374\n",
            "Epoch 464: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5374 - val_accuracy: 0.6579 - val_loss: 0.5983 - learning_rate: 6.8353e-04\n",
            "Epoch 465/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6768 - loss: 0.5680\n",
            "Epoch 465: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6772 - loss: 0.5681 - val_accuracy: 0.6561 - val_loss: 0.6043 - learning_rate: 6.8306e-04\n",
            "Epoch 466/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5751\n",
            "Epoch 466: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5751 - val_accuracy: 0.6542 - val_loss: 0.6031 - learning_rate: 6.8259e-04\n",
            "Epoch 467/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6778 - loss: 0.5602\n",
            "Epoch 467: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6778 - loss: 0.5603 - val_accuracy: 0.6991 - val_loss: 0.5903 - learning_rate: 6.8213e-04\n",
            "Epoch 468/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5758\n",
            "Epoch 468: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5758 - val_accuracy: 0.6430 - val_loss: 0.6000 - learning_rate: 6.8166e-04\n",
            "Epoch 469/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6705 - loss: 0.5722\n",
            "Epoch 469: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6710 - loss: 0.5724 - val_accuracy: 0.6710 - val_loss: 0.5953 - learning_rate: 6.8120e-04\n",
            "Epoch 470/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7097 - loss: 0.4956\n",
            "Epoch 470: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7097 - loss: 0.4956 - val_accuracy: 0.6692 - val_loss: 0.5970 - learning_rate: 6.8074e-04\n",
            "Epoch 471/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7124 - loss: 0.5638\n",
            "Epoch 471: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.7116 - loss: 0.5636 - val_accuracy: 0.6879 - val_loss: 0.5981 - learning_rate: 6.8027e-04\n",
            "Epoch 472/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6344 - loss: 0.5119\n",
            "Epoch 472: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6344 - loss: 0.5119 - val_accuracy: 0.6953 - val_loss: 0.5911 - learning_rate: 6.7981e-04\n",
            "Epoch 473/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6712 - loss: 0.5749\n",
            "Epoch 473: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6719 - loss: 0.5746 - val_accuracy: 0.6860 - val_loss: 0.5923 - learning_rate: 6.7935e-04\n",
            "Epoch 474/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.5967\n",
            "Epoch 474: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.5967 - val_accuracy: 0.6654 - val_loss: 0.5983 - learning_rate: 6.7889e-04\n",
            "Epoch 475/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6898 - loss: 0.5528\n",
            "Epoch 475: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6897 - loss: 0.5534 - val_accuracy: 0.6822 - val_loss: 0.5876 - learning_rate: 6.7843e-04\n",
            "Epoch 476/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6953 - loss: 0.5522\n",
            "Epoch 476: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5522 - val_accuracy: 0.6804 - val_loss: 0.5901 - learning_rate: 6.7797e-04\n",
            "Epoch 477/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6799 - loss: 0.5614\n",
            "Epoch 477: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6802 - loss: 0.5611 - val_accuracy: 0.6542 - val_loss: 0.6090 - learning_rate: 6.7751e-04\n",
            "Epoch 478/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5828\n",
            "Epoch 478: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5828 - val_accuracy: 0.6841 - val_loss: 0.5905 - learning_rate: 6.7705e-04\n",
            "Epoch 479/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6929 - loss: 0.5796\n",
            "Epoch 479: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6924 - loss: 0.5791 - val_accuracy: 0.6879 - val_loss: 0.5887 - learning_rate: 6.7659e-04\n",
            "Epoch 480/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5257\n",
            "Epoch 480: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5257 - val_accuracy: 0.6710 - val_loss: 0.5929 - learning_rate: 6.7613e-04\n",
            "Epoch 481/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6742 - loss: 0.5777\n",
            "Epoch 481: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6751 - loss: 0.5770 - val_accuracy: 0.6785 - val_loss: 0.5941 - learning_rate: 6.7568e-04\n",
            "Epoch 482/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5865\n",
            "Epoch 482: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7266 - loss: 0.5865 - val_accuracy: 0.6692 - val_loss: 0.6039 - learning_rate: 6.7522e-04\n",
            "Epoch 483/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6918 - loss: 0.5596\n",
            "Epoch 483: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6916 - loss: 0.5601 - val_accuracy: 0.6748 - val_loss: 0.5861 - learning_rate: 6.7476e-04\n",
            "Epoch 484/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6016\n",
            "Epoch 484: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6016 - val_accuracy: 0.6692 - val_loss: 0.5954 - learning_rate: 6.7431e-04\n",
            "Epoch 485/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6930 - loss: 0.5613\n",
            "Epoch 485: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6933 - loss: 0.5610 - val_accuracy: 0.6879 - val_loss: 0.5955 - learning_rate: 6.7385e-04\n",
            "Epoch 486/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.5925\n",
            "Epoch 486: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5925 - val_accuracy: 0.6710 - val_loss: 0.5992 - learning_rate: 6.7340e-04\n",
            "Epoch 487/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6972 - loss: 0.5459\n",
            "Epoch 487: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6963 - loss: 0.5469 - val_accuracy: 0.6972 - val_loss: 0.5912 - learning_rate: 6.7295e-04\n",
            "Epoch 488/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7031 - loss: 0.5501\n",
            "Epoch 488: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5501 - val_accuracy: 0.6729 - val_loss: 0.5947 - learning_rate: 6.7249e-04\n",
            "Epoch 489/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6958 - loss: 0.5566\n",
            "Epoch 489: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6950 - loss: 0.5572 - val_accuracy: 0.6822 - val_loss: 0.6003 - learning_rate: 6.7204e-04\n",
            "Epoch 490/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.5693\n",
            "Epoch 490: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.5693 - val_accuracy: 0.6766 - val_loss: 0.5888 - learning_rate: 6.7159e-04\n",
            "Epoch 491/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6786 - loss: 0.5564\n",
            "Epoch 491: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6782 - loss: 0.5569 - val_accuracy: 0.6822 - val_loss: 0.6027 - learning_rate: 6.7114e-04\n",
            "Epoch 492/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5819\n",
            "Epoch 492: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5819 - val_accuracy: 0.6766 - val_loss: 0.6028 - learning_rate: 6.7069e-04\n",
            "Epoch 493/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6803 - loss: 0.5750\n",
            "Epoch 493: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6808 - loss: 0.5744 - val_accuracy: 0.6916 - val_loss: 0.5878 - learning_rate: 6.7024e-04\n",
            "Epoch 494/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5433\n",
            "Epoch 494: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5433 - val_accuracy: 0.6916 - val_loss: 0.5942 - learning_rate: 6.6979e-04\n",
            "Epoch 495/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6634 - loss: 0.5580\n",
            "Epoch 495: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6640 - loss: 0.5580 - val_accuracy: 0.6617 - val_loss: 0.6012 - learning_rate: 6.6934e-04\n",
            "Epoch 496/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5462\n",
            "Epoch 496: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5462 - val_accuracy: 0.6953 - val_loss: 0.6043 - learning_rate: 6.6890e-04\n",
            "Epoch 497/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6802 - loss: 0.5714\n",
            "Epoch 497: val_loss did not improve from 0.58573\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6808 - loss: 0.5709 - val_accuracy: 0.6729 - val_loss: 0.6060 - learning_rate: 6.6845e-04\n",
            "Epoch 498/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7422 - loss: 0.5193\n",
            "Epoch 498: val_loss improved from 0.58573 to 0.58458, saving model to model_1_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7422 - loss: 0.5193 - val_accuracy: 0.6766 - val_loss: 0.5846 - learning_rate: 6.6800e-04\n",
            "Epoch 499/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6775 - loss: 0.5642\n",
            "Epoch 499: val_loss did not improve from 0.58458\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6776 - loss: 0.5645 - val_accuracy: 0.6935 - val_loss: 0.5957 - learning_rate: 6.6756e-04\n",
            "Epoch 500/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.4604\n",
            "Epoch 500: val_loss did not improve from 0.58458\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.4604 - val_accuracy: 0.6897 - val_loss: 0.5990 - learning_rate: 6.6711e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# History of accuracy and loss\n",
        "tra_loss_1 = history_1.history['loss']\n",
        "tra_acc_1 = history_1.history['accuracy']\n",
        "val_loss_1 = history_1.history['val_loss']\n",
        "val_acc_1 = history_1.history['val_accuracy']\n",
        "\n",
        "# Total number of epochs training\n",
        "epochs_1 = range(1, len(tra_acc_1)+1)\n",
        "end_epoch_1 = len(tra_acc_1)\n",
        "\n",
        "# Epoch when reached the validation loss minimum\n",
        "opt_epoch_1 = val_loss_1.index(min(val_loss_1)) + 1\n",
        "\n",
        "# Loss and accuracy on the validation set\n",
        "end_val_loss_1 = val_loss_1[-1]\n",
        "end_val_acc_1 = val_acc_1[-1]\n",
        "opt_val_loss_1 = val_loss_1[opt_epoch_1-1]\n",
        "opt_val_acc_1 = val_acc_1[opt_epoch_1-1]\n",
        "\n",
        "# Loss and accuracy on the test set\n",
        "opt_model_1 = models.load_model('model_1_benmal_best.keras')  # Load the best model\n",
        "test_loss_1, test_acc_1 = opt_model_1.evaluate(test_images, test_labels, verbose=False)\n",
        "\n",
        "# Predict using the best model\n",
        "opt_pred_1 = opt_model_1.predict(test_images)  # Only pass test images\n",
        "pred_classes_1 = np.rint(opt_pred_1)  # Round predictions to get class labels\n",
        "\n",
        "# Print results\n",
        "print(\"Model 1\\n\")\n",
        "\n",
        "print(\"Epoch [end]: %d\" % end_epoch_1)\n",
        "print(\"Epoch [opt]: %d\" % opt_epoch_1)\n",
        "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_1)\n",
        "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_1)\n",
        "print(\"Test accuracy [end]:  %.4f\" % test_acc_1)\n",
        "print(\"Test accuracy [opt]:  %.4f\" % test_acc_1)  # This should be the same as test_acc_1 for 'opt_model_1'\n",
        "print(\"Valid loss [end]: %.4f\" % end_val_loss_1)\n",
        "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_1)\n",
        "print(\"Test loss [end]:  %.4f\" % test_loss_1)\n",
        "print(\"Test loss [opt]:  %.4f\" % test_loss_1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_labels, pred_classes_1, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiKHplB6jspW",
        "outputId": "624e1579-7649-447c-b91c-7b4b58b86177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
            "Model 1\n",
            "\n",
            "Epoch [end]: 500\n",
            "Epoch [opt]: 498\n",
            "Valid accuracy [end]: 0.6897\n",
            "Valid accuracy [opt]: 0.6766\n",
            "Test accuracy [end]:  0.6667\n",
            "Test accuracy [opt]:  0.6667\n",
            "Valid loss [end]: 0.5990\n",
            "Valid loss [opt]: 0.5846\n",
            "Test loss [end]:  0.6116\n",
            "Test loss [opt]:  0.6116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7421    0.7489    0.7455       219\n",
            "           1     0.5217    0.5128    0.5172       117\n",
            "\n",
            "    accuracy                         0.6667       336\n",
            "   macro avg     0.6319    0.6308    0.6313       336\n",
            "weighted avg     0.6654    0.6667    0.6660       336\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Model 1 Accuracy\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 1 Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(epochs_1, tra_acc_1, 'r', label='Training Set')\n",
        "plt.plot(epochs_1, val_acc_1, 'g', label='Validation Set')\n",
        "\n",
        "# Mark optimal epoch with a green dot\n",
        "plt.plot(opt_epoch_1, val_acc_1[opt_epoch_1-1], 'go', markersize=8, label='Optimal Epoch')\n",
        "\n",
        "# Add dashed vertical line for optimal epoch\n",
        "plt.vlines(opt_epoch_1, min(val_acc_1), opt_val_acc_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "\n",
        "# Add dashed horizontal line for optimal validation accuracy\n",
        "plt.hlines(opt_val_acc_1, 1, opt_epoch_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "# Plotting Model 1 Loss\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 1 Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(epochs_1, tra_loss_1, 'r', label='Training Set')\n",
        "plt.plot(epochs_1, val_loss_1, 'g', label='Validation Set')\n",
        "\n",
        "# Mark optimal epoch with a green dot\n",
        "plt.plot(opt_epoch_1, val_loss_1[opt_epoch_1-1], 'go', markersize=8, label='Optimal Epoch')\n",
        "\n",
        "# Add dashed vertical line for optimal epoch\n",
        "plt.vlines(opt_epoch_1, min(val_loss_1), opt_val_loss_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "\n",
        "# Add dashed horizontal line for optimal validation loss\n",
        "plt.hlines(opt_val_loss_1, 1, opt_epoch_1, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x6DrD-v6jsmZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8efa3017-4a46-4e0f-8e1f-3923fd4995ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model 2 architecture\n",
        "model_2 = models.Sequential([\n",
        "    layers.Input(shape=(150, 150, 1)),  # Input layer\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Print summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "OmO9-rhbjsja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "2d5e59ec-11f3-4939-f769-d97b95eda424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m640\u001b[0m \n",
              "\n",
              " max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m73,856\u001b[0m \n",
              "\n",
              " max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m295,168\u001b[0m \n",
              "\n",
              " max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73984\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m4,735,040\u001b[0m \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m65\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \n",
              "\n",
              " max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
              "\n",
              " max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
              "\n",
              " max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73984</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,040</span> \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,104,769\u001b[0m (19.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,104,769</span> (19.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,104,769\u001b[0m (19.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,104,769</span> (19.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping (stop training after the validation loss reaches the minimum)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=80, verbose=1)\n",
        "\n",
        "# Callback for checkpointing\n",
        "checkpoint = ModelCheckpoint('model_2_benmal_best.keras',\n",
        "                             monitor='val_loss', mode='min', verbose=1,\n",
        "                             save_best_only=True, save_freq='epoch')\n",
        "# Custom decay function to match RMSprop's decay behavior\n",
        "def lr_decay(epoch, lr):\n",
        "    initial_lr = 0.001  # Your initial learning rate\n",
        "    decay_rate = 1e-3  # Same decay as in RMSprop\n",
        "    return initial_lr * (1 / (1 + decay_rate * epoch))\n",
        "\n",
        "# Use the custom decay in the LearningRateScheduler\n",
        "lr_scheduler = LearningRateScheduler(lr_decay)\n",
        "\n",
        "# Compile the model with the updated optimizer using the learning rate schedule\n",
        "model_2.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "                loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_2 = model_2.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=int(0.8 * n_train_img) // 128,\n",
        "    epochs=500,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[checkpoint, earlystopping, lr_scheduler],  # Include both callbacks\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    initial_epoch=0\n",
        ")\n",
        "\n",
        "# Save the final model after training\n",
        "model_2.save('model_2_benmal_end.keras')\n",
        "\n",
        "# Optionally copy the model to Google Drive (if using Colab)\n",
        "!cp model* \"/content/drive/My Drive/FYP_Project/models/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShJhhYDWrQ7a",
        "outputId": "ef17d58e-183a-45a2-d9b9-a7ee0a379d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.5313 - loss: 0.7294\n",
            "Epoch 1: val_loss improved from inf to 0.68693, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - accuracy: 0.5334 - loss: 0.7281 - val_accuracy: 0.5720 - val_loss: 0.6869 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5625 - loss: 0.6854"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 0.68693 to 0.68550, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5625 - loss: 0.6854 - val_accuracy: 0.5720 - val_loss: 0.6855 - learning_rate: 9.9900e-04\n",
            "Epoch 3/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.5893 - loss: 0.6798\n",
            "Epoch 3: val_loss improved from 0.68550 to 0.68148, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.5894 - loss: 0.6798 - val_accuracy: 0.5720 - val_loss: 0.6815 - learning_rate: 9.9800e-04\n",
            "Epoch 4/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5703 - loss: 0.6813\n",
            "Epoch 4: val_loss improved from 0.68148 to 0.68024, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5703 - loss: 0.6813 - val_accuracy: 0.5720 - val_loss: 0.6802 - learning_rate: 9.9701e-04\n",
            "Epoch 5/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5943 - loss: 0.6836\n",
            "Epoch 5: val_loss improved from 0.68024 to 0.67716, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.5940 - loss: 0.6841 - val_accuracy: 0.5720 - val_loss: 0.6772 - learning_rate: 9.9602e-04\n",
            "Epoch 6/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6720\n",
            "Epoch 6: val_loss improved from 0.67716 to 0.67508, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.5781 - loss: 0.6720 - val_accuracy: 0.5720 - val_loss: 0.6751 - learning_rate: 9.9502e-04\n",
            "Epoch 7/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.5951 - loss: 0.6759\n",
            "Epoch 7: val_loss did not improve from 0.67508\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.5947 - loss: 0.6763 - val_accuracy: 0.5720 - val_loss: 0.6799 - learning_rate: 9.9404e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6761\n",
            "Epoch 8: val_loss did not improve from 0.67508\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5938 - loss: 0.6761 - val_accuracy: 0.5720 - val_loss: 0.6773 - learning_rate: 9.9305e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5987 - loss: 0.6748\n",
            "Epoch 9: val_loss improved from 0.67508 to 0.67347, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.5983 - loss: 0.6748 - val_accuracy: 0.5720 - val_loss: 0.6735 - learning_rate: 9.9206e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5469 - loss: 0.6811\n",
            "Epoch 10: val_loss improved from 0.67347 to 0.67311, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5469 - loss: 0.6811 - val_accuracy: 0.5720 - val_loss: 0.6731 - learning_rate: 9.9108e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.5759 - loss: 0.6694\n",
            "Epoch 11: val_loss did not improve from 0.67311\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.5765 - loss: 0.6694 - val_accuracy: 0.5720 - val_loss: 0.6848 - learning_rate: 9.9010e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6687\n",
            "Epoch 12: val_loss improved from 0.67311 to 0.66856, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6328 - loss: 0.6687 - val_accuracy: 0.5720 - val_loss: 0.6686 - learning_rate: 9.8912e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.5951 - loss: 0.6669\n",
            "Epoch 13: val_loss improved from 0.66856 to 0.66697, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.5945 - loss: 0.6669 - val_accuracy: 0.6056 - val_loss: 0.6670 - learning_rate: 9.8814e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5391 - loss: 0.6950\n",
            "Epoch 14: val_loss did not improve from 0.66697\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5391 - loss: 0.6950 - val_accuracy: 0.5757 - val_loss: 0.6671 - learning_rate: 9.8717e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6079 - loss: 0.6653\n",
            "Epoch 15: val_loss improved from 0.66697 to 0.66358, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6076 - loss: 0.6653 - val_accuracy: 0.5813 - val_loss: 0.6636 - learning_rate: 9.8619e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6572\n",
            "Epoch 16: val_loss did not improve from 0.66358\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6016 - loss: 0.6572 - val_accuracy: 0.5869 - val_loss: 0.6674 - learning_rate: 9.8522e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5914 - loss: 0.6616\n",
            "Epoch 17: val_loss improved from 0.66358 to 0.66335, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.5915 - loss: 0.6616 - val_accuracy: 0.5720 - val_loss: 0.6633 - learning_rate: 9.8425e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6529\n",
            "Epoch 18: val_loss improved from 0.66335 to 0.65980, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5859 - loss: 0.6529 - val_accuracy: 0.5925 - val_loss: 0.6598 - learning_rate: 9.8328e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6005 - loss: 0.6601\n",
            "Epoch 19: val_loss did not improve from 0.65980\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.5996 - loss: 0.6605 - val_accuracy: 0.5738 - val_loss: 0.6651 - learning_rate: 9.8232e-04\n",
            "Epoch 20/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5547 - loss: 0.6661\n",
            "Epoch 20: val_loss improved from 0.65980 to 0.65975, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.5547 - loss: 0.6661 - val_accuracy: 0.5757 - val_loss: 0.6597 - learning_rate: 9.8135e-04\n",
            "Epoch 21/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5848 - loss: 0.6649\n",
            "Epoch 21: val_loss improved from 0.65975 to 0.65720, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.5850 - loss: 0.6649 - val_accuracy: 0.5738 - val_loss: 0.6572 - learning_rate: 9.8039e-04\n",
            "Epoch 22/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6366\n",
            "Epoch 22: val_loss did not improve from 0.65720\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.6366 - val_accuracy: 0.5720 - val_loss: 0.6614 - learning_rate: 9.7943e-04\n",
            "Epoch 23/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5923 - loss: 0.6566\n",
            "Epoch 23: val_loss did not improve from 0.65720\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.5925 - loss: 0.6569 - val_accuracy: 0.5869 - val_loss: 0.6585 - learning_rate: 9.7847e-04\n",
            "Epoch 24/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6314\n",
            "Epoch 24: val_loss did not improve from 0.65720\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6484 - loss: 0.6314 - val_accuracy: 0.5720 - val_loss: 0.6707 - learning_rate: 9.7752e-04\n",
            "Epoch 25/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6139 - loss: 0.6532\n",
            "Epoch 25: val_loss did not improve from 0.65720\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6145 - loss: 0.6531 - val_accuracy: 0.5850 - val_loss: 0.6638 - learning_rate: 9.7656e-04\n",
            "Epoch 26/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6583\n",
            "Epoch 26: val_loss did not improve from 0.65720\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5781 - loss: 0.6583 - val_accuracy: 0.5794 - val_loss: 0.6627 - learning_rate: 9.7561e-04\n",
            "Epoch 27/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6200 - loss: 0.6581\n",
            "Epoch 27: val_loss improved from 0.65720 to 0.65194, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6198 - loss: 0.6580 - val_accuracy: 0.6019 - val_loss: 0.6519 - learning_rate: 9.7466e-04\n",
            "Epoch 28/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6265\n",
            "Epoch 28: val_loss improved from 0.65194 to 0.64620, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6250 - loss: 0.6265 - val_accuracy: 0.6523 - val_loss: 0.6462 - learning_rate: 9.7371e-04\n",
            "Epoch 29/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6366 - loss: 0.6467\n",
            "Epoch 29: val_loss improved from 0.64620 to 0.64531, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 284ms/step - accuracy: 0.6364 - loss: 0.6470 - val_accuracy: 0.6318 - val_loss: 0.6453 - learning_rate: 9.7276e-04\n",
            "Epoch 30/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6372\n",
            "Epoch 30: val_loss did not improve from 0.64531\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6372 - val_accuracy: 0.6000 - val_loss: 0.6457 - learning_rate: 9.7182e-04\n",
            "Epoch 31/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6057 - loss: 0.6632\n",
            "Epoch 31: val_loss did not improve from 0.64531\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6069 - loss: 0.6626 - val_accuracy: 0.6299 - val_loss: 0.6466 - learning_rate: 9.7087e-04\n",
            "Epoch 32/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6384\n",
            "Epoch 32: val_loss improved from 0.64531 to 0.64341, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5938 - loss: 0.6384 - val_accuracy: 0.6262 - val_loss: 0.6434 - learning_rate: 9.6993e-04\n",
            "Epoch 33/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6156 - loss: 0.6500\n",
            "Epoch 33: val_loss did not improve from 0.64341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6156 - loss: 0.6502 - val_accuracy: 0.6168 - val_loss: 0.6563 - learning_rate: 9.6899e-04\n",
            "Epoch 34/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6293\n",
            "Epoch 34: val_loss did not improve from 0.64341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6293 - val_accuracy: 0.5925 - val_loss: 0.6513 - learning_rate: 9.6805e-04\n",
            "Epoch 35/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6214 - loss: 0.6586\n",
            "Epoch 35: val_loss did not improve from 0.64341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6220 - loss: 0.6580 - val_accuracy: 0.6019 - val_loss: 0.6510 - learning_rate: 9.6712e-04\n",
            "Epoch 36/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6841\n",
            "Epoch 36: val_loss did not improve from 0.64341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6841 - val_accuracy: 0.6112 - val_loss: 0.6482 - learning_rate: 9.6618e-04\n",
            "Epoch 37/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6399 - loss: 0.6407\n",
            "Epoch 37: val_loss did not improve from 0.64341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6398 - loss: 0.6408 - val_accuracy: 0.6280 - val_loss: 0.6462 - learning_rate: 9.6525e-04\n",
            "Epoch 38/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5860\n",
            "Epoch 38: val_loss did not improve from 0.64341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5860 - val_accuracy: 0.6336 - val_loss: 0.6445 - learning_rate: 9.6432e-04\n",
            "Epoch 39/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6223 - loss: 0.6468\n",
            "Epoch 39: val_loss improved from 0.64341 to 0.63854, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6216 - loss: 0.6468 - val_accuracy: 0.6318 - val_loss: 0.6385 - learning_rate: 9.6339e-04\n",
            "Epoch 40/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6391\n",
            "Epoch 40: val_loss did not improve from 0.63854\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6391 - val_accuracy: 0.6299 - val_loss: 0.6470 - learning_rate: 9.6246e-04\n",
            "Epoch 41/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6392 - loss: 0.6408\n",
            "Epoch 41: val_loss did not improve from 0.63854\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6390 - loss: 0.6407 - val_accuracy: 0.6411 - val_loss: 0.6434 - learning_rate: 9.6154e-04\n",
            "Epoch 42/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6414\n",
            "Epoch 42: val_loss did not improve from 0.63854\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6414 - val_accuracy: 0.6336 - val_loss: 0.6427 - learning_rate: 9.6061e-04\n",
            "Epoch 43/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6049 - loss: 0.6488\n",
            "Epoch 43: val_loss did not improve from 0.63854\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6060 - loss: 0.6484 - val_accuracy: 0.5963 - val_loss: 0.6454 - learning_rate: 9.5969e-04\n",
            "Epoch 44/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6572\n",
            "Epoch 44: val_loss did not improve from 0.63854\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6572 - val_accuracy: 0.6168 - val_loss: 0.6407 - learning_rate: 9.5877e-04\n",
            "Epoch 45/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6236 - loss: 0.6447\n",
            "Epoch 45: val_loss did not improve from 0.63854\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6237 - loss: 0.6447 - val_accuracy: 0.5832 - val_loss: 0.6558 - learning_rate: 9.5785e-04\n",
            "Epoch 46/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5312 - loss: 0.7037\n",
            "Epoch 46: val_loss did not improve from 0.63854\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5312 - loss: 0.7037 - val_accuracy: 0.6262 - val_loss: 0.6441 - learning_rate: 9.5694e-04\n",
            "Epoch 47/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6142 - loss: 0.6432\n",
            "Epoch 47: val_loss improved from 0.63854 to 0.63829, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.6149 - loss: 0.6432 - val_accuracy: 0.6393 - val_loss: 0.6383 - learning_rate: 9.5602e-04\n",
            "Epoch 48/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.6172\n",
            "Epoch 48: val_loss improved from 0.63829 to 0.63806, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7109 - loss: 0.6172 - val_accuracy: 0.6187 - val_loss: 0.6381 - learning_rate: 9.5511e-04\n",
            "Epoch 49/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6306 - loss: 0.6442\n",
            "Epoch 49: val_loss did not improve from 0.63806\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6305 - loss: 0.6440 - val_accuracy: 0.6262 - val_loss: 0.6430 - learning_rate: 9.5420e-04\n",
            "Epoch 50/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5883\n",
            "Epoch 50: val_loss did not improve from 0.63806\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5883 - val_accuracy: 0.6393 - val_loss: 0.6435 - learning_rate: 9.5329e-04\n",
            "Epoch 51/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6218 - loss: 0.6446\n",
            "Epoch 51: val_loss improved from 0.63806 to 0.63341, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6229 - loss: 0.6441 - val_accuracy: 0.6262 - val_loss: 0.6334 - learning_rate: 9.5238e-04\n",
            "Epoch 52/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6648\n",
            "Epoch 52: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.6648 - val_accuracy: 0.5907 - val_loss: 0.6490 - learning_rate: 9.5147e-04\n",
            "Epoch 53/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6343 - loss: 0.6379\n",
            "Epoch 53: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6341 - loss: 0.6381 - val_accuracy: 0.6336 - val_loss: 0.6409 - learning_rate: 9.5057e-04\n",
            "Epoch 54/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.6009\n",
            "Epoch 54: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.6009 - val_accuracy: 0.6131 - val_loss: 0.6388 - learning_rate: 9.4967e-04\n",
            "Epoch 55/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6349 - loss: 0.6422\n",
            "Epoch 55: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6348 - loss: 0.6421 - val_accuracy: 0.6336 - val_loss: 0.6366 - learning_rate: 9.4877e-04\n",
            "Epoch 56/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7031 - loss: 0.6166\n",
            "Epoch 56: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.6166 - val_accuracy: 0.6336 - val_loss: 0.6419 - learning_rate: 9.4787e-04\n",
            "Epoch 57/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6460 - loss: 0.6259\n",
            "Epoch 57: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6457 - loss: 0.6264 - val_accuracy: 0.6131 - val_loss: 0.6373 - learning_rate: 9.4697e-04\n",
            "Epoch 58/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5591 - loss: 0.6713\n",
            "Epoch 58: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5591 - loss: 0.6713 - val_accuracy: 0.5981 - val_loss: 0.6482 - learning_rate: 9.4607e-04\n",
            "Epoch 59/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6268 - loss: 0.6400\n",
            "Epoch 59: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6269 - loss: 0.6398 - val_accuracy: 0.6056 - val_loss: 0.6415 - learning_rate: 9.4518e-04\n",
            "Epoch 60/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6596\n",
            "Epoch 60: val_loss did not improve from 0.63341\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6016 - loss: 0.6596 - val_accuracy: 0.6224 - val_loss: 0.6370 - learning_rate: 9.4429e-04\n",
            "Epoch 61/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6165 - loss: 0.6508\n",
            "Epoch 61: val_loss improved from 0.63341 to 0.63315, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6170 - loss: 0.6504 - val_accuracy: 0.6355 - val_loss: 0.6331 - learning_rate: 9.4340e-04\n",
            "Epoch 62/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5776\n",
            "Epoch 62: val_loss did not improve from 0.63315\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5776 - val_accuracy: 0.6019 - val_loss: 0.6779 - learning_rate: 9.4251e-04\n",
            "Epoch 63/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6449 - loss: 0.6324\n",
            "Epoch 63: val_loss did not improve from 0.63315\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6445 - loss: 0.6326 - val_accuracy: 0.6467 - val_loss: 0.6341 - learning_rate: 9.4162e-04\n",
            "Epoch 64/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6176\n",
            "Epoch 64: val_loss did not improve from 0.63315\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6176 - val_accuracy: 0.6374 - val_loss: 0.6398 - learning_rate: 9.4073e-04\n",
            "Epoch 65/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6228 - loss: 0.6444\n",
            "Epoch 65: val_loss did not improve from 0.63315\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6229 - loss: 0.6442 - val_accuracy: 0.6299 - val_loss: 0.6340 - learning_rate: 9.3985e-04\n",
            "Epoch 66/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.6338\n",
            "Epoch 66: val_loss improved from 0.63315 to 0.63310, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6484 - loss: 0.6338 - val_accuracy: 0.6393 - val_loss: 0.6331 - learning_rate: 9.3897e-04\n",
            "Epoch 67/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6483 - loss: 0.6250\n",
            "Epoch 67: val_loss did not improve from 0.63310\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6478 - loss: 0.6256 - val_accuracy: 0.6000 - val_loss: 0.6385 - learning_rate: 9.3809e-04\n",
            "Epoch 68/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5703 - loss: 0.6522\n",
            "Epoch 68: val_loss did not improve from 0.63310\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5703 - loss: 0.6522 - val_accuracy: 0.5981 - val_loss: 0.6384 - learning_rate: 9.3721e-04\n",
            "Epoch 69/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6287 - loss: 0.6342\n",
            "Epoch 69: val_loss improved from 0.63310 to 0.63213, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6292 - loss: 0.6339 - val_accuracy: 0.6280 - val_loss: 0.6321 - learning_rate: 9.3633e-04\n",
            "Epoch 70/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6035\n",
            "Epoch 70: val_loss improved from 0.63213 to 0.63144, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6797 - loss: 0.6035 - val_accuracy: 0.6355 - val_loss: 0.6314 - learning_rate: 9.3545e-04\n",
            "Epoch 71/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6420 - loss: 0.6189\n",
            "Epoch 71: val_loss did not improve from 0.63144\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6415 - loss: 0.6196 - val_accuracy: 0.6467 - val_loss: 0.6339 - learning_rate: 9.3458e-04\n",
            "Epoch 72/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6212\n",
            "Epoch 72: val_loss improved from 0.63144 to 0.63053, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6797 - loss: 0.6212 - val_accuracy: 0.6430 - val_loss: 0.6305 - learning_rate: 9.3371e-04\n",
            "Epoch 73/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6305 - loss: 0.6353\n",
            "Epoch 73: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6310 - loss: 0.6351 - val_accuracy: 0.6318 - val_loss: 0.6375 - learning_rate: 9.3284e-04\n",
            "Epoch 74/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5806 - loss: 0.6678\n",
            "Epoch 74: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5806 - loss: 0.6678 - val_accuracy: 0.6168 - val_loss: 0.6352 - learning_rate: 9.3197e-04\n",
            "Epoch 75/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6273 - loss: 0.6440\n",
            "Epoch 75: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6275 - loss: 0.6437 - val_accuracy: 0.6056 - val_loss: 0.6372 - learning_rate: 9.3110e-04\n",
            "Epoch 76/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6456\n",
            "Epoch 76: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6456 - val_accuracy: 0.6411 - val_loss: 0.6374 - learning_rate: 9.3023e-04\n",
            "Epoch 77/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6587 - loss: 0.6270\n",
            "Epoch 77: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6573 - loss: 0.6275 - val_accuracy: 0.6374 - val_loss: 0.6315 - learning_rate: 9.2937e-04\n",
            "Epoch 78/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6234\n",
            "Epoch 78: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6234 - val_accuracy: 0.6336 - val_loss: 0.6340 - learning_rate: 9.2851e-04\n",
            "Epoch 79/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6524 - loss: 0.6121\n",
            "Epoch 79: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6514 - loss: 0.6131 - val_accuracy: 0.6168 - val_loss: 0.6312 - learning_rate: 9.2764e-04\n",
            "Epoch 80/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6448\n",
            "Epoch 80: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6448 - val_accuracy: 0.6430 - val_loss: 0.6328 - learning_rate: 9.2678e-04\n",
            "Epoch 81/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6586 - loss: 0.6204\n",
            "Epoch 81: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6579 - loss: 0.6209 - val_accuracy: 0.6318 - val_loss: 0.6346 - learning_rate: 9.2593e-04\n",
            "Epoch 82/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6303\n",
            "Epoch 82: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6303 - val_accuracy: 0.6318 - val_loss: 0.6371 - learning_rate: 9.2507e-04\n",
            "Epoch 83/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6329 - loss: 0.6291\n",
            "Epoch 83: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6328 - loss: 0.6292 - val_accuracy: 0.6112 - val_loss: 0.6379 - learning_rate: 9.2421e-04\n",
            "Epoch 84/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6135\n",
            "Epoch 84: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6135 - val_accuracy: 0.6243 - val_loss: 0.6428 - learning_rate: 9.2336e-04\n",
            "Epoch 85/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6311 - loss: 0.6361\n",
            "Epoch 85: val_loss did not improve from 0.63053\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6311 - loss: 0.6360 - val_accuracy: 0.6336 - val_loss: 0.6368 - learning_rate: 9.2251e-04\n",
            "Epoch 86/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.6032\n",
            "Epoch 86: val_loss improved from 0.63053 to 0.62658, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6406 - loss: 0.6032 - val_accuracy: 0.6187 - val_loss: 0.6266 - learning_rate: 9.2166e-04\n",
            "Epoch 87/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6221 - loss: 0.6318\n",
            "Epoch 87: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6225 - loss: 0.6317 - val_accuracy: 0.6355 - val_loss: 0.6306 - learning_rate: 9.2081e-04\n",
            "Epoch 88/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6087\n",
            "Epoch 88: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6087 - val_accuracy: 0.6262 - val_loss: 0.6288 - learning_rate: 9.1996e-04\n",
            "Epoch 89/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6600 - loss: 0.6232\n",
            "Epoch 89: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6595 - loss: 0.6232 - val_accuracy: 0.6224 - val_loss: 0.6340 - learning_rate: 9.1912e-04\n",
            "Epoch 90/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5469 - loss: 0.7172\n",
            "Epoch 90: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5469 - loss: 0.7172 - val_accuracy: 0.6374 - val_loss: 0.6309 - learning_rate: 9.1827e-04\n",
            "Epoch 91/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6402 - loss: 0.6238\n",
            "Epoch 91: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6402 - loss: 0.6242 - val_accuracy: 0.6150 - val_loss: 0.6374 - learning_rate: 9.1743e-04\n",
            "Epoch 92/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6220\n",
            "Epoch 92: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6220 - val_accuracy: 0.6206 - val_loss: 0.6296 - learning_rate: 9.1659e-04\n",
            "Epoch 93/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6282 - loss: 0.6314\n",
            "Epoch 93: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6284 - loss: 0.6313 - val_accuracy: 0.6280 - val_loss: 0.6311 - learning_rate: 9.1575e-04\n",
            "Epoch 94/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.6342\n",
            "Epoch 94: val_loss did not improve from 0.62658\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6342 - val_accuracy: 0.5832 - val_loss: 0.6419 - learning_rate: 9.1491e-04\n",
            "Epoch 95/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6419 - loss: 0.6170\n",
            "Epoch 95: val_loss improved from 0.62658 to 0.62186, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6417 - loss: 0.6172 - val_accuracy: 0.6355 - val_loss: 0.6219 - learning_rate: 9.1408e-04\n",
            "Epoch 96/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6452\n",
            "Epoch 96: val_loss did not improve from 0.62186\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6452 - val_accuracy: 0.6430 - val_loss: 0.6269 - learning_rate: 9.1324e-04\n",
            "Epoch 97/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6420 - loss: 0.6246\n",
            "Epoch 97: val_loss did not improve from 0.62186\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6424 - loss: 0.6244 - val_accuracy: 0.6224 - val_loss: 0.6325 - learning_rate: 9.1241e-04\n",
            "Epoch 98/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6242\n",
            "Epoch 98: val_loss did not improve from 0.62186\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5859 - loss: 0.6242 - val_accuracy: 0.6224 - val_loss: 0.6359 - learning_rate: 9.1158e-04\n",
            "Epoch 99/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6348 - loss: 0.6252\n",
            "Epoch 99: val_loss did not improve from 0.62186\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6356 - loss: 0.6253 - val_accuracy: 0.6374 - val_loss: 0.6350 - learning_rate: 9.1075e-04\n",
            "Epoch 100/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5781 - loss: 0.6628\n",
            "Epoch 100: val_loss did not improve from 0.62186\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5781 - loss: 0.6628 - val_accuracy: 0.6168 - val_loss: 0.6265 - learning_rate: 9.0992e-04\n",
            "Epoch 101/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6566 - loss: 0.6219\n",
            "Epoch 101: val_loss did not improve from 0.62186\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6561 - loss: 0.6219 - val_accuracy: 0.6355 - val_loss: 0.6237 - learning_rate: 9.0909e-04\n",
            "Epoch 102/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6134\n",
            "Epoch 102: val_loss improved from 0.62186 to 0.62141, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6875 - loss: 0.6134 - val_accuracy: 0.6355 - val_loss: 0.6214 - learning_rate: 9.0827e-04\n",
            "Epoch 103/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6100 - loss: 0.6372\n",
            "Epoch 103: val_loss did not improve from 0.62141\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6111 - loss: 0.6370 - val_accuracy: 0.6523 - val_loss: 0.6236 - learning_rate: 9.0744e-04\n",
            "Epoch 104/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6327\n",
            "Epoch 104: val_loss did not improve from 0.62141\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6327 - val_accuracy: 0.6486 - val_loss: 0.6214 - learning_rate: 9.0662e-04\n",
            "Epoch 105/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6666 - loss: 0.6193\n",
            "Epoch 105: val_loss did not improve from 0.62141\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6660 - loss: 0.6194 - val_accuracy: 0.6299 - val_loss: 0.6330 - learning_rate: 9.0580e-04\n",
            "Epoch 106/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6535\n",
            "Epoch 106: val_loss did not improve from 0.62141\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6535 - val_accuracy: 0.6374 - val_loss: 0.6255 - learning_rate: 9.0498e-04\n",
            "Epoch 107/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6492 - loss: 0.6227\n",
            "Epoch 107: val_loss did not improve from 0.62141\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6482 - loss: 0.6231 - val_accuracy: 0.6075 - val_loss: 0.6352 - learning_rate: 9.0416e-04\n",
            "Epoch 108/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.6198\n",
            "Epoch 108: val_loss did not improve from 0.62141\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6198 - val_accuracy: 0.6336 - val_loss: 0.6282 - learning_rate: 9.0334e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6454 - loss: 0.6197\n",
            "Epoch 109: val_loss did not improve from 0.62141\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6454 - loss: 0.6197 - val_accuracy: 0.6262 - val_loss: 0.6411 - learning_rate: 9.0253e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6016 - loss: 0.6715\n",
            "Epoch 110: val_loss improved from 0.62141 to 0.61847, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6016 - loss: 0.6715 - val_accuracy: 0.6355 - val_loss: 0.6185 - learning_rate: 9.0171e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6397 - loss: 0.6183\n",
            "Epoch 111: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6403 - loss: 0.6184 - val_accuracy: 0.6542 - val_loss: 0.6226 - learning_rate: 9.0090e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7031 - loss: 0.6259\n",
            "Epoch 112: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.6259 - val_accuracy: 0.6243 - val_loss: 0.6407 - learning_rate: 9.0009e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6536 - loss: 0.6119\n",
            "Epoch 113: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6535 - loss: 0.6124 - val_accuracy: 0.6486 - val_loss: 0.6214 - learning_rate: 8.9928e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6234\n",
            "Epoch 114: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6328 - loss: 0.6234 - val_accuracy: 0.6262 - val_loss: 0.6274 - learning_rate: 8.9847e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6472 - loss: 0.6209\n",
            "Epoch 115: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6468 - loss: 0.6208 - val_accuracy: 0.6168 - val_loss: 0.6270 - learning_rate: 8.9767e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6172 - loss: 0.6515\n",
            "Epoch 116: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6515 - val_accuracy: 0.6206 - val_loss: 0.6272 - learning_rate: 8.9686e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6425 - loss: 0.6303\n",
            "Epoch 117: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6419 - loss: 0.6303 - val_accuracy: 0.6318 - val_loss: 0.6302 - learning_rate: 8.9606e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5814\n",
            "Epoch 118: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7188 - loss: 0.5814 - val_accuracy: 0.6299 - val_loss: 0.6338 - learning_rate: 8.9526e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6683 - loss: 0.6039\n",
            "Epoch 119: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6679 - loss: 0.6051 - val_accuracy: 0.6318 - val_loss: 0.6310 - learning_rate: 8.9445e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6284\n",
            "Epoch 120: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6284 - val_accuracy: 0.6318 - val_loss: 0.6353 - learning_rate: 8.9366e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6522 - loss: 0.6219\n",
            "Epoch 121: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6522 - loss: 0.6218 - val_accuracy: 0.6449 - val_loss: 0.6211 - learning_rate: 8.9286e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.5739\n",
            "Epoch 122: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5739 - val_accuracy: 0.6112 - val_loss: 0.6318 - learning_rate: 8.9206e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6339 - loss: 0.6206\n",
            "Epoch 123: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6341 - loss: 0.6205 - val_accuracy: 0.6336 - val_loss: 0.6281 - learning_rate: 8.9127e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6172\n",
            "Epoch 124: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6172 - val_accuracy: 0.6336 - val_loss: 0.6231 - learning_rate: 8.9047e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6617 - loss: 0.6138\n",
            "Epoch 125: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6609 - loss: 0.6141 - val_accuracy: 0.6393 - val_loss: 0.6236 - learning_rate: 8.8968e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6359\n",
            "Epoch 126: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6359 - val_accuracy: 0.6299 - val_loss: 0.6258 - learning_rate: 8.8889e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6421 - loss: 0.6197\n",
            "Epoch 127: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6422 - loss: 0.6198 - val_accuracy: 0.6318 - val_loss: 0.6233 - learning_rate: 8.8810e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.6351\n",
            "Epoch 128: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.6351 - val_accuracy: 0.6243 - val_loss: 0.6328 - learning_rate: 8.8731e-04\n",
            "Epoch 129/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6472 - loss: 0.6156\n",
            "Epoch 129: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6467 - loss: 0.6158 - val_accuracy: 0.6243 - val_loss: 0.6291 - learning_rate: 8.8652e-04\n",
            "Epoch 130/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6559 - loss: 0.6193\n",
            "Epoch 130: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6559 - loss: 0.6193 - val_accuracy: 0.6093 - val_loss: 0.6383 - learning_rate: 8.8574e-04\n",
            "Epoch 131/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6228 - loss: 0.6239\n",
            "Epoch 131: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6238 - loss: 0.6236 - val_accuracy: 0.6449 - val_loss: 0.6224 - learning_rate: 8.8496e-04\n",
            "Epoch 132/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6197\n",
            "Epoch 132: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6197 - val_accuracy: 0.6355 - val_loss: 0.6264 - learning_rate: 8.8417e-04\n",
            "Epoch 133/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6510 - loss: 0.6133\n",
            "Epoch 133: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6509 - loss: 0.6139 - val_accuracy: 0.6355 - val_loss: 0.6222 - learning_rate: 8.8339e-04\n",
            "Epoch 134/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5949\n",
            "Epoch 134: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5949 - val_accuracy: 0.6467 - val_loss: 0.6199 - learning_rate: 8.8261e-04\n",
            "Epoch 135/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6395 - loss: 0.6209\n",
            "Epoch 135: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6400 - loss: 0.6206 - val_accuracy: 0.6318 - val_loss: 0.6232 - learning_rate: 8.8183e-04\n",
            "Epoch 136/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6217\n",
            "Epoch 136: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6217 - val_accuracy: 0.6224 - val_loss: 0.6285 - learning_rate: 8.8106e-04\n",
            "Epoch 137/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6596 - loss: 0.6164\n",
            "Epoch 137: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6590 - loss: 0.6168 - val_accuracy: 0.6374 - val_loss: 0.6197 - learning_rate: 8.8028e-04\n",
            "Epoch 138/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6480\n",
            "Epoch 138: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5938 - loss: 0.6480 - val_accuracy: 0.6318 - val_loss: 0.6193 - learning_rate: 8.7951e-04\n",
            "Epoch 139/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6601 - loss: 0.6069\n",
            "Epoch 139: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6596 - loss: 0.6075 - val_accuracy: 0.6505 - val_loss: 0.6253 - learning_rate: 8.7873e-04\n",
            "Epoch 140/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6291\n",
            "Epoch 140: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6291 - val_accuracy: 0.6262 - val_loss: 0.6206 - learning_rate: 8.7796e-04\n",
            "Epoch 141/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6513 - loss: 0.6288\n",
            "Epoch 141: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6515 - loss: 0.6283 - val_accuracy: 0.6318 - val_loss: 0.6230 - learning_rate: 8.7719e-04\n",
            "Epoch 142/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6586\n",
            "Epoch 142: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6586 - val_accuracy: 0.6206 - val_loss: 0.6309 - learning_rate: 8.7642e-04\n",
            "Epoch 143/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6522 - loss: 0.6186\n",
            "Epoch 143: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6518 - loss: 0.6186 - val_accuracy: 0.6112 - val_loss: 0.6305 - learning_rate: 8.7566e-04\n",
            "Epoch 144/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6231\n",
            "Epoch 144: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6231 - val_accuracy: 0.6112 - val_loss: 0.6300 - learning_rate: 8.7489e-04\n",
            "Epoch 145/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6384 - loss: 0.6142\n",
            "Epoch 145: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6391 - loss: 0.6140 - val_accuracy: 0.6131 - val_loss: 0.6293 - learning_rate: 8.7413e-04\n",
            "Epoch 146/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.6147\n",
            "Epoch 146: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7344 - loss: 0.6147 - val_accuracy: 0.6318 - val_loss: 0.6293 - learning_rate: 8.7336e-04\n",
            "Epoch 147/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6422 - loss: 0.6211\n",
            "Epoch 147: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6424 - loss: 0.6212 - val_accuracy: 0.6262 - val_loss: 0.6217 - learning_rate: 8.7260e-04\n",
            "Epoch 148/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5811\n",
            "Epoch 148: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5811 - val_accuracy: 0.6374 - val_loss: 0.6238 - learning_rate: 8.7184e-04\n",
            "Epoch 149/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6567 - loss: 0.6149\n",
            "Epoch 149: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6567 - loss: 0.6148 - val_accuracy: 0.6336 - val_loss: 0.6293 - learning_rate: 8.7108e-04\n",
            "Epoch 150/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5312 - loss: 0.7203\n",
            "Epoch 150: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5312 - loss: 0.7203 - val_accuracy: 0.6262 - val_loss: 0.6338 - learning_rate: 8.7032e-04\n",
            "Epoch 151/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6550 - loss: 0.6186\n",
            "Epoch 151: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6550 - loss: 0.6185 - val_accuracy: 0.6299 - val_loss: 0.6277 - learning_rate: 8.6957e-04\n",
            "Epoch 152/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6406\n",
            "Epoch 152: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6406 - val_accuracy: 0.6299 - val_loss: 0.6315 - learning_rate: 8.6881e-04\n",
            "Epoch 153/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6402 - loss: 0.6228\n",
            "Epoch 153: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6406 - loss: 0.6224 - val_accuracy: 0.6467 - val_loss: 0.6201 - learning_rate: 8.6806e-04\n",
            "Epoch 154/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6062\n",
            "Epoch 154: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6062 - val_accuracy: 0.6299 - val_loss: 0.6236 - learning_rate: 8.6730e-04\n",
            "Epoch 155/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6565 - loss: 0.6096\n",
            "Epoch 155: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6565 - loss: 0.6098 - val_accuracy: 0.6467 - val_loss: 0.6221 - learning_rate: 8.6655e-04\n",
            "Epoch 156/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5547 - loss: 0.6342\n",
            "Epoch 156: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5547 - loss: 0.6342 - val_accuracy: 0.6505 - val_loss: 0.6256 - learning_rate: 8.6580e-04\n",
            "Epoch 157/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6413 - loss: 0.6199\n",
            "Epoch 157: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6415 - loss: 0.6198 - val_accuracy: 0.6355 - val_loss: 0.6217 - learning_rate: 8.6505e-04\n",
            "Epoch 158/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6143\n",
            "Epoch 158: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6143 - val_accuracy: 0.6224 - val_loss: 0.6307 - learning_rate: 8.6430e-04\n",
            "Epoch 159/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6410 - loss: 0.6308\n",
            "Epoch 159: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6410 - loss: 0.6302 - val_accuracy: 0.6280 - val_loss: 0.6244 - learning_rate: 8.6356e-04\n",
            "Epoch 160/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6044\n",
            "Epoch 160: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6044 - val_accuracy: 0.6280 - val_loss: 0.6247 - learning_rate: 8.6281e-04\n",
            "Epoch 161/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6452 - loss: 0.6154\n",
            "Epoch 161: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6456 - loss: 0.6153 - val_accuracy: 0.6355 - val_loss: 0.6217 - learning_rate: 8.6207e-04\n",
            "Epoch 162/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6147\n",
            "Epoch 162: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6147 - val_accuracy: 0.6449 - val_loss: 0.6189 - learning_rate: 8.6133e-04\n",
            "Epoch 163/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6654 - loss: 0.6050\n",
            "Epoch 163: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6646 - loss: 0.6054 - val_accuracy: 0.6131 - val_loss: 0.6277 - learning_rate: 8.6059e-04\n",
            "Epoch 164/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6488\n",
            "Epoch 164: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6488 - val_accuracy: 0.6355 - val_loss: 0.6271 - learning_rate: 8.5985e-04\n",
            "Epoch 165/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6538 - loss: 0.6153\n",
            "Epoch 165: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6532 - loss: 0.6153 - val_accuracy: 0.6206 - val_loss: 0.6247 - learning_rate: 8.5911e-04\n",
            "Epoch 166/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6953 - loss: 0.5997\n",
            "Epoch 166: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5997 - val_accuracy: 0.6187 - val_loss: 0.6245 - learning_rate: 8.5837e-04\n",
            "Epoch 167/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6530 - loss: 0.6141\n",
            "Epoch 167: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6532 - loss: 0.6139 - val_accuracy: 0.6336 - val_loss: 0.6242 - learning_rate: 8.5763e-04\n",
            "Epoch 168/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6094 - loss: 0.6105\n",
            "Epoch 168: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.6105 - val_accuracy: 0.6131 - val_loss: 0.6381 - learning_rate: 8.5690e-04\n",
            "Epoch 169/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6565 - loss: 0.6196\n",
            "Epoch 169: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6564 - loss: 0.6197 - val_accuracy: 0.6374 - val_loss: 0.6244 - learning_rate: 8.5616e-04\n",
            "Epoch 170/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6145\n",
            "Epoch 170: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6145 - val_accuracy: 0.6430 - val_loss: 0.6237 - learning_rate: 8.5543e-04\n",
            "Epoch 171/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6487 - loss: 0.6103\n",
            "Epoch 171: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6495 - loss: 0.6101 - val_accuracy: 0.5981 - val_loss: 0.6282 - learning_rate: 8.5470e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5469 - loss: 0.6700\n",
            "Epoch 172: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5469 - loss: 0.6700 - val_accuracy: 0.6374 - val_loss: 0.6248 - learning_rate: 8.5397e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6630 - loss: 0.6070\n",
            "Epoch 173: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6626 - loss: 0.6071 - val_accuracy: 0.6280 - val_loss: 0.6266 - learning_rate: 8.5324e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6278\n",
            "Epoch 174: val_loss did not improve from 0.61847\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6278 - val_accuracy: 0.6486 - val_loss: 0.6191 - learning_rate: 8.5251e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6546 - loss: 0.6062\n",
            "Epoch 175: val_loss improved from 0.61847 to 0.61787, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.6544 - loss: 0.6065 - val_accuracy: 0.6355 - val_loss: 0.6179 - learning_rate: 8.5179e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5916\n",
            "Epoch 176: val_loss did not improve from 0.61787\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5916 - val_accuracy: 0.6168 - val_loss: 0.6265 - learning_rate: 8.5106e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6589 - loss: 0.6004\n",
            "Epoch 177: val_loss did not improve from 0.61787\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6588 - loss: 0.6007 - val_accuracy: 0.6411 - val_loss: 0.6224 - learning_rate: 8.5034e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6184\n",
            "Epoch 178: val_loss did not improve from 0.61787\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6184 - val_accuracy: 0.6093 - val_loss: 0.6394 - learning_rate: 8.4962e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6483 - loss: 0.6169\n",
            "Epoch 179: val_loss improved from 0.61787 to 0.61538, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6485 - loss: 0.6166 - val_accuracy: 0.6561 - val_loss: 0.6154 - learning_rate: 8.4890e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5904\n",
            "Epoch 180: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5904 - val_accuracy: 0.6224 - val_loss: 0.6217 - learning_rate: 8.4818e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6480 - loss: 0.6095\n",
            "Epoch 181: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6482 - loss: 0.6093 - val_accuracy: 0.6430 - val_loss: 0.6202 - learning_rate: 8.4746e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6349\n",
            "Epoch 182: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6349 - val_accuracy: 0.6393 - val_loss: 0.6295 - learning_rate: 8.4674e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6299 - loss: 0.6235\n",
            "Epoch 183: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6312 - loss: 0.6229 - val_accuracy: 0.6318 - val_loss: 0.6176 - learning_rate: 8.4602e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6127\n",
            "Epoch 184: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6127 - val_accuracy: 0.6374 - val_loss: 0.6194 - learning_rate: 8.4531e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6539 - loss: 0.6057\n",
            "Epoch 185: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6545 - loss: 0.6054 - val_accuracy: 0.6093 - val_loss: 0.6294 - learning_rate: 8.4459e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5859 - loss: 0.6935\n",
            "Epoch 186: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5859 - loss: 0.6935 - val_accuracy: 0.6112 - val_loss: 0.6297 - learning_rate: 8.4388e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6617 - loss: 0.6020\n",
            "Epoch 187: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6612 - loss: 0.6024 - val_accuracy: 0.6280 - val_loss: 0.6216 - learning_rate: 8.4317e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.5910\n",
            "Epoch 188: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.5910 - val_accuracy: 0.6430 - val_loss: 0.6215 - learning_rate: 8.4246e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6486 - loss: 0.6093\n",
            "Epoch 189: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6489 - loss: 0.6092 - val_accuracy: 0.6430 - val_loss: 0.6191 - learning_rate: 8.4175e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6265\n",
            "Epoch 190: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6265 - val_accuracy: 0.6299 - val_loss: 0.6159 - learning_rate: 8.4104e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6494 - loss: 0.6130\n",
            "Epoch 191: val_loss did not improve from 0.61538\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6490 - loss: 0.6129 - val_accuracy: 0.6393 - val_loss: 0.6165 - learning_rate: 8.4034e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.6114\n",
            "Epoch 192: val_loss improved from 0.61538 to 0.61252, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7031 - loss: 0.6114 - val_accuracy: 0.6449 - val_loss: 0.6125 - learning_rate: 8.3963e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6673 - loss: 0.5829\n",
            "Epoch 193: val_loss did not improve from 0.61252\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6665 - loss: 0.5841 - val_accuracy: 0.6318 - val_loss: 0.6140 - learning_rate: 8.3893e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6040\n",
            "Epoch 194: val_loss did not improve from 0.61252\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.6040 - val_accuracy: 0.6299 - val_loss: 0.6172 - learning_rate: 8.3822e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6603 - loss: 0.6211\n",
            "Epoch 195: val_loss did not improve from 0.61252\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6609 - loss: 0.6203 - val_accuracy: 0.6355 - val_loss: 0.6152 - learning_rate: 8.3752e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6099\n",
            "Epoch 196: val_loss did not improve from 0.61252\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6099 - val_accuracy: 0.6336 - val_loss: 0.6184 - learning_rate: 8.3682e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6620 - loss: 0.6034\n",
            "Epoch 197: val_loss did not improve from 0.61252\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6615 - loss: 0.6038 - val_accuracy: 0.6262 - val_loss: 0.6187 - learning_rate: 8.3612e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5460\n",
            "Epoch 198: val_loss did not improve from 0.61252\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7344 - loss: 0.5460 - val_accuracy: 0.6393 - val_loss: 0.6143 - learning_rate: 8.3542e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6731 - loss: 0.5998\n",
            "Epoch 199: val_loss did not improve from 0.61252\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6729 - loss: 0.5998 - val_accuracy: 0.6411 - val_loss: 0.6187 - learning_rate: 8.3472e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6217\n",
            "Epoch 200: val_loss improved from 0.61252 to 0.61118, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6094 - loss: 0.6217 - val_accuracy: 0.6561 - val_loss: 0.6112 - learning_rate: 8.3403e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6630 - loss: 0.6051\n",
            "Epoch 201: val_loss did not improve from 0.61118\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6629 - loss: 0.6052 - val_accuracy: 0.6467 - val_loss: 0.6165 - learning_rate: 8.3333e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6077\n",
            "Epoch 202: val_loss did not improve from 0.61118\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6077 - val_accuracy: 0.6393 - val_loss: 0.6207 - learning_rate: 8.3264e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6517 - loss: 0.6037\n",
            "Epoch 203: val_loss did not improve from 0.61118\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6519 - loss: 0.6036 - val_accuracy: 0.6374 - val_loss: 0.6193 - learning_rate: 8.3195e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6343\n",
            "Epoch 204: val_loss did not improve from 0.61118\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6343 - val_accuracy: 0.6206 - val_loss: 0.6216 - learning_rate: 8.3126e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6653 - loss: 0.5984\n",
            "Epoch 205: val_loss did not improve from 0.61118\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6650 - loss: 0.5989 - val_accuracy: 0.6430 - val_loss: 0.6131 - learning_rate: 8.3056e-04\n",
            "Epoch 206/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5849\n",
            "Epoch 206: val_loss did not improve from 0.61118\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5849 - val_accuracy: 0.6280 - val_loss: 0.6182 - learning_rate: 8.2988e-04\n",
            "Epoch 207/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6627 - loss: 0.6020\n",
            "Epoch 207: val_loss did not improve from 0.61118\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6618 - loss: 0.6022 - val_accuracy: 0.6318 - val_loss: 0.6175 - learning_rate: 8.2919e-04\n",
            "Epoch 208/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5943\n",
            "Epoch 208: val_loss improved from 0.61118 to 0.61001, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7109 - loss: 0.5943 - val_accuracy: 0.6636 - val_loss: 0.6100 - learning_rate: 8.2850e-04\n",
            "Epoch 209/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6296 - loss: 0.6055\n",
            "Epoch 209: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6302 - loss: 0.6055 - val_accuracy: 0.6430 - val_loss: 0.6105 - learning_rate: 8.2781e-04\n",
            "Epoch 210/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6989 - loss: 0.5838\n",
            "Epoch 210: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6989 - loss: 0.5838 - val_accuracy: 0.6168 - val_loss: 0.6317 - learning_rate: 8.2713e-04\n",
            "Epoch 211/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6585 - loss: 0.5938\n",
            "Epoch 211: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6580 - loss: 0.5943 - val_accuracy: 0.6206 - val_loss: 0.6187 - learning_rate: 8.2645e-04\n",
            "Epoch 212/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6172 - loss: 0.6118\n",
            "Epoch 212: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6118 - val_accuracy: 0.6505 - val_loss: 0.6184 - learning_rate: 8.2576e-04\n",
            "Epoch 213/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6548 - loss: 0.6016\n",
            "Epoch 213: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6555 - loss: 0.6017 - val_accuracy: 0.6187 - val_loss: 0.6208 - learning_rate: 8.2508e-04\n",
            "Epoch 214/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5494\n",
            "Epoch 214: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6562 - loss: 0.5494 - val_accuracy: 0.6336 - val_loss: 0.6160 - learning_rate: 8.2440e-04\n",
            "Epoch 215/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6497 - loss: 0.5973\n",
            "Epoch 215: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6499 - loss: 0.5970 - val_accuracy: 0.6449 - val_loss: 0.6148 - learning_rate: 8.2372e-04\n",
            "Epoch 216/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6171\n",
            "Epoch 216: val_loss did not improve from 0.61001\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6171 - val_accuracy: 0.6411 - val_loss: 0.6148 - learning_rate: 8.2305e-04\n",
            "Epoch 217/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6740 - loss: 0.5851\n",
            "Epoch 217: val_loss improved from 0.61001 to 0.60977, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6728 - loss: 0.5861 - val_accuracy: 0.6542 - val_loss: 0.6098 - learning_rate: 8.2237e-04\n",
            "Epoch 218/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.5749\n",
            "Epoch 218: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6406 - loss: 0.5749 - val_accuracy: 0.6168 - val_loss: 0.6253 - learning_rate: 8.2169e-04\n",
            "Epoch 219/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6703 - loss: 0.5871\n",
            "Epoch 219: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6699 - loss: 0.5877 - val_accuracy: 0.6505 - val_loss: 0.6102 - learning_rate: 8.2102e-04\n",
            "Epoch 220/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5710\n",
            "Epoch 220: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.5710 - val_accuracy: 0.6411 - val_loss: 0.6133 - learning_rate: 8.2034e-04\n",
            "Epoch 221/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6760 - loss: 0.5850\n",
            "Epoch 221: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6750 - loss: 0.5858 - val_accuracy: 0.6280 - val_loss: 0.6184 - learning_rate: 8.1967e-04\n",
            "Epoch 222/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.6042\n",
            "Epoch 222: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6042 - val_accuracy: 0.6336 - val_loss: 0.6130 - learning_rate: 8.1900e-04\n",
            "Epoch 223/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6517 - loss: 0.6120\n",
            "Epoch 223: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6526 - loss: 0.6111 - val_accuracy: 0.6542 - val_loss: 0.6112 - learning_rate: 8.1833e-04\n",
            "Epoch 224/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6293\n",
            "Epoch 224: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6293 - val_accuracy: 0.6355 - val_loss: 0.6142 - learning_rate: 8.1766e-04\n",
            "Epoch 225/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6444 - loss: 0.6039\n",
            "Epoch 225: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6455 - loss: 0.6033 - val_accuracy: 0.6280 - val_loss: 0.6180 - learning_rate: 8.1699e-04\n",
            "Epoch 226/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.5833\n",
            "Epoch 226: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.5833 - val_accuracy: 0.6430 - val_loss: 0.6170 - learning_rate: 8.1633e-04\n",
            "Epoch 227/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6564 - loss: 0.5989\n",
            "Epoch 227: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6567 - loss: 0.5989 - val_accuracy: 0.6486 - val_loss: 0.6123 - learning_rate: 8.1566e-04\n",
            "Epoch 228/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5805\n",
            "Epoch 228: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5805 - val_accuracy: 0.6280 - val_loss: 0.6202 - learning_rate: 8.1500e-04\n",
            "Epoch 229/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6624 - loss: 0.5923\n",
            "Epoch 229: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6618 - loss: 0.5926 - val_accuracy: 0.6486 - val_loss: 0.6122 - learning_rate: 8.1433e-04\n",
            "Epoch 230/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6069\n",
            "Epoch 230: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6069 - val_accuracy: 0.6486 - val_loss: 0.6131 - learning_rate: 8.1367e-04\n",
            "Epoch 231/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6327 - loss: 0.6120\n",
            "Epoch 231: val_loss did not improve from 0.60977\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6341 - loss: 0.6113 - val_accuracy: 0.6430 - val_loss: 0.6111 - learning_rate: 8.1301e-04\n",
            "Epoch 232/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6347\n",
            "Epoch 232: val_loss improved from 0.60977 to 0.60850, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6094 - loss: 0.6347 - val_accuracy: 0.6579 - val_loss: 0.6085 - learning_rate: 8.1235e-04\n",
            "Epoch 233/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6354 - loss: 0.5989\n",
            "Epoch 233: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6361 - loss: 0.5988 - val_accuracy: 0.6505 - val_loss: 0.6098 - learning_rate: 8.1169e-04\n",
            "Epoch 234/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5714\n",
            "Epoch 234: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5714 - val_accuracy: 0.6449 - val_loss: 0.6146 - learning_rate: 8.1103e-04\n",
            "Epoch 235/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6648 - loss: 0.5915\n",
            "Epoch 235: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6645 - loss: 0.5917 - val_accuracy: 0.6224 - val_loss: 0.6238 - learning_rate: 8.1037e-04\n",
            "Epoch 236/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5972\n",
            "Epoch 236: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5972 - val_accuracy: 0.6523 - val_loss: 0.6090 - learning_rate: 8.0972e-04\n",
            "Epoch 237/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6789 - loss: 0.5862\n",
            "Epoch 237: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6784 - loss: 0.5866 - val_accuracy: 0.6561 - val_loss: 0.6089 - learning_rate: 8.0906e-04\n",
            "Epoch 238/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6008\n",
            "Epoch 238: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6008 - val_accuracy: 0.6486 - val_loss: 0.6092 - learning_rate: 8.0841e-04\n",
            "Epoch 239/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6343 - loss: 0.6149\n",
            "Epoch 239: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6355 - loss: 0.6142 - val_accuracy: 0.6318 - val_loss: 0.6108 - learning_rate: 8.0775e-04\n",
            "Epoch 240/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5462\n",
            "Epoch 240: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5462 - val_accuracy: 0.6355 - val_loss: 0.6154 - learning_rate: 8.0710e-04\n",
            "Epoch 241/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6693 - loss: 0.5915\n",
            "Epoch 241: val_loss did not improve from 0.60850\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6694 - loss: 0.5916 - val_accuracy: 0.6393 - val_loss: 0.6195 - learning_rate: 8.0645e-04\n",
            "Epoch 242/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6123\n",
            "Epoch 242: val_loss improved from 0.60850 to 0.60673, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6250 - loss: 0.6123 - val_accuracy: 0.6505 - val_loss: 0.6067 - learning_rate: 8.0580e-04\n",
            "Epoch 243/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6685 - loss: 0.5823\n",
            "Epoch 243: val_loss did not improve from 0.60673\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6679 - loss: 0.5830 - val_accuracy: 0.6636 - val_loss: 0.6073 - learning_rate: 8.0515e-04\n",
            "Epoch 244/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5555\n",
            "Epoch 244: val_loss did not improve from 0.60673\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5555 - val_accuracy: 0.6355 - val_loss: 0.6145 - learning_rate: 8.0451e-04\n",
            "Epoch 245/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6529 - loss: 0.6057\n",
            "Epoch 245: val_loss did not improve from 0.60673\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6536 - loss: 0.6050 - val_accuracy: 0.6336 - val_loss: 0.6110 - learning_rate: 8.0386e-04\n",
            "Epoch 246/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6034\n",
            "Epoch 246: val_loss improved from 0.60673 to 0.60305, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6328 - loss: 0.6034 - val_accuracy: 0.6598 - val_loss: 0.6030 - learning_rate: 8.0321e-04\n",
            "Epoch 247/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6627 - loss: 0.5935\n",
            "Epoch 247: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6630 - loss: 0.5934 - val_accuracy: 0.6411 - val_loss: 0.6064 - learning_rate: 8.0257e-04\n",
            "Epoch 248/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6243\n",
            "Epoch 248: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.6243 - val_accuracy: 0.6542 - val_loss: 0.6032 - learning_rate: 8.0192e-04\n",
            "Epoch 249/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6543 - loss: 0.6039\n",
            "Epoch 249: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6548 - loss: 0.6035 - val_accuracy: 0.6336 - val_loss: 0.6140 - learning_rate: 8.0128e-04\n",
            "Epoch 250/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6066\n",
            "Epoch 250: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6066 - val_accuracy: 0.6093 - val_loss: 0.6240 - learning_rate: 8.0064e-04\n",
            "Epoch 251/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6733 - loss: 0.5732\n",
            "Epoch 251: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6721 - loss: 0.5743 - val_accuracy: 0.6187 - val_loss: 0.6229 - learning_rate: 8.0000e-04\n",
            "Epoch 252/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5781 - loss: 0.6253\n",
            "Epoch 252: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5781 - loss: 0.6253 - val_accuracy: 0.6374 - val_loss: 0.6159 - learning_rate: 7.9936e-04\n",
            "Epoch 253/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6607 - loss: 0.5799\n",
            "Epoch 253: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6607 - loss: 0.5805 - val_accuracy: 0.6449 - val_loss: 0.6078 - learning_rate: 7.9872e-04\n",
            "Epoch 254/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5551\n",
            "Epoch 254: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5551 - val_accuracy: 0.6336 - val_loss: 0.6101 - learning_rate: 7.9808e-04\n",
            "Epoch 255/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6530 - loss: 0.5966\n",
            "Epoch 255: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6532 - loss: 0.5966 - val_accuracy: 0.6505 - val_loss: 0.6084 - learning_rate: 7.9745e-04\n",
            "Epoch 256/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.6334\n",
            "Epoch 256: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6334 - val_accuracy: 0.6729 - val_loss: 0.6058 - learning_rate: 7.9681e-04\n",
            "Epoch 257/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6740 - loss: 0.5988\n",
            "Epoch 257: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6731 - loss: 0.5986 - val_accuracy: 0.6598 - val_loss: 0.6100 - learning_rate: 7.9618e-04\n",
            "Epoch 258/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7422 - loss: 0.5442\n",
            "Epoch 258: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5442 - val_accuracy: 0.6654 - val_loss: 0.6049 - learning_rate: 7.9554e-04\n",
            "Epoch 259/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6698 - loss: 0.5882\n",
            "Epoch 259: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6699 - loss: 0.5884 - val_accuracy: 0.6579 - val_loss: 0.6085 - learning_rate: 7.9491e-04\n",
            "Epoch 260/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7031 - loss: 0.5923\n",
            "Epoch 260: val_loss did not improve from 0.60305\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5923 - val_accuracy: 0.6598 - val_loss: 0.6086 - learning_rate: 7.9428e-04\n",
            "Epoch 261/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6642 - loss: 0.5906\n",
            "Epoch 261: val_loss improved from 0.60305 to 0.60095, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.6642 - loss: 0.5909 - val_accuracy: 0.6505 - val_loss: 0.6009 - learning_rate: 7.9365e-04\n",
            "Epoch 262/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5233\n",
            "Epoch 262: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5233 - val_accuracy: 0.6561 - val_loss: 0.6102 - learning_rate: 7.9302e-04\n",
            "Epoch 263/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6763 - loss: 0.5718\n",
            "Epoch 263: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6751 - loss: 0.5730 - val_accuracy: 0.6729 - val_loss: 0.6051 - learning_rate: 7.9239e-04\n",
            "Epoch 264/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7422 - loss: 0.5719\n",
            "Epoch 264: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5719 - val_accuracy: 0.6411 - val_loss: 0.6072 - learning_rate: 7.9177e-04\n",
            "Epoch 265/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6733 - loss: 0.5898\n",
            "Epoch 265: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6729 - loss: 0.5901 - val_accuracy: 0.6598 - val_loss: 0.6068 - learning_rate: 7.9114e-04\n",
            "Epoch 266/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6091\n",
            "Epoch 266: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6091 - val_accuracy: 0.6411 - val_loss: 0.6043 - learning_rate: 7.9051e-04\n",
            "Epoch 267/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6794 - loss: 0.5919\n",
            "Epoch 267: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6789 - loss: 0.5917 - val_accuracy: 0.6449 - val_loss: 0.6105 - learning_rate: 7.8989e-04\n",
            "Epoch 268/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7097 - loss: 0.5719\n",
            "Epoch 268: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7097 - loss: 0.5719 - val_accuracy: 0.6355 - val_loss: 0.6105 - learning_rate: 7.8927e-04\n",
            "Epoch 269/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6838 - loss: 0.5879\n",
            "Epoch 269: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6826 - loss: 0.5880 - val_accuracy: 0.6449 - val_loss: 0.6191 - learning_rate: 7.8864e-04\n",
            "Epoch 270/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5532\n",
            "Epoch 270: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5532 - val_accuracy: 0.6449 - val_loss: 0.6080 - learning_rate: 7.8802e-04\n",
            "Epoch 271/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6490 - loss: 0.5945\n",
            "Epoch 271: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6498 - loss: 0.5945 - val_accuracy: 0.6486 - val_loss: 0.6096 - learning_rate: 7.8740e-04\n",
            "Epoch 272/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7656 - loss: 0.4855\n",
            "Epoch 272: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7656 - loss: 0.4855 - val_accuracy: 0.6561 - val_loss: 0.6099 - learning_rate: 7.8678e-04\n",
            "Epoch 273/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6537 - loss: 0.5846\n",
            "Epoch 273: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6542 - loss: 0.5845 - val_accuracy: 0.6636 - val_loss: 0.6121 - learning_rate: 7.8616e-04\n",
            "Epoch 274/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6362\n",
            "Epoch 274: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6362 - val_accuracy: 0.6336 - val_loss: 0.6182 - learning_rate: 7.8555e-04\n",
            "Epoch 275/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6564 - loss: 0.5870\n",
            "Epoch 275: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6566 - loss: 0.5870 - val_accuracy: 0.6112 - val_loss: 0.6261 - learning_rate: 7.8493e-04\n",
            "Epoch 276/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6328 - loss: 0.6004\n",
            "Epoch 276: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6004 - val_accuracy: 0.6542 - val_loss: 0.6091 - learning_rate: 7.8431e-04\n",
            "Epoch 277/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6908 - loss: 0.5926\n",
            "Epoch 277: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6895 - loss: 0.5926 - val_accuracy: 0.6636 - val_loss: 0.6178 - learning_rate: 7.8370e-04\n",
            "Epoch 278/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5704\n",
            "Epoch 278: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5704 - val_accuracy: 0.6523 - val_loss: 0.6037 - learning_rate: 7.8309e-04\n",
            "Epoch 279/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6652 - loss: 0.5897\n",
            "Epoch 279: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6653 - loss: 0.5895 - val_accuracy: 0.6617 - val_loss: 0.6119 - learning_rate: 7.8247e-04\n",
            "Epoch 280/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5700\n",
            "Epoch 280: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.5700 - val_accuracy: 0.6542 - val_loss: 0.6101 - learning_rate: 7.8186e-04\n",
            "Epoch 281/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6717 - loss: 0.5773\n",
            "Epoch 281: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6711 - loss: 0.5781 - val_accuracy: 0.6486 - val_loss: 0.6050 - learning_rate: 7.8125e-04\n",
            "Epoch 282/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5696\n",
            "Epoch 282: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6484 - loss: 0.5696 - val_accuracy: 0.6598 - val_loss: 0.6032 - learning_rate: 7.8064e-04\n",
            "Epoch 283/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6721 - loss: 0.5849\n",
            "Epoch 283: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6714 - loss: 0.5852 - val_accuracy: 0.6486 - val_loss: 0.6128 - learning_rate: 7.8003e-04\n",
            "Epoch 284/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6043\n",
            "Epoch 284: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6043 - val_accuracy: 0.6523 - val_loss: 0.6061 - learning_rate: 7.7942e-04\n",
            "Epoch 285/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6859 - loss: 0.5661\n",
            "Epoch 285: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6850 - loss: 0.5671 - val_accuracy: 0.6299 - val_loss: 0.6122 - learning_rate: 7.7882e-04\n",
            "Epoch 286/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.6278\n",
            "Epoch 286: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6278 - val_accuracy: 0.6243 - val_loss: 0.6193 - learning_rate: 7.7821e-04\n",
            "Epoch 287/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6719 - loss: 0.5870\n",
            "Epoch 287: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6721 - loss: 0.5871 - val_accuracy: 0.6355 - val_loss: 0.6140 - learning_rate: 7.7760e-04\n",
            "Epoch 288/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5973\n",
            "Epoch 288: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5973 - val_accuracy: 0.6280 - val_loss: 0.6106 - learning_rate: 7.7700e-04\n",
            "Epoch 289/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6825 - loss: 0.5864\n",
            "Epoch 289: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6824 - loss: 0.5861 - val_accuracy: 0.6411 - val_loss: 0.6026 - learning_rate: 7.7640e-04\n",
            "Epoch 290/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6012\n",
            "Epoch 290: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6012 - val_accuracy: 0.6561 - val_loss: 0.6077 - learning_rate: 7.7580e-04\n",
            "Epoch 291/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6680 - loss: 0.5804\n",
            "Epoch 291: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6681 - loss: 0.5807 - val_accuracy: 0.6467 - val_loss: 0.6069 - learning_rate: 7.7519e-04\n",
            "Epoch 292/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6013\n",
            "Epoch 292: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6013 - val_accuracy: 0.6449 - val_loss: 0.6113 - learning_rate: 7.7459e-04\n",
            "Epoch 293/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6925 - loss: 0.5742\n",
            "Epoch 293: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6919 - loss: 0.5746 - val_accuracy: 0.6561 - val_loss: 0.6142 - learning_rate: 7.7399e-04\n",
            "Epoch 294/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7188 - loss: 0.5555\n",
            "Epoch 294: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7188 - loss: 0.5555 - val_accuracy: 0.6355 - val_loss: 0.6147 - learning_rate: 7.7340e-04\n",
            "Epoch 295/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6816 - loss: 0.5743\n",
            "Epoch 295: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6814 - loss: 0.5748 - val_accuracy: 0.6336 - val_loss: 0.6091 - learning_rate: 7.7280e-04\n",
            "Epoch 296/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5713\n",
            "Epoch 296: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5713 - val_accuracy: 0.6430 - val_loss: 0.6163 - learning_rate: 7.7220e-04\n",
            "Epoch 297/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6768 - loss: 0.5690\n",
            "Epoch 297: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6762 - loss: 0.5695 - val_accuracy: 0.6486 - val_loss: 0.6100 - learning_rate: 7.7160e-04\n",
            "Epoch 298/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6393\n",
            "Epoch 298: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6393 - val_accuracy: 0.6598 - val_loss: 0.6116 - learning_rate: 7.7101e-04\n",
            "Epoch 299/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6715 - loss: 0.5850\n",
            "Epoch 299: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6715 - loss: 0.5851 - val_accuracy: 0.6505 - val_loss: 0.6091 - learning_rate: 7.7042e-04\n",
            "Epoch 300/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6989 - loss: 0.6177\n",
            "Epoch 300: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6989 - loss: 0.6177 - val_accuracy: 0.6299 - val_loss: 0.6126 - learning_rate: 7.6982e-04\n",
            "Epoch 301/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6748 - loss: 0.5805\n",
            "Epoch 301: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6746 - loss: 0.5807 - val_accuracy: 0.6598 - val_loss: 0.6093 - learning_rate: 7.6923e-04\n",
            "Epoch 302/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6239\n",
            "Epoch 302: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6239 - val_accuracy: 0.6486 - val_loss: 0.6131 - learning_rate: 7.6864e-04\n",
            "Epoch 303/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6688 - loss: 0.5895\n",
            "Epoch 303: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6687 - loss: 0.5894 - val_accuracy: 0.6505 - val_loss: 0.6107 - learning_rate: 7.6805e-04\n",
            "Epoch 304/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5549\n",
            "Epoch 304: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7344 - loss: 0.5549 - val_accuracy: 0.6093 - val_loss: 0.6318 - learning_rate: 7.6746e-04\n",
            "Epoch 305/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6894 - loss: 0.5777\n",
            "Epoch 305: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6888 - loss: 0.5781 - val_accuracy: 0.6692 - val_loss: 0.6068 - learning_rate: 7.6687e-04\n",
            "Epoch 306/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5408\n",
            "Epoch 306: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5408 - val_accuracy: 0.6673 - val_loss: 0.6018 - learning_rate: 7.6628e-04\n",
            "Epoch 307/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6605 - loss: 0.5750\n",
            "Epoch 307: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6606 - loss: 0.5757 - val_accuracy: 0.6785 - val_loss: 0.6074 - learning_rate: 7.6570e-04\n",
            "Epoch 308/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6040\n",
            "Epoch 308: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6040 - val_accuracy: 0.6710 - val_loss: 0.6015 - learning_rate: 7.6511e-04\n",
            "Epoch 309/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6667 - loss: 0.5788\n",
            "Epoch 309: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6667 - loss: 0.5791 - val_accuracy: 0.6860 - val_loss: 0.6086 - learning_rate: 7.6453e-04\n",
            "Epoch 310/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5758\n",
            "Epoch 310: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5758 - val_accuracy: 0.6654 - val_loss: 0.6069 - learning_rate: 7.6394e-04\n",
            "Epoch 311/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6894 - loss: 0.5743\n",
            "Epoch 311: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6886 - loss: 0.5745 - val_accuracy: 0.6467 - val_loss: 0.6111 - learning_rate: 7.6336e-04\n",
            "Epoch 312/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5927\n",
            "Epoch 312: val_loss did not improve from 0.60095\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.5927 - val_accuracy: 0.6748 - val_loss: 0.6051 - learning_rate: 7.6278e-04\n",
            "Epoch 313/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6816 - loss: 0.5741\n",
            "Epoch 313: val_loss improved from 0.60095 to 0.60007, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.6815 - loss: 0.5747 - val_accuracy: 0.6542 - val_loss: 0.6001 - learning_rate: 7.6220e-04\n",
            "Epoch 314/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5698\n",
            "Epoch 314: val_loss improved from 0.60007 to 0.59640, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7031 - loss: 0.5698 - val_accuracy: 0.6542 - val_loss: 0.5964 - learning_rate: 7.6161e-04\n",
            "Epoch 315/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6638 - loss: 0.5923\n",
            "Epoch 315: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6642 - loss: 0.5919 - val_accuracy: 0.6430 - val_loss: 0.6113 - learning_rate: 7.6104e-04\n",
            "Epoch 316/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7031 - loss: 0.5871\n",
            "Epoch 316: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5871 - val_accuracy: 0.6636 - val_loss: 0.6006 - learning_rate: 7.6046e-04\n",
            "Epoch 317/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6828 - loss: 0.5715\n",
            "Epoch 317: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6821 - loss: 0.5720 - val_accuracy: 0.6280 - val_loss: 0.6174 - learning_rate: 7.5988e-04\n",
            "Epoch 318/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.5842\n",
            "Epoch 318: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5842 - val_accuracy: 0.6467 - val_loss: 0.6057 - learning_rate: 7.5930e-04\n",
            "Epoch 319/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6816 - loss: 0.5830\n",
            "Epoch 319: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6812 - loss: 0.5825 - val_accuracy: 0.6336 - val_loss: 0.6205 - learning_rate: 7.5873e-04\n",
            "Epoch 320/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6289\n",
            "Epoch 320: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6289 - val_accuracy: 0.6505 - val_loss: 0.6126 - learning_rate: 7.5815e-04\n",
            "Epoch 321/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6579 - loss: 0.5989\n",
            "Epoch 321: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6583 - loss: 0.5982 - val_accuracy: 0.6561 - val_loss: 0.6112 - learning_rate: 7.5758e-04\n",
            "Epoch 322/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6124\n",
            "Epoch 322: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6124 - val_accuracy: 0.6374 - val_loss: 0.6110 - learning_rate: 7.5700e-04\n",
            "Epoch 323/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6738 - loss: 0.5917\n",
            "Epoch 323: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6745 - loss: 0.5906 - val_accuracy: 0.6673 - val_loss: 0.6039 - learning_rate: 7.5643e-04\n",
            "Epoch 324/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6039\n",
            "Epoch 324: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6039 - val_accuracy: 0.6430 - val_loss: 0.6200 - learning_rate: 7.5586e-04\n",
            "Epoch 325/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6698 - loss: 0.5768\n",
            "Epoch 325: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6697 - loss: 0.5774 - val_accuracy: 0.6486 - val_loss: 0.6033 - learning_rate: 7.5529e-04\n",
            "Epoch 326/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5455\n",
            "Epoch 326: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7266 - loss: 0.5455 - val_accuracy: 0.6804 - val_loss: 0.6039 - learning_rate: 7.5472e-04\n",
            "Epoch 327/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6741 - loss: 0.5834\n",
            "Epoch 327: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6737 - loss: 0.5839 - val_accuracy: 0.6729 - val_loss: 0.5997 - learning_rate: 7.5415e-04\n",
            "Epoch 328/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5627\n",
            "Epoch 328: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5627 - val_accuracy: 0.6393 - val_loss: 0.6139 - learning_rate: 7.5358e-04\n",
            "Epoch 329/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6904 - loss: 0.5753\n",
            "Epoch 329: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6896 - loss: 0.5755 - val_accuracy: 0.6411 - val_loss: 0.6051 - learning_rate: 7.5301e-04\n",
            "Epoch 330/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5968\n",
            "Epoch 330: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5968 - val_accuracy: 0.6449 - val_loss: 0.6176 - learning_rate: 7.5245e-04\n",
            "Epoch 331/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6732 - loss: 0.5902\n",
            "Epoch 331: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6734 - loss: 0.5898 - val_accuracy: 0.6785 - val_loss: 0.5991 - learning_rate: 7.5188e-04\n",
            "Epoch 332/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5746\n",
            "Epoch 332: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6797 - loss: 0.5746 - val_accuracy: 0.6561 - val_loss: 0.6076 - learning_rate: 7.5131e-04\n",
            "Epoch 333/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6905 - loss: 0.5628\n",
            "Epoch 333: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6898 - loss: 0.5633 - val_accuracy: 0.6710 - val_loss: 0.6036 - learning_rate: 7.5075e-04\n",
            "Epoch 334/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5860\n",
            "Epoch 334: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5860 - val_accuracy: 0.6430 - val_loss: 0.6162 - learning_rate: 7.5019e-04\n",
            "Epoch 335/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6926 - loss: 0.5790\n",
            "Epoch 335: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6920 - loss: 0.5794 - val_accuracy: 0.6393 - val_loss: 0.6038 - learning_rate: 7.4963e-04\n",
            "Epoch 336/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5305\n",
            "Epoch 336: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6875 - loss: 0.5305 - val_accuracy: 0.6561 - val_loss: 0.6044 - learning_rate: 7.4906e-04\n",
            "Epoch 337/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6615 - loss: 0.5805\n",
            "Epoch 337: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6619 - loss: 0.5804 - val_accuracy: 0.6467 - val_loss: 0.6100 - learning_rate: 7.4850e-04\n",
            "Epoch 338/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5747\n",
            "Epoch 338: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5747 - val_accuracy: 0.6579 - val_loss: 0.6051 - learning_rate: 7.4794e-04\n",
            "Epoch 339/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6647 - loss: 0.5851\n",
            "Epoch 339: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6651 - loss: 0.5848 - val_accuracy: 0.6710 - val_loss: 0.6060 - learning_rate: 7.4738e-04\n",
            "Epoch 340/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7109 - loss: 0.5063\n",
            "Epoch 340: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5063 - val_accuracy: 0.6692 - val_loss: 0.6102 - learning_rate: 7.4683e-04\n",
            "Epoch 341/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6751 - loss: 0.5633\n",
            "Epoch 341: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6745 - loss: 0.5641 - val_accuracy: 0.6654 - val_loss: 0.6047 - learning_rate: 7.4627e-04\n",
            "Epoch 342/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5552\n",
            "Epoch 342: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5552 - val_accuracy: 0.6243 - val_loss: 0.6288 - learning_rate: 7.4571e-04\n",
            "Epoch 343/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6565 - loss: 0.5874\n",
            "Epoch 343: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6573 - loss: 0.5870 - val_accuracy: 0.6523 - val_loss: 0.6103 - learning_rate: 7.4516e-04\n",
            "Epoch 344/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5448\n",
            "Epoch 344: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5448 - val_accuracy: 0.6617 - val_loss: 0.5980 - learning_rate: 7.4460e-04\n",
            "Epoch 345/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6544 - loss: 0.5813\n",
            "Epoch 345: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6553 - loss: 0.5809 - val_accuracy: 0.6579 - val_loss: 0.5983 - learning_rate: 7.4405e-04\n",
            "Epoch 346/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7031 - loss: 0.5418\n",
            "Epoch 346: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5418 - val_accuracy: 0.6542 - val_loss: 0.6069 - learning_rate: 7.4349e-04\n",
            "Epoch 347/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7145 - loss: 0.5494\n",
            "Epoch 347: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.7131 - loss: 0.5507 - val_accuracy: 0.6505 - val_loss: 0.6148 - learning_rate: 7.4294e-04\n",
            "Epoch 348/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5781 - loss: 0.6199\n",
            "Epoch 348: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5781 - loss: 0.6199 - val_accuracy: 0.6523 - val_loss: 0.6075 - learning_rate: 7.4239e-04\n",
            "Epoch 349/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6780 - loss: 0.5768\n",
            "Epoch 349: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6778 - loss: 0.5768 - val_accuracy: 0.6636 - val_loss: 0.5989 - learning_rate: 7.4184e-04\n",
            "Epoch 350/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6200\n",
            "Epoch 350: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.6200 - val_accuracy: 0.6636 - val_loss: 0.6025 - learning_rate: 7.4129e-04\n",
            "Epoch 351/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6913 - loss: 0.5621\n",
            "Epoch 351: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6906 - loss: 0.5629 - val_accuracy: 0.6299 - val_loss: 0.6047 - learning_rate: 7.4074e-04\n",
            "Epoch 352/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5422\n",
            "Epoch 352: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5422 - val_accuracy: 0.6561 - val_loss: 0.6052 - learning_rate: 7.4019e-04\n",
            "Epoch 353/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6514 - loss: 0.5867\n",
            "Epoch 353: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6523 - loss: 0.5856 - val_accuracy: 0.6467 - val_loss: 0.6102 - learning_rate: 7.3964e-04\n",
            "Epoch 354/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6478\n",
            "Epoch 354: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6478 - val_accuracy: 0.6598 - val_loss: 0.6019 - learning_rate: 7.3910e-04\n",
            "Epoch 355/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6832 - loss: 0.5620\n",
            "Epoch 355: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6827 - loss: 0.5630 - val_accuracy: 0.6692 - val_loss: 0.6090 - learning_rate: 7.3855e-04\n",
            "Epoch 356/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5870\n",
            "Epoch 356: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.5870 - val_accuracy: 0.6636 - val_loss: 0.6057 - learning_rate: 7.3801e-04\n",
            "Epoch 357/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6732 - loss: 0.5766\n",
            "Epoch 357: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - accuracy: 0.6731 - loss: 0.5768 - val_accuracy: 0.6561 - val_loss: 0.6068 - learning_rate: 7.3746e-04\n",
            "Epoch 358/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7422 - loss: 0.5157\n",
            "Epoch 358: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5157 - val_accuracy: 0.6523 - val_loss: 0.6011 - learning_rate: 7.3692e-04\n",
            "Epoch 359/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6817 - loss: 0.5764\n",
            "Epoch 359: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6813 - loss: 0.5763 - val_accuracy: 0.6430 - val_loss: 0.6071 - learning_rate: 7.3638e-04\n",
            "Epoch 360/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5322\n",
            "Epoch 360: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5322 - val_accuracy: 0.6673 - val_loss: 0.5993 - learning_rate: 7.3584e-04\n",
            "Epoch 361/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6725 - loss: 0.5802\n",
            "Epoch 361: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6729 - loss: 0.5805 - val_accuracy: 0.6336 - val_loss: 0.6164 - learning_rate: 7.3529e-04\n",
            "Epoch 362/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6161\n",
            "Epoch 362: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6161 - val_accuracy: 0.6579 - val_loss: 0.5992 - learning_rate: 7.3475e-04\n",
            "Epoch 363/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6758 - loss: 0.5827\n",
            "Epoch 363: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6753 - loss: 0.5827 - val_accuracy: 0.6393 - val_loss: 0.6064 - learning_rate: 7.3421e-04\n",
            "Epoch 364/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.5764\n",
            "Epoch 364: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.5764 - val_accuracy: 0.6598 - val_loss: 0.6054 - learning_rate: 7.3368e-04\n",
            "Epoch 365/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6951 - loss: 0.5630\n",
            "Epoch 365: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6946 - loss: 0.5637 - val_accuracy: 0.6766 - val_loss: 0.5992 - learning_rate: 7.3314e-04\n",
            "Epoch 366/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5394\n",
            "Epoch 366: val_loss improved from 0.59640 to 0.59640, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6875 - loss: 0.5394 - val_accuracy: 0.6710 - val_loss: 0.5964 - learning_rate: 7.3260e-04\n",
            "Epoch 367/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6715 - loss: 0.5838\n",
            "Epoch 367: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6722 - loss: 0.5835 - val_accuracy: 0.6935 - val_loss: 0.5997 - learning_rate: 7.3206e-04\n",
            "Epoch 368/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5861\n",
            "Epoch 368: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5861 - val_accuracy: 0.6561 - val_loss: 0.6037 - learning_rate: 7.3153e-04\n",
            "Epoch 369/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6783 - loss: 0.5854\n",
            "Epoch 369: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6783 - loss: 0.5849 - val_accuracy: 0.6822 - val_loss: 0.6120 - learning_rate: 7.3099e-04\n",
            "Epoch 370/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5608\n",
            "Epoch 370: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5608 - val_accuracy: 0.6505 - val_loss: 0.6117 - learning_rate: 7.3046e-04\n",
            "Epoch 371/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6707 - loss: 0.5774\n",
            "Epoch 371: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6712 - loss: 0.5772 - val_accuracy: 0.6841 - val_loss: 0.6016 - learning_rate: 7.2993e-04\n",
            "Epoch 372/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.5809\n",
            "Epoch 372: val_loss did not improve from 0.59640\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5809 - val_accuracy: 0.6804 - val_loss: 0.6065 - learning_rate: 7.2939e-04\n",
            "Epoch 373/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6868 - loss: 0.5607\n",
            "Epoch 373: val_loss improved from 0.59640 to 0.59299, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.6862 - loss: 0.5613 - val_accuracy: 0.6636 - val_loss: 0.5930 - learning_rate: 7.2886e-04\n",
            "Epoch 374/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.5996\n",
            "Epoch 374: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6016 - loss: 0.5996 - val_accuracy: 0.6579 - val_loss: 0.5993 - learning_rate: 7.2833e-04\n",
            "Epoch 375/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6776 - loss: 0.5782\n",
            "Epoch 375: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6775 - loss: 0.5784 - val_accuracy: 0.6710 - val_loss: 0.6017 - learning_rate: 7.2780e-04\n",
            "Epoch 376/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5481\n",
            "Epoch 376: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5481 - val_accuracy: 0.6636 - val_loss: 0.5996 - learning_rate: 7.2727e-04\n",
            "Epoch 377/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6747 - loss: 0.5708\n",
            "Epoch 377: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6747 - loss: 0.5708 - val_accuracy: 0.6654 - val_loss: 0.5994 - learning_rate: 7.2674e-04\n",
            "Epoch 378/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5281\n",
            "Epoch 378: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5281 - val_accuracy: 0.6617 - val_loss: 0.6100 - learning_rate: 7.2622e-04\n",
            "Epoch 379/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6891 - loss: 0.5665\n",
            "Epoch 379: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6882 - loss: 0.5671 - val_accuracy: 0.6262 - val_loss: 0.6212 - learning_rate: 7.2569e-04\n",
            "Epoch 380/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.5976\n",
            "Epoch 380: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.5976 - val_accuracy: 0.6486 - val_loss: 0.6029 - learning_rate: 7.2516e-04\n",
            "Epoch 381/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6949 - loss: 0.5596\n",
            "Epoch 381: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6942 - loss: 0.5602 - val_accuracy: 0.6804 - val_loss: 0.6065 - learning_rate: 7.2464e-04\n",
            "Epoch 382/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6155\n",
            "Epoch 382: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6155 - val_accuracy: 0.6542 - val_loss: 0.6163 - learning_rate: 7.2411e-04\n",
            "Epoch 383/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6805 - loss: 0.5622\n",
            "Epoch 383: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6801 - loss: 0.5631 - val_accuracy: 0.6523 - val_loss: 0.6043 - learning_rate: 7.2359e-04\n",
            "Epoch 384/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5854\n",
            "Epoch 384: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7266 - loss: 0.5854 - val_accuracy: 0.6486 - val_loss: 0.6059 - learning_rate: 7.2307e-04\n",
            "Epoch 385/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6940 - loss: 0.5625\n",
            "Epoch 385: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6931 - loss: 0.5633 - val_accuracy: 0.6636 - val_loss: 0.6066 - learning_rate: 7.2254e-04\n",
            "Epoch 386/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5615\n",
            "Epoch 386: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5615 - val_accuracy: 0.6542 - val_loss: 0.6036 - learning_rate: 7.2202e-04\n",
            "Epoch 387/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6725 - loss: 0.5806\n",
            "Epoch 387: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6728 - loss: 0.5808 - val_accuracy: 0.6542 - val_loss: 0.6061 - learning_rate: 7.2150e-04\n",
            "Epoch 388/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7578 - loss: 0.5020\n",
            "Epoch 388: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7578 - loss: 0.5020 - val_accuracy: 0.6729 - val_loss: 0.6049 - learning_rate: 7.2098e-04\n",
            "Epoch 389/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6912 - loss: 0.5834\n",
            "Epoch 389: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6908 - loss: 0.5828 - val_accuracy: 0.6729 - val_loss: 0.6105 - learning_rate: 7.2046e-04\n",
            "Epoch 390/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5953\n",
            "Epoch 390: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5953 - val_accuracy: 0.6617 - val_loss: 0.6016 - learning_rate: 7.1994e-04\n",
            "Epoch 391/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6781 - loss: 0.5860\n",
            "Epoch 391: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6782 - loss: 0.5853 - val_accuracy: 0.6654 - val_loss: 0.6056 - learning_rate: 7.1942e-04\n",
            "Epoch 392/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5844\n",
            "Epoch 392: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5844 - val_accuracy: 0.6542 - val_loss: 0.5958 - learning_rate: 7.1891e-04\n",
            "Epoch 393/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6674 - loss: 0.5730\n",
            "Epoch 393: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6674 - loss: 0.5735 - val_accuracy: 0.6598 - val_loss: 0.6026 - learning_rate: 7.1839e-04\n",
            "Epoch 394/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.5457\n",
            "Epoch 394: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5457 - val_accuracy: 0.6505 - val_loss: 0.6092 - learning_rate: 7.1788e-04\n",
            "Epoch 395/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6752 - loss: 0.5741\n",
            "Epoch 395: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6755 - loss: 0.5740 - val_accuracy: 0.6841 - val_loss: 0.5993 - learning_rate: 7.1736e-04\n",
            "Epoch 396/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5935\n",
            "Epoch 396: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5935 - val_accuracy: 0.6262 - val_loss: 0.6212 - learning_rate: 7.1685e-04\n",
            "Epoch 397/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6820 - loss: 0.5653\n",
            "Epoch 397: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6824 - loss: 0.5653 - val_accuracy: 0.6692 - val_loss: 0.5961 - learning_rate: 7.1633e-04\n",
            "Epoch 398/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6612\n",
            "Epoch 398: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.6612 - val_accuracy: 0.6748 - val_loss: 0.6048 - learning_rate: 7.1582e-04\n",
            "Epoch 399/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6700 - loss: 0.5744\n",
            "Epoch 399: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6702 - loss: 0.5748 - val_accuracy: 0.6897 - val_loss: 0.5964 - learning_rate: 7.1531e-04\n",
            "Epoch 400/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5572\n",
            "Epoch 400: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6953 - loss: 0.5572 - val_accuracy: 0.6523 - val_loss: 0.6055 - learning_rate: 7.1480e-04\n",
            "Epoch 401/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6754 - loss: 0.5717\n",
            "Epoch 401: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6753 - loss: 0.5721 - val_accuracy: 0.6654 - val_loss: 0.6005 - learning_rate: 7.1429e-04\n",
            "Epoch 402/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5249\n",
            "Epoch 402: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7188 - loss: 0.5249 - val_accuracy: 0.6598 - val_loss: 0.6084 - learning_rate: 7.1378e-04\n",
            "Epoch 403/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6767 - loss: 0.5897\n",
            "Epoch 403: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6771 - loss: 0.5889 - val_accuracy: 0.6579 - val_loss: 0.6008 - learning_rate: 7.1327e-04\n",
            "Epoch 404/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.5702\n",
            "Epoch 404: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5702 - val_accuracy: 0.6729 - val_loss: 0.6036 - learning_rate: 7.1276e-04\n",
            "Epoch 405/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6800 - loss: 0.5752\n",
            "Epoch 405: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6800 - loss: 0.5752 - val_accuracy: 0.6673 - val_loss: 0.6002 - learning_rate: 7.1225e-04\n",
            "Epoch 406/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.5388\n",
            "Epoch 406: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5388 - val_accuracy: 0.6654 - val_loss: 0.6041 - learning_rate: 7.1174e-04\n",
            "Epoch 407/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6802 - loss: 0.5796\n",
            "Epoch 407: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6800 - loss: 0.5797 - val_accuracy: 0.6617 - val_loss: 0.5978 - learning_rate: 7.1124e-04\n",
            "Epoch 408/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7422 - loss: 0.5304\n",
            "Epoch 408: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7422 - loss: 0.5304 - val_accuracy: 0.6523 - val_loss: 0.6021 - learning_rate: 7.1073e-04\n",
            "Epoch 409/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6680 - loss: 0.5687\n",
            "Epoch 409: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6680 - loss: 0.5689 - val_accuracy: 0.6785 - val_loss: 0.5964 - learning_rate: 7.1023e-04\n",
            "Epoch 410/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6173\n",
            "Epoch 410: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.6173 - val_accuracy: 0.6411 - val_loss: 0.6091 - learning_rate: 7.0972e-04\n",
            "Epoch 411/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6766 - loss: 0.5615\n",
            "Epoch 411: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6764 - loss: 0.5618 - val_accuracy: 0.6673 - val_loss: 0.6031 - learning_rate: 7.0922e-04\n",
            "Epoch 412/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.5571\n",
            "Epoch 412: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5571 - val_accuracy: 0.6729 - val_loss: 0.6080 - learning_rate: 7.0872e-04\n",
            "Epoch 413/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6962 - loss: 0.5788\n",
            "Epoch 413: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6960 - loss: 0.5786 - val_accuracy: 0.6467 - val_loss: 0.6097 - learning_rate: 7.0822e-04\n",
            "Epoch 414/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5290\n",
            "Epoch 414: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5290 - val_accuracy: 0.6804 - val_loss: 0.5936 - learning_rate: 7.0771e-04\n",
            "Epoch 415/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6826 - loss: 0.5860\n",
            "Epoch 415: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6826 - loss: 0.5857 - val_accuracy: 0.6523 - val_loss: 0.6114 - learning_rate: 7.0721e-04\n",
            "Epoch 416/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6797 - loss: 0.5705\n",
            "Epoch 416: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5705 - val_accuracy: 0.6579 - val_loss: 0.6024 - learning_rate: 7.0671e-04\n",
            "Epoch 417/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6721 - loss: 0.5803\n",
            "Epoch 417: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6723 - loss: 0.5801 - val_accuracy: 0.6860 - val_loss: 0.5989 - learning_rate: 7.0621e-04\n",
            "Epoch 418/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5738\n",
            "Epoch 418: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6875 - loss: 0.5738 - val_accuracy: 0.6561 - val_loss: 0.6065 - learning_rate: 7.0572e-04\n",
            "Epoch 419/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6598 - loss: 0.5878\n",
            "Epoch 419: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6600 - loss: 0.5873 - val_accuracy: 0.6430 - val_loss: 0.6078 - learning_rate: 7.0522e-04\n",
            "Epoch 420/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.6130\n",
            "Epoch 420: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.6130 - val_accuracy: 0.6280 - val_loss: 0.6164 - learning_rate: 7.0472e-04\n",
            "Epoch 421/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6657 - loss: 0.5749\n",
            "Epoch 421: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6662 - loss: 0.5748 - val_accuracy: 0.6710 - val_loss: 0.6005 - learning_rate: 7.0423e-04\n",
            "Epoch 422/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5132\n",
            "Epoch 422: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7266 - loss: 0.5132 - val_accuracy: 0.6598 - val_loss: 0.6104 - learning_rate: 7.0373e-04\n",
            "Epoch 423/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6676 - loss: 0.5977\n",
            "Epoch 423: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6685 - loss: 0.5965 - val_accuracy: 0.6561 - val_loss: 0.6106 - learning_rate: 7.0323e-04\n",
            "Epoch 424/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5545\n",
            "Epoch 424: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5545 - val_accuracy: 0.6542 - val_loss: 0.6005 - learning_rate: 7.0274e-04\n",
            "Epoch 425/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6825 - loss: 0.5628\n",
            "Epoch 425: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6820 - loss: 0.5631 - val_accuracy: 0.6374 - val_loss: 0.6133 - learning_rate: 7.0225e-04\n",
            "Epoch 426/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5621\n",
            "Epoch 426: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5621 - val_accuracy: 0.6411 - val_loss: 0.6193 - learning_rate: 7.0175e-04\n",
            "Epoch 427/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6704 - loss: 0.5824\n",
            "Epoch 427: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6712 - loss: 0.5820 - val_accuracy: 0.6673 - val_loss: 0.6177 - learning_rate: 7.0126e-04\n",
            "Epoch 428/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6094 - loss: 0.6126\n",
            "Epoch 428: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6126 - val_accuracy: 0.6579 - val_loss: 0.6042 - learning_rate: 7.0077e-04\n",
            "Epoch 429/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6989 - loss: 0.5663\n",
            "Epoch 429: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6980 - loss: 0.5665 - val_accuracy: 0.6579 - val_loss: 0.6030 - learning_rate: 7.0028e-04\n",
            "Epoch 430/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5772\n",
            "Epoch 430: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5772 - val_accuracy: 0.6710 - val_loss: 0.6008 - learning_rate: 6.9979e-04\n",
            "Epoch 431/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6816 - loss: 0.5592\n",
            "Epoch 431: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6811 - loss: 0.5601 - val_accuracy: 0.6654 - val_loss: 0.6008 - learning_rate: 6.9930e-04\n",
            "Epoch 432/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5723\n",
            "Epoch 432: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6719 - loss: 0.5723 - val_accuracy: 0.6748 - val_loss: 0.5955 - learning_rate: 6.9881e-04\n",
            "Epoch 433/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6720 - loss: 0.5794\n",
            "Epoch 433: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6731 - loss: 0.5787 - val_accuracy: 0.6636 - val_loss: 0.6178 - learning_rate: 6.9832e-04\n",
            "Epoch 434/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.7182\n",
            "Epoch 434: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.7182 - val_accuracy: 0.6785 - val_loss: 0.5956 - learning_rate: 6.9784e-04\n",
            "Epoch 435/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6662 - loss: 0.5674\n",
            "Epoch 435: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6664 - loss: 0.5672 - val_accuracy: 0.6542 - val_loss: 0.6028 - learning_rate: 6.9735e-04\n",
            "Epoch 436/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6025\n",
            "Epoch 436: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6719 - loss: 0.6025 - val_accuracy: 0.6822 - val_loss: 0.5934 - learning_rate: 6.9686e-04\n",
            "Epoch 437/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6995 - loss: 0.5495\n",
            "Epoch 437: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6987 - loss: 0.5506 - val_accuracy: 0.6224 - val_loss: 0.6248 - learning_rate: 6.9638e-04\n",
            "Epoch 438/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.5803\n",
            "Epoch 438: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5803 - val_accuracy: 0.6411 - val_loss: 0.6009 - learning_rate: 6.9589e-04\n",
            "Epoch 439/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6717 - loss: 0.5660\n",
            "Epoch 439: val_loss did not improve from 0.59299\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6724 - loss: 0.5662 - val_accuracy: 0.6748 - val_loss: 0.5990 - learning_rate: 6.9541e-04\n",
            "Epoch 440/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.5131\n",
            "Epoch 440: val_loss improved from 0.59299 to 0.59162, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7500 - loss: 0.5131 - val_accuracy: 0.6897 - val_loss: 0.5916 - learning_rate: 6.9493e-04\n",
            "Epoch 441/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6809 - loss: 0.5739\n",
            "Epoch 441: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6807 - loss: 0.5742 - val_accuracy: 0.6673 - val_loss: 0.5976 - learning_rate: 6.9444e-04\n",
            "Epoch 442/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5738\n",
            "Epoch 442: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.5738 - val_accuracy: 0.6897 - val_loss: 0.5938 - learning_rate: 6.9396e-04\n",
            "Epoch 443/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6833 - loss: 0.5865\n",
            "Epoch 443: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6835 - loss: 0.5858 - val_accuracy: 0.6766 - val_loss: 0.5950 - learning_rate: 6.9348e-04\n",
            "Epoch 444/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6797 - loss: 0.5653\n",
            "Epoch 444: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5653 - val_accuracy: 0.6804 - val_loss: 0.5923 - learning_rate: 6.9300e-04\n",
            "Epoch 445/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7046 - loss: 0.5570\n",
            "Epoch 445: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.7039 - loss: 0.5575 - val_accuracy: 0.6579 - val_loss: 0.6082 - learning_rate: 6.9252e-04\n",
            "Epoch 446/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6994\n",
            "Epoch 446: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5781 - loss: 0.6994 - val_accuracy: 0.6505 - val_loss: 0.6008 - learning_rate: 6.9204e-04\n",
            "Epoch 447/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6934 - loss: 0.5636\n",
            "Epoch 447: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6928 - loss: 0.5643 - val_accuracy: 0.6561 - val_loss: 0.6115 - learning_rate: 6.9156e-04\n",
            "Epoch 448/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6953 - loss: 0.5672\n",
            "Epoch 448: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5672 - val_accuracy: 0.6804 - val_loss: 0.5965 - learning_rate: 6.9109e-04\n",
            "Epoch 449/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6771 - loss: 0.5725\n",
            "Epoch 449: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6775 - loss: 0.5724 - val_accuracy: 0.6449 - val_loss: 0.6150 - learning_rate: 6.9061e-04\n",
            "Epoch 450/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5858\n",
            "Epoch 450: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5858 - val_accuracy: 0.6822 - val_loss: 0.5974 - learning_rate: 6.9013e-04\n",
            "Epoch 451/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6816 - loss: 0.5690\n",
            "Epoch 451: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6818 - loss: 0.5688 - val_accuracy: 0.6654 - val_loss: 0.5992 - learning_rate: 6.8966e-04\n",
            "Epoch 452/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6953 - loss: 0.5507\n",
            "Epoch 452: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5507 - val_accuracy: 0.6729 - val_loss: 0.6076 - learning_rate: 6.8918e-04\n",
            "Epoch 453/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6917 - loss: 0.5765\n",
            "Epoch 453: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6911 - loss: 0.5762 - val_accuracy: 0.6636 - val_loss: 0.6085 - learning_rate: 6.8871e-04\n",
            "Epoch 454/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6173\n",
            "Epoch 454: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6173 - val_accuracy: 0.6486 - val_loss: 0.6006 - learning_rate: 6.8823e-04\n",
            "Epoch 455/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6894 - loss: 0.5553\n",
            "Epoch 455: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6892 - loss: 0.5555 - val_accuracy: 0.6075 - val_loss: 0.6407 - learning_rate: 6.8776e-04\n",
            "Epoch 456/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6152\n",
            "Epoch 456: val_loss did not improve from 0.59162\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6152 - val_accuracy: 0.6617 - val_loss: 0.6006 - learning_rate: 6.8729e-04\n",
            "Epoch 457/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6985 - loss: 0.5601\n",
            "Epoch 457: val_loss improved from 0.59162 to 0.58559, saving model to model_2_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6979 - loss: 0.5608 - val_accuracy: 0.6654 - val_loss: 0.5856 - learning_rate: 6.8681e-04\n",
            "Epoch 458/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5477\n",
            "Epoch 458: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7266 - loss: 0.5477 - val_accuracy: 0.6879 - val_loss: 0.5930 - learning_rate: 6.8634e-04\n",
            "Epoch 459/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6736 - loss: 0.5879\n",
            "Epoch 459: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6734 - loss: 0.5872 - val_accuracy: 0.6785 - val_loss: 0.5876 - learning_rate: 6.8587e-04\n",
            "Epoch 460/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7891 - loss: 0.4917\n",
            "Epoch 460: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7891 - loss: 0.4917 - val_accuracy: 0.6505 - val_loss: 0.6192 - learning_rate: 6.8540e-04\n",
            "Epoch 461/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6897 - loss: 0.5737\n",
            "Epoch 461: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6891 - loss: 0.5736 - val_accuracy: 0.6561 - val_loss: 0.6119 - learning_rate: 6.8493e-04\n",
            "Epoch 462/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.5999\n",
            "Epoch 462: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5999 - val_accuracy: 0.6673 - val_loss: 0.6096 - learning_rate: 6.8446e-04\n",
            "Epoch 463/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6879 - loss: 0.5593\n",
            "Epoch 463: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6875 - loss: 0.5595 - val_accuracy: 0.6523 - val_loss: 0.6040 - learning_rate: 6.8399e-04\n",
            "Epoch 464/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6191\n",
            "Epoch 464: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6191 - val_accuracy: 0.6729 - val_loss: 0.5997 - learning_rate: 6.8353e-04\n",
            "Epoch 465/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6886 - loss: 0.5677\n",
            "Epoch 465: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6878 - loss: 0.5681 - val_accuracy: 0.6785 - val_loss: 0.5903 - learning_rate: 6.8306e-04\n",
            "Epoch 466/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5756\n",
            "Epoch 466: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5756 - val_accuracy: 0.6617 - val_loss: 0.5995 - learning_rate: 6.8259e-04\n",
            "Epoch 467/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6878 - loss: 0.5642\n",
            "Epoch 467: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6878 - loss: 0.5644 - val_accuracy: 0.6486 - val_loss: 0.6078 - learning_rate: 6.8213e-04\n",
            "Epoch 468/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5828\n",
            "Epoch 468: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5828 - val_accuracy: 0.6617 - val_loss: 0.6037 - learning_rate: 6.8166e-04\n",
            "Epoch 469/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6845 - loss: 0.5663\n",
            "Epoch 469: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6842 - loss: 0.5665 - val_accuracy: 0.6841 - val_loss: 0.5950 - learning_rate: 6.8120e-04\n",
            "Epoch 470/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5337\n",
            "Epoch 470: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5337 - val_accuracy: 0.6654 - val_loss: 0.5966 - learning_rate: 6.8074e-04\n",
            "Epoch 471/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6893 - loss: 0.5578\n",
            "Epoch 471: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6889 - loss: 0.5584 - val_accuracy: 0.6636 - val_loss: 0.6041 - learning_rate: 6.8027e-04\n",
            "Epoch 472/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5580\n",
            "Epoch 472: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5580 - val_accuracy: 0.6822 - val_loss: 0.5996 - learning_rate: 6.7981e-04\n",
            "Epoch 473/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6848 - loss: 0.5614\n",
            "Epoch 473: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6842 - loss: 0.5621 - val_accuracy: 0.6729 - val_loss: 0.6074 - learning_rate: 6.7935e-04\n",
            "Epoch 474/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.5457\n",
            "Epoch 474: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5457 - val_accuracy: 0.6262 - val_loss: 0.6176 - learning_rate: 6.7889e-04\n",
            "Epoch 475/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6678 - loss: 0.5622\n",
            "Epoch 475: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6686 - loss: 0.5621 - val_accuracy: 0.6617 - val_loss: 0.6068 - learning_rate: 6.7843e-04\n",
            "Epoch 476/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5283\n",
            "Epoch 476: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5283 - val_accuracy: 0.6748 - val_loss: 0.5994 - learning_rate: 6.7797e-04\n",
            "Epoch 477/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7045 - loss: 0.5617\n",
            "Epoch 477: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.7037 - loss: 0.5623 - val_accuracy: 0.6729 - val_loss: 0.5950 - learning_rate: 6.7751e-04\n",
            "Epoch 478/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5352\n",
            "Epoch 478: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7266 - loss: 0.5352 - val_accuracy: 0.6804 - val_loss: 0.5941 - learning_rate: 6.7705e-04\n",
            "Epoch 479/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6860 - loss: 0.5577\n",
            "Epoch 479: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6855 - loss: 0.5580 - val_accuracy: 0.6542 - val_loss: 0.6046 - learning_rate: 6.7659e-04\n",
            "Epoch 480/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5605\n",
            "Epoch 480: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5605 - val_accuracy: 0.6841 - val_loss: 0.5979 - learning_rate: 6.7613e-04\n",
            "Epoch 481/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6908 - loss: 0.5649\n",
            "Epoch 481: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6902 - loss: 0.5654 - val_accuracy: 0.6393 - val_loss: 0.6066 - learning_rate: 6.7568e-04\n",
            "Epoch 482/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5270\n",
            "Epoch 482: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7344 - loss: 0.5270 - val_accuracy: 0.6766 - val_loss: 0.5946 - learning_rate: 6.7522e-04\n",
            "Epoch 483/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6725 - loss: 0.5695\n",
            "Epoch 483: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6725 - loss: 0.5695 - val_accuracy: 0.6636 - val_loss: 0.6084 - learning_rate: 6.7476e-04\n",
            "Epoch 484/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5595\n",
            "Epoch 484: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5595 - val_accuracy: 0.6748 - val_loss: 0.6018 - learning_rate: 6.7431e-04\n",
            "Epoch 485/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6926 - loss: 0.5617\n",
            "Epoch 485: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6925 - loss: 0.5621 - val_accuracy: 0.6729 - val_loss: 0.5933 - learning_rate: 6.7385e-04\n",
            "Epoch 486/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5261\n",
            "Epoch 486: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5261 - val_accuracy: 0.6860 - val_loss: 0.5936 - learning_rate: 6.7340e-04\n",
            "Epoch 487/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6642 - loss: 0.5698\n",
            "Epoch 487: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6648 - loss: 0.5693 - val_accuracy: 0.6654 - val_loss: 0.5961 - learning_rate: 6.7295e-04\n",
            "Epoch 488/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5755\n",
            "Epoch 488: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5755 - val_accuracy: 0.6561 - val_loss: 0.6139 - learning_rate: 6.7249e-04\n",
            "Epoch 489/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6739 - loss: 0.5608\n",
            "Epoch 489: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6742 - loss: 0.5613 - val_accuracy: 0.6953 - val_loss: 0.5948 - learning_rate: 6.7204e-04\n",
            "Epoch 490/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5747\n",
            "Epoch 490: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6719 - loss: 0.5747 - val_accuracy: 0.6579 - val_loss: 0.5945 - learning_rate: 6.7159e-04\n",
            "Epoch 491/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6892 - loss: 0.5620\n",
            "Epoch 491: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6889 - loss: 0.5622 - val_accuracy: 0.6729 - val_loss: 0.6040 - learning_rate: 6.7114e-04\n",
            "Epoch 492/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5872\n",
            "Epoch 492: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5872 - val_accuracy: 0.6579 - val_loss: 0.6006 - learning_rate: 6.7069e-04\n",
            "Epoch 493/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6695 - loss: 0.5840\n",
            "Epoch 493: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6703 - loss: 0.5835 - val_accuracy: 0.6748 - val_loss: 0.6036 - learning_rate: 6.7024e-04\n",
            "Epoch 494/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5659\n",
            "Epoch 494: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.5659 - val_accuracy: 0.6785 - val_loss: 0.5968 - learning_rate: 6.6979e-04\n",
            "Epoch 495/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6810 - loss: 0.5738\n",
            "Epoch 495: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6809 - loss: 0.5735 - val_accuracy: 0.6729 - val_loss: 0.6002 - learning_rate: 6.6934e-04\n",
            "Epoch 496/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5618\n",
            "Epoch 496: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5618 - val_accuracy: 0.6822 - val_loss: 0.5980 - learning_rate: 6.6890e-04\n",
            "Epoch 497/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6895 - loss: 0.5565\n",
            "Epoch 497: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6887 - loss: 0.5574 - val_accuracy: 0.6617 - val_loss: 0.5975 - learning_rate: 6.6845e-04\n",
            "Epoch 498/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6001\n",
            "Epoch 498: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6001 - val_accuracy: 0.6505 - val_loss: 0.6042 - learning_rate: 6.6800e-04\n",
            "Epoch 499/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6966 - loss: 0.5564\n",
            "Epoch 499: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6958 - loss: 0.5568 - val_accuracy: 0.6729 - val_loss: 0.5990 - learning_rate: 6.6756e-04\n",
            "Epoch 500/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5777\n",
            "Epoch 500: val_loss did not improve from 0.58559\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7031 - loss: 0.5777 - val_accuracy: 0.6841 - val_loss: 0.5950 - learning_rate: 6.6711e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# History of accuracy and loss\n",
        "tra_loss_2 = history_2.history['loss']\n",
        "tra_acc_2 = history_2.history['accuracy']  # Updated key for accuracy\n",
        "val_loss_2 = history_2.history['val_loss']\n",
        "val_acc_2 = history_2.history['val_accuracy']  # Updated key for validation accuracy\n",
        "\n",
        "# Total number of epochs training\n",
        "epochs_2 = range(1, len(tra_acc_2) + 1)\n",
        "end_epoch_2 = len(tra_acc_2)\n",
        "\n",
        "# Epoch when reached the validation loss minimum\n",
        "opt_epoch_2 = val_loss_2.index(min(val_loss_2)) + 1\n",
        "\n",
        "# Loss and accuracy on the validation set\n",
        "end_val_loss_2 = val_loss_2[-1]\n",
        "end_val_acc_2 = val_acc_2[-1]\n",
        "opt_val_loss_2 = val_loss_2[opt_epoch_2 - 1]\n",
        "opt_val_acc_2 = val_acc_2[opt_epoch_2 - 1]\n",
        "\n",
        "# Loss and accuracy on the test set\n",
        "opt_model_2 = models.load_model('model_2_benmal_best.keras')  # Load the best model\n",
        "test_loss_2, test_acc_2 = opt_model_2.evaluate(test_images, test_labels, verbose=False)  # Evaluate the best model\n",
        "opt_test_loss_2, opt_test_acc_2 = test_loss_2, test_acc_2  # Since both are from the same model\n",
        "\n",
        "# Predict using the best model\n",
        "opt_pred_2 = opt_model_2.predict(test_images)  # Only pass test images, not labels\n",
        "pred_classes_2 = np.rint(opt_pred_2)  # Round predictions to get class labels\n",
        "\n",
        "# Print results\n",
        "print(\"Model 2\\n\")\n",
        "print(f\"Epoch [end]: {end_epoch_2}\")\n",
        "print(f\"Epoch [opt]: {opt_epoch_2}\")\n",
        "print(f\"Valid accuracy [end]: {end_val_acc_2:.4f}\")\n",
        "print(f\"Valid accuracy [opt]: {opt_val_acc_2:.4f}\")\n",
        "print(f\"Test accuracy [end]: {test_acc_2:.4f}\")\n",
        "print(f\"Test accuracy [opt]: {opt_test_acc_2:.4f}\")\n",
        "print(f\"Valid loss [end]: {end_val_loss_2:.4f}\")\n",
        "print(f\"Valid loss [opt]: {opt_val_loss_2:.4f}\")\n",
        "print(f\"Test loss [end]: {test_loss_2:.4f}\")\n",
        "print(f\"Test loss [opt]: {opt_test_loss_2:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_labels, pred_classes_2, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaTGU14krQ4a",
        "outputId": "c11c805e-646b-4008-a966-7cce1888cea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
            "Model 2\n",
            "\n",
            "Epoch [end]: 500\n",
            "Epoch [opt]: 457\n",
            "Valid accuracy [end]: 0.6841\n",
            "Valid accuracy [opt]: 0.6654\n",
            "Test accuracy [end]: 0.6577\n",
            "Test accuracy [opt]: 0.6577\n",
            "Valid loss [end]: 0.5950\n",
            "Valid loss [opt]: 0.5856\n",
            "Test loss [end]: 0.6250\n",
            "Test loss [opt]: 0.6250\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7407    0.7306    0.7356       219\n",
            "           1     0.5083    0.5214    0.5148       117\n",
            "\n",
            "    accuracy                         0.6577       336\n",
            "   macro avg     0.6245    0.6260    0.6252       336\n",
            "weighted avg     0.6598    0.6577    0.6587       336\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 accuracy plot\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 2 Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(epochs_2, tra_acc_2, 'r', label='Training set')\n",
        "plt.plot(epochs_2, val_acc_2, 'g', label='Validation set')\n",
        "\n",
        "# Mark the optimal epoch with a green dot\n",
        "plt.plot(opt_epoch_2, val_acc_2[opt_epoch_2 - 1], 'go', markersize=8, label='Optimal Epoch')\n",
        "\n",
        "# Add dashed vertical and horizontal lines for optimal epoch\n",
        "plt.vlines(opt_epoch_2, min(val_acc_2), opt_val_acc_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_acc_2, 1, opt_epoch_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Show plot for accuracy\n",
        "plt.show()\n",
        "\n",
        "# Model 2 loss plot\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 2 Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Set y-axis limits for better visualization\n",
        "plt.ylim(0.48, 0.9)\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(epochs_2, tra_loss_2, 'r', label='Training set')\n",
        "plt.plot(epochs_2, val_loss_2, 'g', label='Validation set')\n",
        "\n",
        "# Mark the optimal epoch with a green dot\n",
        "plt.plot(opt_epoch_2, val_loss_2[opt_epoch_2 - 1], 'go', markersize=8, label='Optimal Epoch')\n",
        "\n",
        "# Add dashed vertical and horizontal lines for optimal epoch\n",
        "plt.vlines(opt_epoch_2, min(val_loss_2), opt_val_loss_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_loss_2, 1, opt_epoch_2, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot for loss\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LjHmF70KrQ3u",
        "outputId": "11e3562c-68ee-45a0-fef4-b15ca8dc0729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = models.Sequential()\n",
        "\n",
        "# Use the Input layer to define input shape\n",
        "model_3.add(layers.Input(shape=(150, 150, 1)))  # Define input shape as 150x150x1\n",
        "\n",
        "# Then, proceed with your convolutional and pooling layers\n",
        "model_3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "model_3.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model_3.add(layers.MaxPooling2D((2, 2)))\n",
        "model_3.add(layers.Flatten())\n",
        "model_3.add(layers.Dense(64, activation='relu'))\n",
        "model_3.add(layers.Dropout(0.5))\n",
        "model_3.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_3.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "zBfZFjX0rQyu",
        "outputId": "55e101ac-77d5-4c43-bd17-1558ea4290f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m640\u001b[0m \n",
              "\n",
              " max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m73,856\u001b[0m \n",
              "\n",
              " max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m295,168\u001b[0m \n",
              "\n",
              " max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m73984\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m4,735,040\u001b[0m \n",
              "\n",
              " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m65\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \n",
              "\n",
              " max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
              "\n",
              " max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
              "\n",
              " max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">73984</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,040</span> \n",
              "\n",
              " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,104,769\u001b[0m (19.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,104,769</span> (19.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,104,769\u001b[0m (19.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,104,769</span> (19.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping (stop training after the validation loss reaches the minimum)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=80, verbose=1)\n",
        "\n",
        "# Callback for checkpointing\n",
        "checkpoint = ModelCheckpoint('model_3_benmal_best.keras',\n",
        "        monitor='val_loss', mode='min', verbose=1,\n",
        "        save_best_only=True, save_freq='epoch'\n",
        ")\n",
        "# Custom decay function to match RMSprop's decay behavior\n",
        "def lr_decay(epoch, lr):\n",
        "    initial_lr = 0.001  # Your initial learning rate\n",
        "    decay_rate = 1e-3  # Same decay as in RMSprop\n",
        "    return initial_lr * (1 / (1 + decay_rate * epoch))\n",
        "\n",
        "# Use the custom decay in the LearningRateScheduler\n",
        "lr_scheduler = LearningRateScheduler(lr_decay)\n",
        "# Compile the model with updated learning rate schedule\n",
        "model_3.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train using the `fit` method instead of the deprecated `fit_generator`\n",
        "history_3 = model_3.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(0.8 * n_train_img) // 128,\n",
        "        epochs=500,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[checkpoint, earlystopping, lr_scheduler],  # Adding early stopping here\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        initial_epoch=0\n",
        ")\n",
        "\n",
        "# Save the final model after training\n",
        "model_3.save('model_3_benmal_end.keras')\n",
        "\n",
        "# Optionally copy the model to Google Drive (if using Colab)\n",
        "!cp model* \"/content/drive/My Drive/FYP_Project/models/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG4bPWWErQwF",
        "outputId": "dc0afeac-bd26-4b3a-8a84-dc3257433224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.5272 - loss: 0.9726\n",
            "Epoch 1: val_loss improved from inf to 0.68912, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 423ms/step - accuracy: 0.5290 - loss: 0.9631 - val_accuracy: 0.5720 - val_loss: 0.6891 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5234 - loss: 0.7037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 0.68912 to 0.68824, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.5234 - loss: 0.7037 - val_accuracy: 0.5720 - val_loss: 0.6882 - learning_rate: 9.9900e-04\n",
            "Epoch 3/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5846 - loss: 0.6850\n",
            "Epoch 3: val_loss improved from 0.68824 to 0.68677, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.5843 - loss: 0.6849 - val_accuracy: 0.5720 - val_loss: 0.6868 - learning_rate: 9.9800e-04\n",
            "Epoch 4/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5484 - loss: 0.6943\n",
            "Epoch 4: val_loss improved from 0.68677 to 0.68247, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5484 - loss: 0.6943 - val_accuracy: 0.5720 - val_loss: 0.6825 - learning_rate: 9.9701e-04\n",
            "Epoch 5/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5740 - loss: 0.6821\n",
            "Epoch 5: val_loss did not improve from 0.68247\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.5744 - loss: 0.6820 - val_accuracy: 0.5720 - val_loss: 0.6829 - learning_rate: 9.9602e-04\n",
            "Epoch 6/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6796\n",
            "Epoch 6: val_loss improved from 0.68247 to 0.68217, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.5938 - loss: 0.6796 - val_accuracy: 0.5720 - val_loss: 0.6822 - learning_rate: 9.9502e-04\n",
            "Epoch 7/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6018 - loss: 0.6760\n",
            "Epoch 7: val_loss improved from 0.68217 to 0.68132, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6011 - loss: 0.6763 - val_accuracy: 0.5720 - val_loss: 0.6813 - learning_rate: 9.9404e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6728\n",
            "Epoch 8: val_loss did not improve from 0.68132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6728 - val_accuracy: 0.5720 - val_loss: 0.6820 - learning_rate: 9.9305e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.5837 - loss: 0.6843\n",
            "Epoch 9: val_loss improved from 0.68132 to 0.67447, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - accuracy: 0.5840 - loss: 0.6840 - val_accuracy: 0.5720 - val_loss: 0.6745 - learning_rate: 9.9206e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6668\n",
            "Epoch 10: val_loss did not improve from 0.67447\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6668 - val_accuracy: 0.5720 - val_loss: 0.6780 - learning_rate: 9.9108e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.5911 - loss: 0.6773\n",
            "Epoch 11: val_loss did not improve from 0.67447\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.5907 - loss: 0.6775 - val_accuracy: 0.5720 - val_loss: 0.6766 - learning_rate: 9.9010e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6315\n",
            "Epoch 12: val_loss did not improve from 0.67447\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6315 - val_accuracy: 0.5720 - val_loss: 0.6806 - learning_rate: 9.8912e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5864 - loss: 0.6711\n",
            "Epoch 13: val_loss improved from 0.67447 to 0.67319, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.5861 - loss: 0.6711 - val_accuracy: 0.5720 - val_loss: 0.6732 - learning_rate: 9.8814e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6696\n",
            "Epoch 14: val_loss improved from 0.67319 to 0.66749, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5781 - loss: 0.6696 - val_accuracy: 0.5720 - val_loss: 0.6675 - learning_rate: 9.8717e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.5939 - loss: 0.6717\n",
            "Epoch 15: val_loss improved from 0.66749 to 0.65954, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.5942 - loss: 0.6714 - val_accuracy: 0.6019 - val_loss: 0.6595 - learning_rate: 9.8619e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6430\n",
            "Epoch 16: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6430 - val_accuracy: 0.5720 - val_loss: 0.7177 - learning_rate: 9.8522e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5907 - loss: 0.6770\n",
            "Epoch 17: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.5908 - loss: 0.6767 - val_accuracy: 0.5963 - val_loss: 0.6622 - learning_rate: 9.8425e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5625 - loss: 0.6612\n",
            "Epoch 18: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5625 - loss: 0.6612 - val_accuracy: 0.5720 - val_loss: 0.6802 - learning_rate: 9.8328e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6087 - loss: 0.6739\n",
            "Epoch 19: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6091 - loss: 0.6736 - val_accuracy: 0.5682 - val_loss: 0.6751 - learning_rate: 9.8232e-04\n",
            "Epoch 20/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5312 - loss: 0.6907\n",
            "Epoch 20: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5312 - loss: 0.6907 - val_accuracy: 0.5720 - val_loss: 0.6819 - learning_rate: 9.8135e-04\n",
            "Epoch 21/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6146 - loss: 0.6641\n",
            "Epoch 21: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6146 - loss: 0.6642 - val_accuracy: 0.5776 - val_loss: 0.6634 - learning_rate: 9.8039e-04\n",
            "Epoch 22/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5161 - loss: 0.6882\n",
            "Epoch 22: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5161 - loss: 0.6882 - val_accuracy: 0.6112 - val_loss: 0.6664 - learning_rate: 9.7943e-04\n",
            "Epoch 23/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6021 - loss: 0.6603\n",
            "Epoch 23: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6023 - loss: 0.6601 - val_accuracy: 0.5757 - val_loss: 0.6767 - learning_rate: 9.7847e-04\n",
            "Epoch 24/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6837\n",
            "Epoch 24: val_loss did not improve from 0.65954\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6837 - val_accuracy: 0.5776 - val_loss: 0.6667 - learning_rate: 9.7752e-04\n",
            "Epoch 25/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.5817 - loss: 0.6678\n",
            "Epoch 25: val_loss improved from 0.65954 to 0.65751, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.5821 - loss: 0.6676 - val_accuracy: 0.5907 - val_loss: 0.6575 - learning_rate: 9.7656e-04\n",
            "Epoch 26/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6237 - loss: 0.6629\n",
            "Epoch 26: val_loss did not improve from 0.65751\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6237 - loss: 0.6629 - val_accuracy: 0.5720 - val_loss: 0.6676 - learning_rate: 9.7561e-04\n",
            "Epoch 27/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6072 - loss: 0.6591\n",
            "Epoch 27: val_loss improved from 0.65751 to 0.65325, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6074 - loss: 0.6590 - val_accuracy: 0.6000 - val_loss: 0.6532 - learning_rate: 9.7466e-04\n",
            "Epoch 28/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5983\n",
            "Epoch 28: val_loss did not improve from 0.65325\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5983 - val_accuracy: 0.5738 - val_loss: 0.6849 - learning_rate: 9.7371e-04\n",
            "Epoch 29/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6286 - loss: 0.6436\n",
            "Epoch 29: val_loss improved from 0.65325 to 0.65217, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.6283 - loss: 0.6440 - val_accuracy: 0.5963 - val_loss: 0.6522 - learning_rate: 9.7276e-04\n",
            "Epoch 30/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6388\n",
            "Epoch 30: val_loss improved from 0.65217 to 0.65058, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6562 - loss: 0.6388 - val_accuracy: 0.6224 - val_loss: 0.6506 - learning_rate: 9.7182e-04\n",
            "Epoch 31/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6224 - loss: 0.6557\n",
            "Epoch 31: val_loss improved from 0.65058 to 0.64655, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6217 - loss: 0.6557 - val_accuracy: 0.6393 - val_loss: 0.6465 - learning_rate: 9.7087e-04\n",
            "Epoch 32/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6376\n",
            "Epoch 32: val_loss improved from 0.64655 to 0.64650, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6797 - loss: 0.6376 - val_accuracy: 0.6355 - val_loss: 0.6465 - learning_rate: 9.6993e-04\n",
            "Epoch 33/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6148 - loss: 0.6569\n",
            "Epoch 33: val_loss did not improve from 0.64650\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6147 - loss: 0.6570 - val_accuracy: 0.6019 - val_loss: 0.6552 - learning_rate: 9.6899e-04\n",
            "Epoch 34/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6719\n",
            "Epoch 34: val_loss did not improve from 0.64650\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5938 - loss: 0.6719 - val_accuracy: 0.6037 - val_loss: 0.6554 - learning_rate: 9.6805e-04\n",
            "Epoch 35/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6378 - loss: 0.6442\n",
            "Epoch 35: val_loss did not improve from 0.64650\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6373 - loss: 0.6448 - val_accuracy: 0.5981 - val_loss: 0.6544 - learning_rate: 9.6712e-04\n",
            "Epoch 36/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6261\n",
            "Epoch 36: val_loss did not improve from 0.64650\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6261 - val_accuracy: 0.6355 - val_loss: 0.6487 - learning_rate: 9.6618e-04\n",
            "Epoch 37/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6178 - loss: 0.6489\n",
            "Epoch 37: val_loss improved from 0.64650 to 0.64626, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 284ms/step - accuracy: 0.6184 - loss: 0.6487 - val_accuracy: 0.6411 - val_loss: 0.6463 - learning_rate: 9.6525e-04\n",
            "Epoch 38/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6527\n",
            "Epoch 38: val_loss did not improve from 0.64626\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6527 - val_accuracy: 0.5925 - val_loss: 0.6608 - learning_rate: 9.6432e-04\n",
            "Epoch 39/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6440 - loss: 0.6486\n",
            "Epoch 39: val_loss improved from 0.64626 to 0.64153, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6441 - loss: 0.6485 - val_accuracy: 0.6037 - val_loss: 0.6415 - learning_rate: 9.6339e-04\n",
            "Epoch 40/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6294\n",
            "Epoch 40: val_loss did not improve from 0.64153\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6294 - val_accuracy: 0.6318 - val_loss: 0.6455 - learning_rate: 9.6246e-04\n",
            "Epoch 41/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6333 - loss: 0.6389\n",
            "Epoch 41: val_loss improved from 0.64153 to 0.64010, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6333 - loss: 0.6391 - val_accuracy: 0.6393 - val_loss: 0.6401 - learning_rate: 9.6154e-04\n",
            "Epoch 42/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5625 - loss: 0.7022\n",
            "Epoch 42: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5625 - loss: 0.7022 - val_accuracy: 0.6224 - val_loss: 0.6462 - learning_rate: 9.6061e-04\n",
            "Epoch 43/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6220 - loss: 0.6498\n",
            "Epoch 43: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6221 - loss: 0.6498 - val_accuracy: 0.6206 - val_loss: 0.6474 - learning_rate: 9.5969e-04\n",
            "Epoch 44/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.6013\n",
            "Epoch 44: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.6013 - val_accuracy: 0.6449 - val_loss: 0.6430 - learning_rate: 9.5877e-04\n",
            "Epoch 45/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6437 - loss: 0.6490\n",
            "Epoch 45: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6435 - loss: 0.6486 - val_accuracy: 0.5813 - val_loss: 0.6994 - learning_rate: 9.5785e-04\n",
            "Epoch 46/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6892\n",
            "Epoch 46: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6016 - loss: 0.6892 - val_accuracy: 0.5850 - val_loss: 0.6471 - learning_rate: 9.5694e-04\n",
            "Epoch 47/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6226 - loss: 0.6553\n",
            "Epoch 47: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6231 - loss: 0.6545 - val_accuracy: 0.6449 - val_loss: 0.6519 - learning_rate: 9.5602e-04\n",
            "Epoch 48/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5914 - loss: 0.6961\n",
            "Epoch 48: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5914 - loss: 0.6961 - val_accuracy: 0.6150 - val_loss: 0.6535 - learning_rate: 9.5511e-04\n",
            "Epoch 49/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6391 - loss: 0.6437\n",
            "Epoch 49: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6395 - loss: 0.6435 - val_accuracy: 0.6299 - val_loss: 0.6402 - learning_rate: 9.5420e-04\n",
            "Epoch 50/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5984\n",
            "Epoch 50: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5984 - val_accuracy: 0.5832 - val_loss: 0.6479 - learning_rate: 9.5329e-04\n",
            "Epoch 51/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6368 - loss: 0.6409\n",
            "Epoch 51: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6368 - loss: 0.6408 - val_accuracy: 0.6131 - val_loss: 0.6511 - learning_rate: 9.5238e-04\n",
            "Epoch 52/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6566\n",
            "Epoch 52: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6566 - val_accuracy: 0.6000 - val_loss: 0.6497 - learning_rate: 9.5147e-04\n",
            "Epoch 53/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6503 - loss: 0.6307\n",
            "Epoch 53: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6503 - loss: 0.6309 - val_accuracy: 0.6150 - val_loss: 0.6457 - learning_rate: 9.5057e-04\n",
            "Epoch 54/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5703 - loss: 0.6714\n",
            "Epoch 54: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5703 - loss: 0.6714 - val_accuracy: 0.6206 - val_loss: 0.6442 - learning_rate: 9.4967e-04\n",
            "Epoch 55/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6588 - loss: 0.6295\n",
            "Epoch 55: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6583 - loss: 0.6299 - val_accuracy: 0.5981 - val_loss: 0.6552 - learning_rate: 9.4877e-04\n",
            "Epoch 56/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6567\n",
            "Epoch 56: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6567 - val_accuracy: 0.6374 - val_loss: 0.6455 - learning_rate: 9.4787e-04\n",
            "Epoch 57/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6488 - loss: 0.6348\n",
            "Epoch 57: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - accuracy: 0.6487 - loss: 0.6348 - val_accuracy: 0.6318 - val_loss: 0.6415 - learning_rate: 9.4697e-04\n",
            "Epoch 58/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6345\n",
            "Epoch 58: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6345 - val_accuracy: 0.6000 - val_loss: 0.6464 - learning_rate: 9.4607e-04\n",
            "Epoch 59/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6391 - loss: 0.6462\n",
            "Epoch 59: val_loss did not improve from 0.64010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6394 - loss: 0.6459 - val_accuracy: 0.6112 - val_loss: 0.6427 - learning_rate: 9.4518e-04\n",
            "Epoch 60/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6599\n",
            "Epoch 60: val_loss improved from 0.64010 to 0.63679, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6406 - loss: 0.6599 - val_accuracy: 0.6374 - val_loss: 0.6368 - learning_rate: 9.4429e-04\n",
            "Epoch 61/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6231 - loss: 0.6411\n",
            "Epoch 61: val_loss did not improve from 0.63679\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6231 - loss: 0.6411 - val_accuracy: 0.6374 - val_loss: 0.6380 - learning_rate: 9.4340e-04\n",
            "Epoch 62/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5778\n",
            "Epoch 62: val_loss improved from 0.63679 to 0.63488, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6797 - loss: 0.5778 - val_accuracy: 0.6374 - val_loss: 0.6349 - learning_rate: 9.4251e-04\n",
            "Epoch 63/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6536 - loss: 0.6316\n",
            "Epoch 63: val_loss did not improve from 0.63488\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6529 - loss: 0.6318 - val_accuracy: 0.5925 - val_loss: 0.6449 - learning_rate: 9.4162e-04\n",
            "Epoch 64/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5703 - loss: 0.6609\n",
            "Epoch 64: val_loss improved from 0.63488 to 0.63297, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5703 - loss: 0.6609 - val_accuracy: 0.6224 - val_loss: 0.6330 - learning_rate: 9.4073e-04\n",
            "Epoch 65/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6396 - loss: 0.6352\n",
            "Epoch 65: val_loss did not improve from 0.63297\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6398 - loss: 0.6348 - val_accuracy: 0.6206 - val_loss: 0.6374 - learning_rate: 9.3985e-04\n",
            "Epoch 66/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6130\n",
            "Epoch 66: val_loss did not improve from 0.63297\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6130 - val_accuracy: 0.6019 - val_loss: 0.6630 - learning_rate: 9.3897e-04\n",
            "Epoch 67/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6326 - loss: 0.6416\n",
            "Epoch 67: val_loss improved from 0.63297 to 0.63197, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6332 - loss: 0.6410 - val_accuracy: 0.6280 - val_loss: 0.6320 - learning_rate: 9.3809e-04\n",
            "Epoch 68/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6225\n",
            "Epoch 68: val_loss did not improve from 0.63197\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6225 - val_accuracy: 0.6019 - val_loss: 0.6572 - learning_rate: 9.3721e-04\n",
            "Epoch 69/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6322 - loss: 0.6390\n",
            "Epoch 69: val_loss did not improve from 0.63197\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6326 - loss: 0.6385 - val_accuracy: 0.6318 - val_loss: 0.6374 - learning_rate: 9.3633e-04\n",
            "Epoch 70/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.6500\n",
            "Epoch 70: val_loss did not improve from 0.63197\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5938 - loss: 0.6500 - val_accuracy: 0.6336 - val_loss: 0.6349 - learning_rate: 9.3545e-04\n",
            "Epoch 71/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6467 - loss: 0.6437\n",
            "Epoch 71: val_loss did not improve from 0.63197\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - accuracy: 0.6469 - loss: 0.6428 - val_accuracy: 0.6187 - val_loss: 0.6436 - learning_rate: 9.3458e-04\n",
            "Epoch 72/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6536\n",
            "Epoch 72: val_loss did not improve from 0.63197\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6536 - val_accuracy: 0.6336 - val_loss: 0.6384 - learning_rate: 9.3371e-04\n",
            "Epoch 73/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6157 - loss: 0.6406\n",
            "Epoch 73: val_loss did not improve from 0.63197\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6166 - loss: 0.6403 - val_accuracy: 0.6187 - val_loss: 0.6396 - learning_rate: 9.3284e-04\n",
            "Epoch 74/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.6051\n",
            "Epoch 74: val_loss did not improve from 0.63197\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.6051 - val_accuracy: 0.6037 - val_loss: 0.6499 - learning_rate: 9.3197e-04\n",
            "Epoch 75/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6517 - loss: 0.6360\n",
            "Epoch 75: val_loss improved from 0.63197 to 0.63077, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6511 - loss: 0.6360 - val_accuracy: 0.6318 - val_loss: 0.6308 - learning_rate: 9.3110e-04\n",
            "Epoch 76/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5747\n",
            "Epoch 76: val_loss improved from 0.63077 to 0.62926, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6719 - loss: 0.5747 - val_accuracy: 0.6299 - val_loss: 0.6293 - learning_rate: 9.3023e-04\n",
            "Epoch 77/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6357 - loss: 0.6333\n",
            "Epoch 77: val_loss did not improve from 0.62926\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6361 - loss: 0.6332 - val_accuracy: 0.6262 - val_loss: 0.6325 - learning_rate: 9.2937e-04\n",
            "Epoch 78/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.6163\n",
            "Epoch 78: val_loss did not improve from 0.62926\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.6163 - val_accuracy: 0.6393 - val_loss: 0.6293 - learning_rate: 9.2851e-04\n",
            "Epoch 79/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6441 - loss: 0.6272\n",
            "Epoch 79: val_loss did not improve from 0.62926\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6443 - loss: 0.6271 - val_accuracy: 0.6280 - val_loss: 0.6300 - learning_rate: 9.2764e-04\n",
            "Epoch 80/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.6121\n",
            "Epoch 80: val_loss improved from 0.62926 to 0.62758, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7031 - loss: 0.6121 - val_accuracy: 0.6355 - val_loss: 0.6276 - learning_rate: 9.2678e-04\n",
            "Epoch 81/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6325 - loss: 0.6376\n",
            "Epoch 81: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6332 - loss: 0.6371 - val_accuracy: 0.6112 - val_loss: 0.6351 - learning_rate: 9.2593e-04\n",
            "Epoch 82/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5990\n",
            "Epoch 82: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5990 - val_accuracy: 0.6131 - val_loss: 0.6449 - learning_rate: 9.2507e-04\n",
            "Epoch 83/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6175 - loss: 0.6364\n",
            "Epoch 83: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6181 - loss: 0.6362 - val_accuracy: 0.6187 - val_loss: 0.6287 - learning_rate: 9.2421e-04\n",
            "Epoch 84/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6091\n",
            "Epoch 84: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6091 - val_accuracy: 0.5981 - val_loss: 0.6469 - learning_rate: 9.2336e-04\n",
            "Epoch 85/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6261 - loss: 0.6313\n",
            "Epoch 85: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6270 - loss: 0.6313 - val_accuracy: 0.6393 - val_loss: 0.6372 - learning_rate: 9.2251e-04\n",
            "Epoch 86/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6696\n",
            "Epoch 86: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6094 - loss: 0.6696 - val_accuracy: 0.6093 - val_loss: 0.6399 - learning_rate: 9.2166e-04\n",
            "Epoch 87/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6567 - loss: 0.6181\n",
            "Epoch 87: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6562 - loss: 0.6185 - val_accuracy: 0.6486 - val_loss: 0.6315 - learning_rate: 9.2081e-04\n",
            "Epoch 88/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6452 - loss: 0.6496\n",
            "Epoch 88: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6452 - loss: 0.6496 - val_accuracy: 0.6112 - val_loss: 0.6384 - learning_rate: 9.1996e-04\n",
            "Epoch 89/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6396 - loss: 0.6199\n",
            "Epoch 89: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6395 - loss: 0.6202 - val_accuracy: 0.6393 - val_loss: 0.6283 - learning_rate: 9.1912e-04\n",
            "Epoch 90/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6362\n",
            "Epoch 90: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6362 - val_accuracy: 0.6449 - val_loss: 0.6312 - learning_rate: 9.1827e-04\n",
            "Epoch 91/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6385 - loss: 0.6364\n",
            "Epoch 91: val_loss did not improve from 0.62758\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6390 - loss: 0.6357 - val_accuracy: 0.6299 - val_loss: 0.6335 - learning_rate: 9.1743e-04\n",
            "Epoch 92/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6793\n",
            "Epoch 92: val_loss improved from 0.62758 to 0.62576, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5859 - loss: 0.6793 - val_accuracy: 0.6411 - val_loss: 0.6258 - learning_rate: 9.1659e-04\n",
            "Epoch 93/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6481 - loss: 0.6277\n",
            "Epoch 93: val_loss did not improve from 0.62576\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6483 - loss: 0.6278 - val_accuracy: 0.6393 - val_loss: 0.6265 - learning_rate: 9.1575e-04\n",
            "Epoch 94/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6504\n",
            "Epoch 94: val_loss did not improve from 0.62576\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6504 - val_accuracy: 0.6037 - val_loss: 0.6413 - learning_rate: 9.1491e-04\n",
            "Epoch 95/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6472 - loss: 0.6209\n",
            "Epoch 95: val_loss did not improve from 0.62576\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6467 - loss: 0.6214 - val_accuracy: 0.6299 - val_loss: 0.6264 - learning_rate: 9.1408e-04\n",
            "Epoch 96/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6353\n",
            "Epoch 96: val_loss did not improve from 0.62576\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6719 - loss: 0.6353 - val_accuracy: 0.6280 - val_loss: 0.6312 - learning_rate: 9.1324e-04\n",
            "Epoch 97/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6470 - loss: 0.6221\n",
            "Epoch 97: val_loss improved from 0.62576 to 0.62510, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6467 - loss: 0.6221 - val_accuracy: 0.6336 - val_loss: 0.6251 - learning_rate: 9.1241e-04\n",
            "Epoch 98/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6291\n",
            "Epoch 98: val_loss did not improve from 0.62510\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6291 - val_accuracy: 0.6280 - val_loss: 0.6265 - learning_rate: 9.1158e-04\n",
            "Epoch 99/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6354 - loss: 0.6275\n",
            "Epoch 99: val_loss did not improve from 0.62510\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6356 - loss: 0.6275 - val_accuracy: 0.6112 - val_loss: 0.6348 - learning_rate: 9.1075e-04\n",
            "Epoch 100/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6109\n",
            "Epoch 100: val_loss did not improve from 0.62510\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5859 - loss: 0.6109 - val_accuracy: 0.6280 - val_loss: 0.6269 - learning_rate: 9.0992e-04\n",
            "Epoch 101/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6614 - loss: 0.6146\n",
            "Epoch 101: val_loss did not improve from 0.62510\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6602 - loss: 0.6151 - val_accuracy: 0.6374 - val_loss: 0.6254 - learning_rate: 9.0909e-04\n",
            "Epoch 102/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6021\n",
            "Epoch 102: val_loss improved from 0.62510 to 0.61996, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6641 - loss: 0.6021 - val_accuracy: 0.6542 - val_loss: 0.6200 - learning_rate: 9.0827e-04\n",
            "Epoch 103/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6413 - loss: 0.6117\n",
            "Epoch 103: val_loss did not improve from 0.61996\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6405 - loss: 0.6125 - val_accuracy: 0.5944 - val_loss: 0.6347 - learning_rate: 9.0744e-04\n",
            "Epoch 104/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6215\n",
            "Epoch 104: val_loss did not improve from 0.61996\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6250 - loss: 0.6215 - val_accuracy: 0.6336 - val_loss: 0.6283 - learning_rate: 9.0662e-04\n",
            "Epoch 105/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6241 - loss: 0.6188\n",
            "Epoch 105: val_loss improved from 0.61996 to 0.61959, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.6250 - loss: 0.6188 - val_accuracy: 0.6411 - val_loss: 0.6196 - learning_rate: 9.0580e-04\n",
            "Epoch 106/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5856\n",
            "Epoch 106: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5856 - val_accuracy: 0.6561 - val_loss: 0.6196 - learning_rate: 9.0498e-04\n",
            "Epoch 107/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6332 - loss: 0.6282\n",
            "Epoch 107: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6334 - loss: 0.6278 - val_accuracy: 0.6393 - val_loss: 0.6250 - learning_rate: 9.0416e-04\n",
            "Epoch 108/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6063\n",
            "Epoch 108: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6063 - val_accuracy: 0.6318 - val_loss: 0.6241 - learning_rate: 9.0334e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6379 - loss: 0.6156\n",
            "Epoch 109: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6381 - loss: 0.6157 - val_accuracy: 0.6280 - val_loss: 0.6275 - learning_rate: 9.0253e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6063\n",
            "Epoch 110: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6063 - val_accuracy: 0.6336 - val_loss: 0.6224 - learning_rate: 9.0171e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6398 - loss: 0.6092\n",
            "Epoch 111: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6399 - loss: 0.6098 - val_accuracy: 0.6318 - val_loss: 0.6213 - learning_rate: 9.0090e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5944\n",
            "Epoch 112: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5944 - val_accuracy: 0.6299 - val_loss: 0.6246 - learning_rate: 9.0009e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6389 - loss: 0.6076\n",
            "Epoch 113: val_loss did not improve from 0.61959\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6391 - loss: 0.6083 - val_accuracy: 0.6262 - val_loss: 0.6252 - learning_rate: 8.9928e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6072\n",
            "Epoch 114: val_loss improved from 0.61959 to 0.61739, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6797 - loss: 0.6072 - val_accuracy: 0.6299 - val_loss: 0.6174 - learning_rate: 8.9847e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6543 - loss: 0.6179\n",
            "Epoch 115: val_loss did not improve from 0.61739\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6542 - loss: 0.6177 - val_accuracy: 0.6336 - val_loss: 0.6210 - learning_rate: 8.9767e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6144\n",
            "Epoch 116: val_loss did not improve from 0.61739\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6144 - val_accuracy: 0.6299 - val_loss: 0.6205 - learning_rate: 8.9686e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6565 - loss: 0.6233\n",
            "Epoch 117: val_loss did not improve from 0.61739\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6561 - loss: 0.6233 - val_accuracy: 0.6467 - val_loss: 0.6230 - learning_rate: 8.9606e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5746\n",
            "Epoch 118: val_loss did not improve from 0.61739\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5746 - val_accuracy: 0.6262 - val_loss: 0.6337 - learning_rate: 8.9526e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6372 - loss: 0.6154\n",
            "Epoch 119: val_loss improved from 0.61739 to 0.61552, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.6378 - loss: 0.6152 - val_accuracy: 0.6393 - val_loss: 0.6155 - learning_rate: 8.9445e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6293\n",
            "Epoch 120: val_loss did not improve from 0.61552\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6293 - val_accuracy: 0.6299 - val_loss: 0.6222 - learning_rate: 8.9366e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6441 - loss: 0.6140\n",
            "Epoch 121: val_loss did not improve from 0.61552\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6440 - loss: 0.6143 - val_accuracy: 0.6374 - val_loss: 0.6180 - learning_rate: 8.9286e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5966\n",
            "Epoch 122: val_loss did not improve from 0.61552\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5966 - val_accuracy: 0.6374 - val_loss: 0.6257 - learning_rate: 8.9206e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6340 - loss: 0.6101\n",
            "Epoch 123: val_loss did not improve from 0.61552\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6346 - loss: 0.6099 - val_accuracy: 0.6075 - val_loss: 0.6281 - learning_rate: 8.9127e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6344 - loss: 0.6324\n",
            "Epoch 124: val_loss did not improve from 0.61552\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6344 - loss: 0.6324 - val_accuracy: 0.6299 - val_loss: 0.6199 - learning_rate: 8.9047e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6348 - loss: 0.6237\n",
            "Epoch 125: val_loss did not improve from 0.61552\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6346 - loss: 0.6237 - val_accuracy: 0.6393 - val_loss: 0.6174 - learning_rate: 8.8968e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5886\n",
            "Epoch 126: val_loss did not improve from 0.61552\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5886 - val_accuracy: 0.6336 - val_loss: 0.6159 - learning_rate: 8.8889e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6496 - loss: 0.6204\n",
            "Epoch 127: val_loss improved from 0.61552 to 0.61414, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6496 - loss: 0.6199 - val_accuracy: 0.6449 - val_loss: 0.6141 - learning_rate: 8.8810e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.6010\n",
            "Epoch 128: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.6010 - val_accuracy: 0.6411 - val_loss: 0.6216 - learning_rate: 8.8731e-04\n",
            "Epoch 129/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6464 - loss: 0.6156\n",
            "Epoch 129: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6466 - loss: 0.6153 - val_accuracy: 0.6280 - val_loss: 0.6215 - learning_rate: 8.8652e-04\n",
            "Epoch 130/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6114\n",
            "Epoch 130: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6114 - val_accuracy: 0.6318 - val_loss: 0.6198 - learning_rate: 8.8574e-04\n",
            "Epoch 131/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6516 - loss: 0.6076\n",
            "Epoch 131: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6516 - loss: 0.6078 - val_accuracy: 0.6224 - val_loss: 0.6196 - learning_rate: 8.8496e-04\n",
            "Epoch 132/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5729\n",
            "Epoch 132: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5729 - val_accuracy: 0.6280 - val_loss: 0.6173 - learning_rate: 8.8417e-04\n",
            "Epoch 133/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6523 - loss: 0.6111\n",
            "Epoch 133: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6519 - loss: 0.6114 - val_accuracy: 0.6467 - val_loss: 0.6215 - learning_rate: 8.8339e-04\n",
            "Epoch 134/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5933\n",
            "Epoch 134: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5933 - val_accuracy: 0.6336 - val_loss: 0.6209 - learning_rate: 8.8261e-04\n",
            "Epoch 135/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6471 - loss: 0.6036\n",
            "Epoch 135: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6475 - loss: 0.6036 - val_accuracy: 0.6336 - val_loss: 0.6199 - learning_rate: 8.8183e-04\n",
            "Epoch 136/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5862\n",
            "Epoch 136: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5862 - val_accuracy: 0.6280 - val_loss: 0.6242 - learning_rate: 8.8106e-04\n",
            "Epoch 137/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6508 - loss: 0.6109\n",
            "Epoch 137: val_loss did not improve from 0.61414\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6506 - loss: 0.6111 - val_accuracy: 0.6374 - val_loss: 0.6158 - learning_rate: 8.8028e-04\n",
            "Epoch 138/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5829\n",
            "Epoch 138: val_loss improved from 0.61414 to 0.61132, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7109 - loss: 0.5829 - val_accuracy: 0.6355 - val_loss: 0.6113 - learning_rate: 8.7951e-04\n",
            "Epoch 139/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6506 - loss: 0.6105\n",
            "Epoch 139: val_loss did not improve from 0.61132\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6508 - loss: 0.6103 - val_accuracy: 0.6411 - val_loss: 0.6181 - learning_rate: 8.7873e-04\n",
            "Epoch 140/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5805\n",
            "Epoch 140: val_loss improved from 0.61132 to 0.61107, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6562 - loss: 0.5805 - val_accuracy: 0.6280 - val_loss: 0.6111 - learning_rate: 8.7796e-04\n",
            "Epoch 141/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6517 - loss: 0.6034\n",
            "Epoch 141: val_loss did not improve from 0.61107\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6516 - loss: 0.6035 - val_accuracy: 0.6056 - val_loss: 0.6375 - learning_rate: 8.7719e-04\n",
            "Epoch 142/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5841\n",
            "Epoch 142: val_loss did not improve from 0.61107\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5841 - val_accuracy: 0.6112 - val_loss: 0.6403 - learning_rate: 8.7642e-04\n",
            "Epoch 143/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6476 - loss: 0.6249\n",
            "Epoch 143: val_loss did not improve from 0.61107\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6488 - loss: 0.6235 - val_accuracy: 0.6243 - val_loss: 0.6242 - learning_rate: 8.7566e-04\n",
            "Epoch 144/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6108\n",
            "Epoch 144: val_loss improved from 0.61107 to 0.60962, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6328 - loss: 0.6108 - val_accuracy: 0.6374 - val_loss: 0.6096 - learning_rate: 8.7489e-04\n",
            "Epoch 145/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6543 - loss: 0.5962\n",
            "Epoch 145: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6540 - loss: 0.5965 - val_accuracy: 0.6280 - val_loss: 0.6168 - learning_rate: 8.7413e-04\n",
            "Epoch 146/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5703 - loss: 0.6174\n",
            "Epoch 146: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5703 - loss: 0.6174 - val_accuracy: 0.6280 - val_loss: 0.6125 - learning_rate: 8.7336e-04\n",
            "Epoch 147/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6557 - loss: 0.5973\n",
            "Epoch 147: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6551 - loss: 0.5977 - val_accuracy: 0.6374 - val_loss: 0.6219 - learning_rate: 8.7260e-04\n",
            "Epoch 148/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5310\n",
            "Epoch 148: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5310 - val_accuracy: 0.6355 - val_loss: 0.6172 - learning_rate: 8.7184e-04\n",
            "Epoch 149/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6322 - loss: 0.6140\n",
            "Epoch 149: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6332 - loss: 0.6135 - val_accuracy: 0.6318 - val_loss: 0.6115 - learning_rate: 8.7108e-04\n",
            "Epoch 150/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.5952\n",
            "Epoch 150: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.5952 - val_accuracy: 0.6374 - val_loss: 0.6165 - learning_rate: 8.7032e-04\n",
            "Epoch 151/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6625 - loss: 0.6146\n",
            "Epoch 151: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6623 - loss: 0.6139 - val_accuracy: 0.6336 - val_loss: 0.6268 - learning_rate: 8.6957e-04\n",
            "Epoch 152/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6164\n",
            "Epoch 152: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.6164 - val_accuracy: 0.6224 - val_loss: 0.6132 - learning_rate: 8.6881e-04\n",
            "Epoch 153/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6403 - loss: 0.5991\n",
            "Epoch 153: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6409 - loss: 0.5992 - val_accuracy: 0.6336 - val_loss: 0.6179 - learning_rate: 8.6806e-04\n",
            "Epoch 154/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6053\n",
            "Epoch 154: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.6053 - val_accuracy: 0.6374 - val_loss: 0.6126 - learning_rate: 8.6730e-04\n",
            "Epoch 155/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6632 - loss: 0.6043\n",
            "Epoch 155: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6635 - loss: 0.6039 - val_accuracy: 0.6187 - val_loss: 0.6315 - learning_rate: 8.6655e-04\n",
            "Epoch 156/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6178\n",
            "Epoch 156: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5781 - loss: 0.6178 - val_accuracy: 0.6093 - val_loss: 0.6180 - learning_rate: 8.6580e-04\n",
            "Epoch 157/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6486 - loss: 0.6038\n",
            "Epoch 157: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6490 - loss: 0.6037 - val_accuracy: 0.6299 - val_loss: 0.6150 - learning_rate: 8.6505e-04\n",
            "Epoch 158/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6205\n",
            "Epoch 158: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6205 - val_accuracy: 0.6393 - val_loss: 0.6121 - learning_rate: 8.6430e-04\n",
            "Epoch 159/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6528 - loss: 0.6098\n",
            "Epoch 159: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6532 - loss: 0.6095 - val_accuracy: 0.6430 - val_loss: 0.6122 - learning_rate: 8.6356e-04\n",
            "Epoch 160/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5635\n",
            "Epoch 160: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.5635 - val_accuracy: 0.6299 - val_loss: 0.6162 - learning_rate: 8.6281e-04\n",
            "Epoch 161/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6683 - loss: 0.6001\n",
            "Epoch 161: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6678 - loss: 0.5999 - val_accuracy: 0.6374 - val_loss: 0.6171 - learning_rate: 8.6207e-04\n",
            "Epoch 162/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6588\n",
            "Epoch 162: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5859 - loss: 0.6588 - val_accuracy: 0.6280 - val_loss: 0.6118 - learning_rate: 8.6133e-04\n",
            "Epoch 163/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6467 - loss: 0.5951\n",
            "Epoch 163: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6470 - loss: 0.5952 - val_accuracy: 0.6430 - val_loss: 0.6130 - learning_rate: 8.6059e-04\n",
            "Epoch 164/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6220\n",
            "Epoch 164: val_loss did not improve from 0.60962\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.6220 - val_accuracy: 0.6505 - val_loss: 0.6102 - learning_rate: 8.5985e-04\n",
            "Epoch 165/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6759 - loss: 0.5937\n",
            "Epoch 165: val_loss improved from 0.60962 to 0.60581, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6751 - loss: 0.5944 - val_accuracy: 0.6299 - val_loss: 0.6058 - learning_rate: 8.5911e-04\n",
            "Epoch 166/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5846\n",
            "Epoch 166: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5846 - val_accuracy: 0.6430 - val_loss: 0.6110 - learning_rate: 8.5837e-04\n",
            "Epoch 167/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6738 - loss: 0.5929\n",
            "Epoch 167: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6729 - loss: 0.5934 - val_accuracy: 0.6523 - val_loss: 0.6097 - learning_rate: 8.5763e-04\n",
            "Epoch 168/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.5855\n",
            "Epoch 168: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.5855 - val_accuracy: 0.6374 - val_loss: 0.6143 - learning_rate: 8.5690e-04\n",
            "Epoch 169/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6540 - loss: 0.6016\n",
            "Epoch 169: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6543 - loss: 0.6017 - val_accuracy: 0.6486 - val_loss: 0.6130 - learning_rate: 8.5616e-04\n",
            "Epoch 170/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6314\n",
            "Epoch 170: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5781 - loss: 0.6314 - val_accuracy: 0.6299 - val_loss: 0.6111 - learning_rate: 8.5543e-04\n",
            "Epoch 171/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6697 - loss: 0.5925\n",
            "Epoch 171: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6691 - loss: 0.5929 - val_accuracy: 0.6280 - val_loss: 0.6138 - learning_rate: 8.5470e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5889\n",
            "Epoch 172: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5889 - val_accuracy: 0.6430 - val_loss: 0.6105 - learning_rate: 8.5397e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6453 - loss: 0.6000\n",
            "Epoch 173: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6462 - loss: 0.5995 - val_accuracy: 0.6486 - val_loss: 0.6149 - learning_rate: 8.5324e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5321\n",
            "Epoch 174: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5321 - val_accuracy: 0.6393 - val_loss: 0.6246 - learning_rate: 8.5251e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6581 - loss: 0.5979\n",
            "Epoch 175: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6576 - loss: 0.5981 - val_accuracy: 0.6355 - val_loss: 0.6117 - learning_rate: 8.5179e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6774 - loss: 0.5375\n",
            "Epoch 176: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6774 - loss: 0.5375 - val_accuracy: 0.6505 - val_loss: 0.6090 - learning_rate: 8.5106e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6564 - loss: 0.6002\n",
            "Epoch 177: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6574 - loss: 0.5995 - val_accuracy: 0.6505 - val_loss: 0.6064 - learning_rate: 8.5034e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5547 - loss: 0.6727\n",
            "Epoch 178: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5547 - loss: 0.6727 - val_accuracy: 0.6187 - val_loss: 0.6356 - learning_rate: 8.4962e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6377 - loss: 0.6166\n",
            "Epoch 179: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6386 - loss: 0.6156 - val_accuracy: 0.6486 - val_loss: 0.6117 - learning_rate: 8.4890e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.6079\n",
            "Epoch 180: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.6079 - val_accuracy: 0.6449 - val_loss: 0.6144 - learning_rate: 8.4818e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6461 - loss: 0.5949\n",
            "Epoch 181: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6467 - loss: 0.5949 - val_accuracy: 0.6131 - val_loss: 0.6319 - learning_rate: 8.4746e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.6061\n",
            "Epoch 182: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6406 - loss: 0.6061 - val_accuracy: 0.6449 - val_loss: 0.6076 - learning_rate: 8.4674e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6444 - loss: 0.6010\n",
            "Epoch 183: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6450 - loss: 0.6008 - val_accuracy: 0.6542 - val_loss: 0.6078 - learning_rate: 8.4602e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5430\n",
            "Epoch 184: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7344 - loss: 0.5430 - val_accuracy: 0.6467 - val_loss: 0.6071 - learning_rate: 8.4531e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6638 - loss: 0.5955\n",
            "Epoch 185: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6639 - loss: 0.5958 - val_accuracy: 0.6486 - val_loss: 0.6073 - learning_rate: 8.4459e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.5617\n",
            "Epoch 186: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5617 - val_accuracy: 0.6374 - val_loss: 0.6194 - learning_rate: 8.4388e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6704 - loss: 0.5923\n",
            "Epoch 187: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6702 - loss: 0.5928 - val_accuracy: 0.6336 - val_loss: 0.6168 - learning_rate: 8.4317e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.6021\n",
            "Epoch 188: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6021 - val_accuracy: 0.6467 - val_loss: 0.6059 - learning_rate: 8.4246e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6746 - loss: 0.5895\n",
            "Epoch 189: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6740 - loss: 0.5895 - val_accuracy: 0.6449 - val_loss: 0.6134 - learning_rate: 8.4175e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.6260\n",
            "Epoch 190: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.6260 - val_accuracy: 0.6280 - val_loss: 0.6224 - learning_rate: 8.4104e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6637 - loss: 0.5873\n",
            "Epoch 191: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6637 - loss: 0.5875 - val_accuracy: 0.6617 - val_loss: 0.6071 - learning_rate: 8.4034e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.5820\n",
            "Epoch 192: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.5820 - val_accuracy: 0.6542 - val_loss: 0.6093 - learning_rate: 8.3963e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6514 - loss: 0.5900\n",
            "Epoch 193: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6516 - loss: 0.5903 - val_accuracy: 0.6523 - val_loss: 0.6128 - learning_rate: 8.3893e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.6020\n",
            "Epoch 194: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7266 - loss: 0.6020 - val_accuracy: 0.6318 - val_loss: 0.6208 - learning_rate: 8.3822e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6481 - loss: 0.5926\n",
            "Epoch 195: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6486 - loss: 0.5930 - val_accuracy: 0.6486 - val_loss: 0.6071 - learning_rate: 8.3752e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6291\n",
            "Epoch 196: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6291 - val_accuracy: 0.6486 - val_loss: 0.6090 - learning_rate: 8.3682e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6717 - loss: 0.5958\n",
            "Epoch 197: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6709 - loss: 0.5960 - val_accuracy: 0.6206 - val_loss: 0.6212 - learning_rate: 8.3612e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5782\n",
            "Epoch 198: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5782 - val_accuracy: 0.6449 - val_loss: 0.6180 - learning_rate: 8.3542e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6720 - loss: 0.5763\n",
            "Epoch 199: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6719 - loss: 0.5769 - val_accuracy: 0.6430 - val_loss: 0.6129 - learning_rate: 8.3472e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6250 - loss: 0.6202\n",
            "Epoch 200: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6250 - loss: 0.6202 - val_accuracy: 0.6318 - val_loss: 0.6161 - learning_rate: 8.3403e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6492 - loss: 0.5897\n",
            "Epoch 201: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6497 - loss: 0.5897 - val_accuracy: 0.6056 - val_loss: 0.6281 - learning_rate: 8.3333e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.6068\n",
            "Epoch 202: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.6068 - val_accuracy: 0.6411 - val_loss: 0.6128 - learning_rate: 8.3264e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6678 - loss: 0.5926\n",
            "Epoch 203: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6675 - loss: 0.5930 - val_accuracy: 0.6336 - val_loss: 0.6197 - learning_rate: 8.3195e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.5410\n",
            "Epoch 204: val_loss did not improve from 0.60581\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5410 - val_accuracy: 0.6449 - val_loss: 0.6059 - learning_rate: 8.3126e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6645 - loss: 0.5834\n",
            "Epoch 205: val_loss improved from 0.60581 to 0.60551, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - accuracy: 0.6639 - loss: 0.5842 - val_accuracy: 0.6411 - val_loss: 0.6055 - learning_rate: 8.3056e-04\n",
            "Epoch 206/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5855\n",
            "Epoch 206: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5855 - val_accuracy: 0.6280 - val_loss: 0.6124 - learning_rate: 8.2988e-04\n",
            "Epoch 207/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6495 - loss: 0.6014\n",
            "Epoch 207: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6502 - loss: 0.6010 - val_accuracy: 0.6561 - val_loss: 0.6128 - learning_rate: 8.2919e-04\n",
            "Epoch 208/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5847\n",
            "Epoch 208: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5847 - val_accuracy: 0.6187 - val_loss: 0.6110 - learning_rate: 8.2850e-04\n",
            "Epoch 209/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6716 - loss: 0.5823\n",
            "Epoch 209: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6713 - loss: 0.5828 - val_accuracy: 0.6299 - val_loss: 0.6079 - learning_rate: 8.2781e-04\n",
            "Epoch 210/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5782\n",
            "Epoch 210: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5782 - val_accuracy: 0.6336 - val_loss: 0.6092 - learning_rate: 8.2713e-04\n",
            "Epoch 211/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6721 - loss: 0.5914\n",
            "Epoch 211: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6718 - loss: 0.5916 - val_accuracy: 0.6037 - val_loss: 0.6223 - learning_rate: 8.2645e-04\n",
            "Epoch 212/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7422 - loss: 0.5390\n",
            "Epoch 212: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5390 - val_accuracy: 0.6187 - val_loss: 0.6390 - learning_rate: 8.2576e-04\n",
            "Epoch 213/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6406 - loss: 0.5991\n",
            "Epoch 213: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6417 - loss: 0.5987 - val_accuracy: 0.6411 - val_loss: 0.6123 - learning_rate: 8.2508e-04\n",
            "Epoch 214/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5711\n",
            "Epoch 214: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5711 - val_accuracy: 0.6598 - val_loss: 0.6075 - learning_rate: 8.2440e-04\n",
            "Epoch 215/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6730 - loss: 0.5826\n",
            "Epoch 215: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6719 - loss: 0.5836 - val_accuracy: 0.6206 - val_loss: 0.6155 - learning_rate: 8.2372e-04\n",
            "Epoch 216/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5640\n",
            "Epoch 216: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5640 - val_accuracy: 0.6411 - val_loss: 0.6105 - learning_rate: 8.2305e-04\n",
            "Epoch 217/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6641 - loss: 0.5933\n",
            "Epoch 217: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6642 - loss: 0.5934 - val_accuracy: 0.6112 - val_loss: 0.6180 - learning_rate: 8.2237e-04\n",
            "Epoch 218/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5889\n",
            "Epoch 218: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5889 - val_accuracy: 0.6336 - val_loss: 0.6168 - learning_rate: 8.2169e-04\n",
            "Epoch 219/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6635 - loss: 0.5925\n",
            "Epoch 219: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6636 - loss: 0.5923 - val_accuracy: 0.6467 - val_loss: 0.6056 - learning_rate: 8.2102e-04\n",
            "Epoch 220/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6192\n",
            "Epoch 220: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6192 - val_accuracy: 0.6243 - val_loss: 0.6192 - learning_rate: 8.2034e-04\n",
            "Epoch 221/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6679 - loss: 0.5945\n",
            "Epoch 221: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6676 - loss: 0.5941 - val_accuracy: 0.6430 - val_loss: 0.6204 - learning_rate: 8.1967e-04\n",
            "Epoch 222/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.5770\n",
            "Epoch 222: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5770 - val_accuracy: 0.6430 - val_loss: 0.6148 - learning_rate: 8.1900e-04\n",
            "Epoch 223/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6655 - loss: 0.5859\n",
            "Epoch 223: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6653 - loss: 0.5858 - val_accuracy: 0.6430 - val_loss: 0.6122 - learning_rate: 8.1833e-04\n",
            "Epoch 224/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6119\n",
            "Epoch 224: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6172 - loss: 0.6119 - val_accuracy: 0.6243 - val_loss: 0.6144 - learning_rate: 8.1766e-04\n",
            "Epoch 225/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6666 - loss: 0.5856\n",
            "Epoch 225: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6666 - loss: 0.5858 - val_accuracy: 0.6393 - val_loss: 0.6159 - learning_rate: 8.1699e-04\n",
            "Epoch 226/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7419 - loss: 0.5903\n",
            "Epoch 226: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7419 - loss: 0.5903 - val_accuracy: 0.6299 - val_loss: 0.6143 - learning_rate: 8.1633e-04\n",
            "Epoch 227/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6645 - loss: 0.5853\n",
            "Epoch 227: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6642 - loss: 0.5853 - val_accuracy: 0.6636 - val_loss: 0.6105 - learning_rate: 8.1566e-04\n",
            "Epoch 228/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6146\n",
            "Epoch 228: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6484 - loss: 0.6146 - val_accuracy: 0.6523 - val_loss: 0.6107 - learning_rate: 8.1500e-04\n",
            "Epoch 229/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6718 - loss: 0.5849\n",
            "Epoch 229: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6709 - loss: 0.5856 - val_accuracy: 0.6374 - val_loss: 0.6129 - learning_rate: 8.1433e-04\n",
            "Epoch 230/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6129 - loss: 0.6360\n",
            "Epoch 230: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6129 - loss: 0.6360 - val_accuracy: 0.6523 - val_loss: 0.6060 - learning_rate: 8.1367e-04\n",
            "Epoch 231/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6702 - loss: 0.5809\n",
            "Epoch 231: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6695 - loss: 0.5816 - val_accuracy: 0.6598 - val_loss: 0.6062 - learning_rate: 8.1301e-04\n",
            "Epoch 232/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5814\n",
            "Epoch 232: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5814 - val_accuracy: 0.6168 - val_loss: 0.6204 - learning_rate: 8.1235e-04\n",
            "Epoch 233/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6638 - loss: 0.5898\n",
            "Epoch 233: val_loss did not improve from 0.60551\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6639 - loss: 0.5898 - val_accuracy: 0.6467 - val_loss: 0.6086 - learning_rate: 8.1169e-04\n",
            "Epoch 234/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7527 - loss: 0.5155\n",
            "Epoch 234: val_loss improved from 0.60551 to 0.60470, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7527 - loss: 0.5155 - val_accuracy: 0.6654 - val_loss: 0.6047 - learning_rate: 8.1103e-04\n",
            "Epoch 235/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6633 - loss: 0.5903\n",
            "Epoch 235: val_loss did not improve from 0.60470\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6638 - loss: 0.5903 - val_accuracy: 0.6486 - val_loss: 0.6136 - learning_rate: 8.1037e-04\n",
            "Epoch 236/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.5844\n",
            "Epoch 236: val_loss did not improve from 0.60470\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.5844 - val_accuracy: 0.6411 - val_loss: 0.6110 - learning_rate: 8.0972e-04\n",
            "Epoch 237/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6695 - loss: 0.6044\n",
            "Epoch 237: val_loss did not improve from 0.60470\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6693 - loss: 0.6040 - val_accuracy: 0.6336 - val_loss: 0.6086 - learning_rate: 8.0906e-04\n",
            "Epoch 238/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5565\n",
            "Epoch 238: val_loss did not improve from 0.60470\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5565 - val_accuracy: 0.6449 - val_loss: 0.6057 - learning_rate: 8.0841e-04\n",
            "Epoch 239/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6808 - loss: 0.5783\n",
            "Epoch 239: val_loss did not improve from 0.60470\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6798 - loss: 0.5788 - val_accuracy: 0.6505 - val_loss: 0.6092 - learning_rate: 8.0775e-04\n",
            "Epoch 240/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5588\n",
            "Epoch 240: val_loss did not improve from 0.60470\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7188 - loss: 0.5588 - val_accuracy: 0.6486 - val_loss: 0.6095 - learning_rate: 8.0710e-04\n",
            "Epoch 241/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6777 - loss: 0.5831\n",
            "Epoch 241: val_loss improved from 0.60470 to 0.60296, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6767 - loss: 0.5835 - val_accuracy: 0.6748 - val_loss: 0.6030 - learning_rate: 8.0645e-04\n",
            "Epoch 242/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5772\n",
            "Epoch 242: val_loss did not improve from 0.60296\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5772 - val_accuracy: 0.6673 - val_loss: 0.6044 - learning_rate: 8.0580e-04\n",
            "Epoch 243/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6672 - loss: 0.5903\n",
            "Epoch 243: val_loss did not improve from 0.60296\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6665 - loss: 0.5903 - val_accuracy: 0.6430 - val_loss: 0.6120 - learning_rate: 8.0515e-04\n",
            "Epoch 244/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5859 - loss: 0.6237\n",
            "Epoch 244: val_loss did not improve from 0.60296\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5859 - loss: 0.6237 - val_accuracy: 0.6748 - val_loss: 0.6069 - learning_rate: 8.0451e-04\n",
            "Epoch 245/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6533 - loss: 0.6025\n",
            "Epoch 245: val_loss did not improve from 0.60296\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6536 - loss: 0.6018 - val_accuracy: 0.6206 - val_loss: 0.6385 - learning_rate: 8.0386e-04\n",
            "Epoch 246/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6050\n",
            "Epoch 246: val_loss did not improve from 0.60296\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5781 - loss: 0.6050 - val_accuracy: 0.6598 - val_loss: 0.6063 - learning_rate: 8.0321e-04\n",
            "Epoch 247/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6564 - loss: 0.5857\n",
            "Epoch 247: val_loss did not improve from 0.60296\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6571 - loss: 0.5855 - val_accuracy: 0.6150 - val_loss: 0.6238 - learning_rate: 8.0257e-04\n",
            "Epoch 248/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5567\n",
            "Epoch 248: val_loss improved from 0.60296 to 0.59936, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6875 - loss: 0.5567 - val_accuracy: 0.6542 - val_loss: 0.5994 - learning_rate: 8.0192e-04\n",
            "Epoch 249/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6701 - loss: 0.5877\n",
            "Epoch 249: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6702 - loss: 0.5875 - val_accuracy: 0.6710 - val_loss: 0.6062 - learning_rate: 8.0128e-04\n",
            "Epoch 250/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6002\n",
            "Epoch 250: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6719 - loss: 0.6002 - val_accuracy: 0.6393 - val_loss: 0.6077 - learning_rate: 8.0064e-04\n",
            "Epoch 251/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6715 - loss: 0.5992\n",
            "Epoch 251: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6712 - loss: 0.5990 - val_accuracy: 0.6729 - val_loss: 0.6089 - learning_rate: 8.0000e-04\n",
            "Epoch 252/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5805\n",
            "Epoch 252: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5805 - val_accuracy: 0.6636 - val_loss: 0.6035 - learning_rate: 7.9936e-04\n",
            "Epoch 253/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6645 - loss: 0.5790\n",
            "Epoch 253: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6643 - loss: 0.5795 - val_accuracy: 0.6617 - val_loss: 0.6019 - learning_rate: 7.9872e-04\n",
            "Epoch 254/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 0.5934\n",
            "Epoch 254: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5934 - val_accuracy: 0.6355 - val_loss: 0.6097 - learning_rate: 7.9808e-04\n",
            "Epoch 255/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6595 - loss: 0.6026\n",
            "Epoch 255: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6605 - loss: 0.6015 - val_accuracy: 0.6617 - val_loss: 0.6038 - learning_rate: 7.9745e-04\n",
            "Epoch 256/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5730\n",
            "Epoch 256: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5730 - val_accuracy: 0.6654 - val_loss: 0.6092 - learning_rate: 7.9681e-04\n",
            "Epoch 257/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6627 - loss: 0.5970\n",
            "Epoch 257: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6627 - loss: 0.5963 - val_accuracy: 0.6336 - val_loss: 0.6114 - learning_rate: 7.9618e-04\n",
            "Epoch 258/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.6009\n",
            "Epoch 258: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6009 - val_accuracy: 0.6355 - val_loss: 0.6153 - learning_rate: 7.9554e-04\n",
            "Epoch 259/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6626 - loss: 0.5983\n",
            "Epoch 259: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6631 - loss: 0.5979 - val_accuracy: 0.6523 - val_loss: 0.6071 - learning_rate: 7.9491e-04\n",
            "Epoch 260/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5365\n",
            "Epoch 260: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7344 - loss: 0.5365 - val_accuracy: 0.6505 - val_loss: 0.6096 - learning_rate: 7.9428e-04\n",
            "Epoch 261/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6604 - loss: 0.5827\n",
            "Epoch 261: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6598 - loss: 0.5828 - val_accuracy: 0.6561 - val_loss: 0.6119 - learning_rate: 7.9365e-04\n",
            "Epoch 262/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5864\n",
            "Epoch 262: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5864 - val_accuracy: 0.6505 - val_loss: 0.6033 - learning_rate: 7.9302e-04\n",
            "Epoch 263/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6794 - loss: 0.5820\n",
            "Epoch 263: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6793 - loss: 0.5821 - val_accuracy: 0.6243 - val_loss: 0.6244 - learning_rate: 7.9239e-04\n",
            "Epoch 264/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5831\n",
            "Epoch 264: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6953 - loss: 0.5831 - val_accuracy: 0.6505 - val_loss: 0.6107 - learning_rate: 7.9177e-04\n",
            "Epoch 265/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6763 - loss: 0.5764\n",
            "Epoch 265: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6762 - loss: 0.5765 - val_accuracy: 0.6299 - val_loss: 0.6176 - learning_rate: 7.9114e-04\n",
            "Epoch 266/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.6238\n",
            "Epoch 266: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.6238 - val_accuracy: 0.6150 - val_loss: 0.6169 - learning_rate: 7.9051e-04\n",
            "Epoch 267/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6519 - loss: 0.5874\n",
            "Epoch 267: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6521 - loss: 0.5874 - val_accuracy: 0.6467 - val_loss: 0.6120 - learning_rate: 7.8989e-04\n",
            "Epoch 268/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6432\n",
            "Epoch 268: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6432 - val_accuracy: 0.6056 - val_loss: 0.6153 - learning_rate: 7.8927e-04\n",
            "Epoch 269/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6539 - loss: 0.5898\n",
            "Epoch 269: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6541 - loss: 0.5898 - val_accuracy: 0.6636 - val_loss: 0.6078 - learning_rate: 7.8864e-04\n",
            "Epoch 270/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5560\n",
            "Epoch 270: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7266 - loss: 0.5560 - val_accuracy: 0.6673 - val_loss: 0.6054 - learning_rate: 7.8802e-04\n",
            "Epoch 271/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6455 - loss: 0.6024\n",
            "Epoch 271: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6468 - loss: 0.6012 - val_accuracy: 0.6355 - val_loss: 0.6098 - learning_rate: 7.8740e-04\n",
            "Epoch 272/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5728\n",
            "Epoch 272: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5728 - val_accuracy: 0.6243 - val_loss: 0.6267 - learning_rate: 7.8678e-04\n",
            "Epoch 273/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6539 - loss: 0.5807\n",
            "Epoch 273: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6544 - loss: 0.5810 - val_accuracy: 0.6617 - val_loss: 0.6052 - learning_rate: 7.8616e-04\n",
            "Epoch 274/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5633\n",
            "Epoch 274: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5633 - val_accuracy: 0.6393 - val_loss: 0.6105 - learning_rate: 7.8555e-04\n",
            "Epoch 275/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6565 - loss: 0.5853\n",
            "Epoch 275: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6571 - loss: 0.5852 - val_accuracy: 0.6710 - val_loss: 0.6037 - learning_rate: 7.8493e-04\n",
            "Epoch 276/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6774 - loss: 0.6577\n",
            "Epoch 276: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6774 - loss: 0.6577 - val_accuracy: 0.6673 - val_loss: 0.6032 - learning_rate: 7.8431e-04\n",
            "Epoch 277/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6744 - loss: 0.5787\n",
            "Epoch 277: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6738 - loss: 0.5791 - val_accuracy: 0.6598 - val_loss: 0.6110 - learning_rate: 7.8370e-04\n",
            "Epoch 278/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6039\n",
            "Epoch 278: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.6039 - val_accuracy: 0.6673 - val_loss: 0.6041 - learning_rate: 7.8309e-04\n",
            "Epoch 279/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6662 - loss: 0.5764\n",
            "Epoch 279: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6662 - loss: 0.5766 - val_accuracy: 0.6449 - val_loss: 0.6042 - learning_rate: 7.8247e-04\n",
            "Epoch 280/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5795\n",
            "Epoch 280: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5795 - val_accuracy: 0.6598 - val_loss: 0.6038 - learning_rate: 7.8186e-04\n",
            "Epoch 281/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6745 - loss: 0.5980\n",
            "Epoch 281: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6742 - loss: 0.5975 - val_accuracy: 0.6505 - val_loss: 0.6018 - learning_rate: 7.8125e-04\n",
            "Epoch 282/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5691\n",
            "Epoch 282: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5691 - val_accuracy: 0.6374 - val_loss: 0.6055 - learning_rate: 7.8064e-04\n",
            "Epoch 283/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6752 - loss: 0.5743\n",
            "Epoch 283: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6750 - loss: 0.5747 - val_accuracy: 0.6187 - val_loss: 0.6204 - learning_rate: 7.8003e-04\n",
            "Epoch 284/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5789\n",
            "Epoch 284: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5789 - val_accuracy: 0.6224 - val_loss: 0.6004 - learning_rate: 7.7942e-04\n",
            "Epoch 285/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6666 - loss: 0.5773\n",
            "Epoch 285: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6667 - loss: 0.5778 - val_accuracy: 0.6411 - val_loss: 0.6059 - learning_rate: 7.7882e-04\n",
            "Epoch 286/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7204 - loss: 0.5384\n",
            "Epoch 286: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7204 - loss: 0.5384 - val_accuracy: 0.6561 - val_loss: 0.5994 - learning_rate: 7.7821e-04\n",
            "Epoch 287/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6768 - loss: 0.5892\n",
            "Epoch 287: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6765 - loss: 0.5888 - val_accuracy: 0.6617 - val_loss: 0.6055 - learning_rate: 7.7760e-04\n",
            "Epoch 288/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6068\n",
            "Epoch 288: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.6068 - val_accuracy: 0.6673 - val_loss: 0.6081 - learning_rate: 7.7700e-04\n",
            "Epoch 289/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6662 - loss: 0.5853\n",
            "Epoch 289: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6656 - loss: 0.5855 - val_accuracy: 0.6280 - val_loss: 0.6105 - learning_rate: 7.7640e-04\n",
            "Epoch 290/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5921\n",
            "Epoch 290: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6484 - loss: 0.5921 - val_accuracy: 0.6262 - val_loss: 0.6029 - learning_rate: 7.7580e-04\n",
            "Epoch 291/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6806 - loss: 0.5749\n",
            "Epoch 291: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6801 - loss: 0.5749 - val_accuracy: 0.6467 - val_loss: 0.6042 - learning_rate: 7.7519e-04\n",
            "Epoch 292/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6122\n",
            "Epoch 292: val_loss did not improve from 0.59936\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6122 - val_accuracy: 0.6766 - val_loss: 0.6080 - learning_rate: 7.7459e-04\n",
            "Epoch 293/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6770 - loss: 0.5805\n",
            "Epoch 293: val_loss improved from 0.59936 to 0.59918, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6769 - loss: 0.5807 - val_accuracy: 0.6822 - val_loss: 0.5992 - learning_rate: 7.7399e-04\n",
            "Epoch 294/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7812 - loss: 0.5157\n",
            "Epoch 294: val_loss did not improve from 0.59918\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7812 - loss: 0.5157 - val_accuracy: 0.6561 - val_loss: 0.6035 - learning_rate: 7.7340e-04\n",
            "Epoch 295/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6593 - loss: 0.5827\n",
            "Epoch 295: val_loss did not improve from 0.59918\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6597 - loss: 0.5825 - val_accuracy: 0.6579 - val_loss: 0.6082 - learning_rate: 7.7280e-04\n",
            "Epoch 296/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5295\n",
            "Epoch 296: val_loss did not improve from 0.59918\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5295 - val_accuracy: 0.6243 - val_loss: 0.6314 - learning_rate: 7.7220e-04\n",
            "Epoch 297/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6652 - loss: 0.5916\n",
            "Epoch 297: val_loss improved from 0.59918 to 0.59803, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6652 - loss: 0.5911 - val_accuracy: 0.6729 - val_loss: 0.5980 - learning_rate: 7.7160e-04\n",
            "Epoch 298/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5747\n",
            "Epoch 298: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5747 - val_accuracy: 0.6523 - val_loss: 0.6076 - learning_rate: 7.7101e-04\n",
            "Epoch 299/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6660 - loss: 0.5847\n",
            "Epoch 299: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6659 - loss: 0.5842 - val_accuracy: 0.6692 - val_loss: 0.6038 - learning_rate: 7.7042e-04\n",
            "Epoch 300/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6129\n",
            "Epoch 300: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6129 - val_accuracy: 0.6748 - val_loss: 0.6091 - learning_rate: 7.6982e-04\n",
            "Epoch 301/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6653 - loss: 0.5807\n",
            "Epoch 301: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6652 - loss: 0.5811 - val_accuracy: 0.6224 - val_loss: 0.6070 - learning_rate: 7.6923e-04\n",
            "Epoch 302/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5718\n",
            "Epoch 302: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5718 - val_accuracy: 0.6617 - val_loss: 0.6037 - learning_rate: 7.6864e-04\n",
            "Epoch 303/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6672 - loss: 0.5675\n",
            "Epoch 303: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6665 - loss: 0.5685 - val_accuracy: 0.6598 - val_loss: 0.6059 - learning_rate: 7.6805e-04\n",
            "Epoch 304/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5809\n",
            "Epoch 304: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.5809 - val_accuracy: 0.6505 - val_loss: 0.6076 - learning_rate: 7.6746e-04\n",
            "Epoch 305/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6626 - loss: 0.5813\n",
            "Epoch 305: val_loss did not improve from 0.59803\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6624 - loss: 0.5813 - val_accuracy: 0.6636 - val_loss: 0.6020 - learning_rate: 7.6687e-04\n",
            "Epoch 306/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5266\n",
            "Epoch 306: val_loss improved from 0.59803 to 0.59687, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7188 - loss: 0.5266 - val_accuracy: 0.6804 - val_loss: 0.5969 - learning_rate: 7.6628e-04\n",
            "Epoch 307/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6851 - loss: 0.5696\n",
            "Epoch 307: val_loss did not improve from 0.59687\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6850 - loss: 0.5700 - val_accuracy: 0.6879 - val_loss: 0.5994 - learning_rate: 7.6570e-04\n",
            "Epoch 308/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.6075\n",
            "Epoch 308: val_loss did not improve from 0.59687\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6075 - val_accuracy: 0.6636 - val_loss: 0.6021 - learning_rate: 7.6511e-04\n",
            "Epoch 309/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6973 - loss: 0.5594\n",
            "Epoch 309: val_loss did not improve from 0.59687\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6966 - loss: 0.5600 - val_accuracy: 0.6411 - val_loss: 0.6035 - learning_rate: 7.6453e-04\n",
            "Epoch 310/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5938\n",
            "Epoch 310: val_loss did not improve from 0.59687\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5938 - val_accuracy: 0.6336 - val_loss: 0.6159 - learning_rate: 7.6394e-04\n",
            "Epoch 311/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6688 - loss: 0.5752\n",
            "Epoch 311: val_loss did not improve from 0.59687\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6687 - loss: 0.5756 - val_accuracy: 0.6841 - val_loss: 0.6202 - learning_rate: 7.6336e-04\n",
            "Epoch 312/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7204 - loss: 0.5383\n",
            "Epoch 312: val_loss did not improve from 0.59687\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7204 - loss: 0.5383 - val_accuracy: 0.6729 - val_loss: 0.6138 - learning_rate: 7.6278e-04\n",
            "Epoch 313/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6775 - loss: 0.5633\n",
            "Epoch 313: val_loss improved from 0.59687 to 0.59676, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 283ms/step - accuracy: 0.6776 - loss: 0.5636 - val_accuracy: 0.6692 - val_loss: 0.5968 - learning_rate: 7.6220e-04\n",
            "Epoch 314/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6172 - loss: 0.6692\n",
            "Epoch 314: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6172 - loss: 0.6692 - val_accuracy: 0.6598 - val_loss: 0.5986 - learning_rate: 7.6161e-04\n",
            "Epoch 315/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6788 - loss: 0.5739\n",
            "Epoch 315: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6788 - loss: 0.5740 - val_accuracy: 0.6748 - val_loss: 0.6017 - learning_rate: 7.6104e-04\n",
            "Epoch 316/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6484 - loss: 0.6922\n",
            "Epoch 316: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6922 - val_accuracy: 0.6355 - val_loss: 0.6035 - learning_rate: 7.6046e-04\n",
            "Epoch 317/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6621 - loss: 0.5699\n",
            "Epoch 317: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6622 - loss: 0.5703 - val_accuracy: 0.6505 - val_loss: 0.6088 - learning_rate: 7.5988e-04\n",
            "Epoch 318/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5812\n",
            "Epoch 318: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5812 - val_accuracy: 0.6785 - val_loss: 0.6028 - learning_rate: 7.5930e-04\n",
            "Epoch 319/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6653 - loss: 0.5868\n",
            "Epoch 319: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.6659 - loss: 0.5863 - val_accuracy: 0.6785 - val_loss: 0.6006 - learning_rate: 7.5873e-04\n",
            "Epoch 320/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6155\n",
            "Epoch 320: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.6155 - val_accuracy: 0.6262 - val_loss: 0.6140 - learning_rate: 7.5815e-04\n",
            "Epoch 321/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6528 - loss: 0.5903\n",
            "Epoch 321: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6531 - loss: 0.5905 - val_accuracy: 0.6692 - val_loss: 0.6000 - learning_rate: 7.5758e-04\n",
            "Epoch 322/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5180\n",
            "Epoch 322: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.5180 - val_accuracy: 0.6579 - val_loss: 0.6089 - learning_rate: 7.5700e-04\n",
            "Epoch 323/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6736 - loss: 0.5817\n",
            "Epoch 323: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6738 - loss: 0.5820 - val_accuracy: 0.6187 - val_loss: 0.6149 - learning_rate: 7.5643e-04\n",
            "Epoch 324/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5369\n",
            "Epoch 324: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5369 - val_accuracy: 0.6486 - val_loss: 0.6015 - learning_rate: 7.5586e-04\n",
            "Epoch 325/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6643 - loss: 0.5778\n",
            "Epoch 325: val_loss did not improve from 0.59676\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6642 - loss: 0.5780 - val_accuracy: 0.6561 - val_loss: 0.5998 - learning_rate: 7.5529e-04\n",
            "Epoch 326/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5468\n",
            "Epoch 326: val_loss improved from 0.59676 to 0.59345, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7188 - loss: 0.5468 - val_accuracy: 0.6617 - val_loss: 0.5935 - learning_rate: 7.5472e-04\n",
            "Epoch 327/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6745 - loss: 0.5717\n",
            "Epoch 327: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6744 - loss: 0.5723 - val_accuracy: 0.6374 - val_loss: 0.6032 - learning_rate: 7.5415e-04\n",
            "Epoch 328/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6016 - loss: 0.5999\n",
            "Epoch 328: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6016 - loss: 0.5999 - val_accuracy: 0.6804 - val_loss: 0.5945 - learning_rate: 7.5358e-04\n",
            "Epoch 329/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6850 - loss: 0.5752\n",
            "Epoch 329: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6847 - loss: 0.5756 - val_accuracy: 0.6523 - val_loss: 0.6037 - learning_rate: 7.5301e-04\n",
            "Epoch 330/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 0.5589\n",
            "Epoch 330: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5589 - val_accuracy: 0.6505 - val_loss: 0.5993 - learning_rate: 7.5245e-04\n",
            "Epoch 331/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6846 - loss: 0.5703\n",
            "Epoch 331: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6838 - loss: 0.5711 - val_accuracy: 0.6654 - val_loss: 0.6013 - learning_rate: 7.5188e-04\n",
            "Epoch 332/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5861\n",
            "Epoch 332: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6328 - loss: 0.5861 - val_accuracy: 0.6579 - val_loss: 0.6009 - learning_rate: 7.5131e-04\n",
            "Epoch 333/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6867 - loss: 0.5731\n",
            "Epoch 333: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6865 - loss: 0.5729 - val_accuracy: 0.6467 - val_loss: 0.6073 - learning_rate: 7.5075e-04\n",
            "Epoch 334/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5784\n",
            "Epoch 334: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5784 - val_accuracy: 0.6542 - val_loss: 0.6026 - learning_rate: 7.5019e-04\n",
            "Epoch 335/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6496 - loss: 0.5861\n",
            "Epoch 335: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6508 - loss: 0.5853 - val_accuracy: 0.6748 - val_loss: 0.6071 - learning_rate: 7.4963e-04\n",
            "Epoch 336/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6452 - loss: 0.6098\n",
            "Epoch 336: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6452 - loss: 0.6098 - val_accuracy: 0.6355 - val_loss: 0.6064 - learning_rate: 7.4906e-04\n",
            "Epoch 337/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6763 - loss: 0.5695\n",
            "Epoch 337: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6762 - loss: 0.5700 - val_accuracy: 0.6729 - val_loss: 0.5948 - learning_rate: 7.4850e-04\n",
            "Epoch 338/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5586\n",
            "Epoch 338: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5586 - val_accuracy: 0.6692 - val_loss: 0.6112 - learning_rate: 7.4794e-04\n",
            "Epoch 339/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6942 - loss: 0.5661\n",
            "Epoch 339: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6936 - loss: 0.5666 - val_accuracy: 0.6673 - val_loss: 0.6053 - learning_rate: 7.4738e-04\n",
            "Epoch 340/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5237\n",
            "Epoch 340: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5237 - val_accuracy: 0.6486 - val_loss: 0.6051 - learning_rate: 7.4683e-04\n",
            "Epoch 341/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6674 - loss: 0.5774\n",
            "Epoch 341: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6676 - loss: 0.5775 - val_accuracy: 0.6804 - val_loss: 0.5939 - learning_rate: 7.4627e-04\n",
            "Epoch 342/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5599\n",
            "Epoch 342: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5599 - val_accuracy: 0.6579 - val_loss: 0.5965 - learning_rate: 7.4571e-04\n",
            "Epoch 343/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6747 - loss: 0.5759\n",
            "Epoch 343: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6747 - loss: 0.5761 - val_accuracy: 0.6168 - val_loss: 0.6122 - learning_rate: 7.4516e-04\n",
            "Epoch 344/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5847\n",
            "Epoch 344: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5847 - val_accuracy: 0.6748 - val_loss: 0.5979 - learning_rate: 7.4460e-04\n",
            "Epoch 345/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6567 - loss: 0.5880\n",
            "Epoch 345: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6574 - loss: 0.5876 - val_accuracy: 0.6673 - val_loss: 0.6123 - learning_rate: 7.4405e-04\n",
            "Epoch 346/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5592\n",
            "Epoch 346: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7266 - loss: 0.5592 - val_accuracy: 0.6598 - val_loss: 0.6021 - learning_rate: 7.4349e-04\n",
            "Epoch 347/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6638 - loss: 0.5816\n",
            "Epoch 347: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6643 - loss: 0.5813 - val_accuracy: 0.6636 - val_loss: 0.5955 - learning_rate: 7.4294e-04\n",
            "Epoch 348/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7097 - loss: 0.5814\n",
            "Epoch 348: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7097 - loss: 0.5814 - val_accuracy: 0.6505 - val_loss: 0.6083 - learning_rate: 7.4239e-04\n",
            "Epoch 349/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6724 - loss: 0.5670\n",
            "Epoch 349: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6726 - loss: 0.5675 - val_accuracy: 0.6673 - val_loss: 0.6004 - learning_rate: 7.4184e-04\n",
            "Epoch 350/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5571\n",
            "Epoch 350: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5571 - val_accuracy: 0.6467 - val_loss: 0.6023 - learning_rate: 7.4129e-04\n",
            "Epoch 351/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6861 - loss: 0.5869\n",
            "Epoch 351: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6855 - loss: 0.5864 - val_accuracy: 0.6486 - val_loss: 0.6041 - learning_rate: 7.4074e-04\n",
            "Epoch 352/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5878\n",
            "Epoch 352: val_loss did not improve from 0.59345\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5878 - val_accuracy: 0.6692 - val_loss: 0.5973 - learning_rate: 7.4019e-04\n",
            "Epoch 353/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6902 - loss: 0.5662\n",
            "Epoch 353: val_loss improved from 0.59345 to 0.59205, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6890 - loss: 0.5672 - val_accuracy: 0.6785 - val_loss: 0.5920 - learning_rate: 7.3964e-04\n",
            "Epoch 354/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5826\n",
            "Epoch 354: val_loss did not improve from 0.59205\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7109 - loss: 0.5826 - val_accuracy: 0.6822 - val_loss: 0.5932 - learning_rate: 7.3910e-04\n",
            "Epoch 355/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6735 - loss: 0.5854\n",
            "Epoch 355: val_loss improved from 0.59205 to 0.59160, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 284ms/step - accuracy: 0.6738 - loss: 0.5846 - val_accuracy: 0.6860 - val_loss: 0.5916 - learning_rate: 7.3855e-04\n",
            "Epoch 356/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6186\n",
            "Epoch 356: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.6186 - val_accuracy: 0.6673 - val_loss: 0.6058 - learning_rate: 7.3801e-04\n",
            "Epoch 357/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6619 - loss: 0.5953\n",
            "Epoch 357: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6624 - loss: 0.5946 - val_accuracy: 0.6486 - val_loss: 0.5976 - learning_rate: 7.3746e-04\n",
            "Epoch 358/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5400\n",
            "Epoch 358: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5400 - val_accuracy: 0.6692 - val_loss: 0.6102 - learning_rate: 7.3692e-04\n",
            "Epoch 359/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6921 - loss: 0.5713\n",
            "Epoch 359: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 277ms/step - accuracy: 0.6914 - loss: 0.5715 - val_accuracy: 0.6579 - val_loss: 0.6075 - learning_rate: 7.3638e-04\n",
            "Epoch 360/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5781 - loss: 0.6324\n",
            "Epoch 360: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5781 - loss: 0.6324 - val_accuracy: 0.6879 - val_loss: 0.6045 - learning_rate: 7.3584e-04\n",
            "Epoch 361/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6816 - loss: 0.5633\n",
            "Epoch 361: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6811 - loss: 0.5638 - val_accuracy: 0.6467 - val_loss: 0.5962 - learning_rate: 7.3529e-04\n",
            "Epoch 362/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.6472\n",
            "Epoch 362: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.6472 - val_accuracy: 0.6692 - val_loss: 0.5934 - learning_rate: 7.3475e-04\n",
            "Epoch 363/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6904 - loss: 0.5737\n",
            "Epoch 363: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6905 - loss: 0.5734 - val_accuracy: 0.6673 - val_loss: 0.6105 - learning_rate: 7.3421e-04\n",
            "Epoch 364/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6094 - loss: 0.6324\n",
            "Epoch 364: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 0.6324 - val_accuracy: 0.6598 - val_loss: 0.6206 - learning_rate: 7.3368e-04\n",
            "Epoch 365/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6890 - loss: 0.5608\n",
            "Epoch 365: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6886 - loss: 0.5613 - val_accuracy: 0.6710 - val_loss: 0.6069 - learning_rate: 7.3314e-04\n",
            "Epoch 366/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.6309\n",
            "Epoch 366: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7031 - loss: 0.6309 - val_accuracy: 0.6430 - val_loss: 0.5966 - learning_rate: 7.3260e-04\n",
            "Epoch 367/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6723 - loss: 0.5659\n",
            "Epoch 367: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6723 - loss: 0.5669 - val_accuracy: 0.6654 - val_loss: 0.6007 - learning_rate: 7.3206e-04\n",
            "Epoch 368/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7422 - loss: 0.5376\n",
            "Epoch 368: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5376 - val_accuracy: 0.6654 - val_loss: 0.5975 - learning_rate: 7.3153e-04\n",
            "Epoch 369/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6905 - loss: 0.5452\n",
            "Epoch 369: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6895 - loss: 0.5465 - val_accuracy: 0.6729 - val_loss: 0.5936 - learning_rate: 7.3099e-04\n",
            "Epoch 370/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7188 - loss: 0.5549\n",
            "Epoch 370: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7188 - loss: 0.5549 - val_accuracy: 0.6766 - val_loss: 0.5970 - learning_rate: 7.3046e-04\n",
            "Epoch 371/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6354 - loss: 0.6040\n",
            "Epoch 371: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6368 - loss: 0.6030 - val_accuracy: 0.6598 - val_loss: 0.6012 - learning_rate: 7.2993e-04\n",
            "Epoch 372/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5601\n",
            "Epoch 372: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5601 - val_accuracy: 0.6710 - val_loss: 0.5976 - learning_rate: 7.2939e-04\n",
            "Epoch 373/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6779 - loss: 0.5790\n",
            "Epoch 373: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6777 - loss: 0.5789 - val_accuracy: 0.6467 - val_loss: 0.6074 - learning_rate: 7.2886e-04\n",
            "Epoch 374/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.5356\n",
            "Epoch 374: val_loss did not improve from 0.59160\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5356 - val_accuracy: 0.6561 - val_loss: 0.6023 - learning_rate: 7.2833e-04\n",
            "Epoch 375/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6644 - loss: 0.5816\n",
            "Epoch 375: val_loss improved from 0.59160 to 0.58693, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6646 - loss: 0.5815 - val_accuracy: 0.6748 - val_loss: 0.5869 - learning_rate: 7.2780e-04\n",
            "Epoch 376/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5839\n",
            "Epoch 376: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5839 - val_accuracy: 0.6449 - val_loss: 0.6019 - learning_rate: 7.2727e-04\n",
            "Epoch 377/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6657 - loss: 0.5754\n",
            "Epoch 377: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6663 - loss: 0.5753 - val_accuracy: 0.6411 - val_loss: 0.6072 - learning_rate: 7.2674e-04\n",
            "Epoch 378/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6953 - loss: 0.5342\n",
            "Epoch 378: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5342 - val_accuracy: 0.6748 - val_loss: 0.5966 - learning_rate: 7.2622e-04\n",
            "Epoch 379/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6870 - loss: 0.5610\n",
            "Epoch 379: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6862 - loss: 0.5618 - val_accuracy: 0.6393 - val_loss: 0.5993 - learning_rate: 7.2569e-04\n",
            "Epoch 380/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5657\n",
            "Epoch 380: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5657 - val_accuracy: 0.6449 - val_loss: 0.6042 - learning_rate: 7.2516e-04\n",
            "Epoch 381/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6624 - loss: 0.5828\n",
            "Epoch 381: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6618 - loss: 0.5829 - val_accuracy: 0.6729 - val_loss: 0.5972 - learning_rate: 7.2464e-04\n",
            "Epoch 382/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5744\n",
            "Epoch 382: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.5744 - val_accuracy: 0.6561 - val_loss: 0.5955 - learning_rate: 7.2411e-04\n",
            "Epoch 383/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6781 - loss: 0.5739\n",
            "Epoch 383: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6786 - loss: 0.5734 - val_accuracy: 0.6785 - val_loss: 0.5887 - learning_rate: 7.2359e-04\n",
            "Epoch 384/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6067\n",
            "Epoch 384: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6067 - val_accuracy: 0.6299 - val_loss: 0.6153 - learning_rate: 7.2307e-04\n",
            "Epoch 385/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6668 - loss: 0.5716\n",
            "Epoch 385: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.6676 - loss: 0.5717 - val_accuracy: 0.6804 - val_loss: 0.5890 - learning_rate: 7.2254e-04\n",
            "Epoch 386/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5419\n",
            "Epoch 386: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5419 - val_accuracy: 0.6766 - val_loss: 0.5980 - learning_rate: 7.2202e-04\n",
            "Epoch 387/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6620 - loss: 0.5846\n",
            "Epoch 387: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6627 - loss: 0.5846 - val_accuracy: 0.6673 - val_loss: 0.5968 - learning_rate: 7.2150e-04\n",
            "Epoch 388/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5376\n",
            "Epoch 388: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5376 - val_accuracy: 0.6785 - val_loss: 0.5974 - learning_rate: 7.2098e-04\n",
            "Epoch 389/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6654 - loss: 0.5744\n",
            "Epoch 389: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6658 - loss: 0.5746 - val_accuracy: 0.6692 - val_loss: 0.5943 - learning_rate: 7.2046e-04\n",
            "Epoch 390/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5803\n",
            "Epoch 390: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5803 - val_accuracy: 0.6505 - val_loss: 0.5926 - learning_rate: 7.1994e-04\n",
            "Epoch 391/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6587 - loss: 0.5866\n",
            "Epoch 391: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6599 - loss: 0.5859 - val_accuracy: 0.6822 - val_loss: 0.5997 - learning_rate: 7.1942e-04\n",
            "Epoch 392/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6719 - loss: 0.5725\n",
            "Epoch 392: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6719 - loss: 0.5725 - val_accuracy: 0.6841 - val_loss: 0.5954 - learning_rate: 7.1891e-04\n",
            "Epoch 393/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6905 - loss: 0.5561\n",
            "Epoch 393: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6897 - loss: 0.5567 - val_accuracy: 0.6206 - val_loss: 0.6241 - learning_rate: 7.1839e-04\n",
            "Epoch 394/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5469 - loss: 0.6805\n",
            "Epoch 394: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5469 - loss: 0.6805 - val_accuracy: 0.7009 - val_loss: 0.5932 - learning_rate: 7.1788e-04\n",
            "Epoch 395/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6868 - loss: 0.5591\n",
            "Epoch 395: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6859 - loss: 0.5599 - val_accuracy: 0.6897 - val_loss: 0.6000 - learning_rate: 7.1736e-04\n",
            "Epoch 396/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6132\n",
            "Epoch 396: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6132 - val_accuracy: 0.6766 - val_loss: 0.6026 - learning_rate: 7.1685e-04\n",
            "Epoch 397/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6967 - loss: 0.5665\n",
            "Epoch 397: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6965 - loss: 0.5666 - val_accuracy: 0.6766 - val_loss: 0.5907 - learning_rate: 7.1633e-04\n",
            "Epoch 398/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6613\n",
            "Epoch 398: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6328 - loss: 0.6613 - val_accuracy: 0.6598 - val_loss: 0.5968 - learning_rate: 7.1582e-04\n",
            "Epoch 399/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6942 - loss: 0.5618\n",
            "Epoch 399: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6938 - loss: 0.5621 - val_accuracy: 0.6579 - val_loss: 0.5917 - learning_rate: 7.1531e-04\n",
            "Epoch 400/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5855\n",
            "Epoch 400: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5855 - val_accuracy: 0.6467 - val_loss: 0.5951 - learning_rate: 7.1480e-04\n",
            "Epoch 401/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6659 - loss: 0.5735\n",
            "Epoch 401: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6660 - loss: 0.5736 - val_accuracy: 0.6598 - val_loss: 0.6012 - learning_rate: 7.1429e-04\n",
            "Epoch 402/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5602\n",
            "Epoch 402: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5602 - val_accuracy: 0.6766 - val_loss: 0.5946 - learning_rate: 7.1378e-04\n",
            "Epoch 403/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6678 - loss: 0.5715\n",
            "Epoch 403: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6679 - loss: 0.5715 - val_accuracy: 0.6505 - val_loss: 0.5977 - learning_rate: 7.1327e-04\n",
            "Epoch 404/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7422 - loss: 0.5477\n",
            "Epoch 404: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5477 - val_accuracy: 0.6336 - val_loss: 0.6003 - learning_rate: 7.1276e-04\n",
            "Epoch 405/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6843 - loss: 0.5652\n",
            "Epoch 405: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6841 - loss: 0.5653 - val_accuracy: 0.6860 - val_loss: 0.6005 - learning_rate: 7.1225e-04\n",
            "Epoch 406/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.4988\n",
            "Epoch 406: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.4988 - val_accuracy: 0.6804 - val_loss: 0.5970 - learning_rate: 7.1174e-04\n",
            "Epoch 407/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6978 - loss: 0.5652\n",
            "Epoch 407: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6967 - loss: 0.5656 - val_accuracy: 0.6617 - val_loss: 0.5999 - learning_rate: 7.1124e-04\n",
            "Epoch 408/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5549\n",
            "Epoch 408: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.5549 - val_accuracy: 0.6879 - val_loss: 0.5918 - learning_rate: 7.1073e-04\n",
            "Epoch 409/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6772 - loss: 0.5809\n",
            "Epoch 409: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6770 - loss: 0.5808 - val_accuracy: 0.6766 - val_loss: 0.5942 - learning_rate: 7.1023e-04\n",
            "Epoch 410/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5484\n",
            "Epoch 410: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5484 - val_accuracy: 0.6505 - val_loss: 0.6009 - learning_rate: 7.0972e-04\n",
            "Epoch 411/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6846 - loss: 0.5565\n",
            "Epoch 411: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6843 - loss: 0.5571 - val_accuracy: 0.6654 - val_loss: 0.5917 - learning_rate: 7.0922e-04\n",
            "Epoch 412/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6344 - loss: 0.6500\n",
            "Epoch 412: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6344 - loss: 0.6500 - val_accuracy: 0.6617 - val_loss: 0.5895 - learning_rate: 7.0872e-04\n",
            "Epoch 413/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6690 - loss: 0.5810\n",
            "Epoch 413: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6694 - loss: 0.5802 - val_accuracy: 0.6692 - val_loss: 0.5924 - learning_rate: 7.0822e-04\n",
            "Epoch 414/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5466\n",
            "Epoch 414: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7188 - loss: 0.5466 - val_accuracy: 0.6449 - val_loss: 0.6095 - learning_rate: 7.0771e-04\n",
            "Epoch 415/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6796 - loss: 0.5854\n",
            "Epoch 415: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6800 - loss: 0.5848 - val_accuracy: 0.6841 - val_loss: 0.5896 - learning_rate: 7.0721e-04\n",
            "Epoch 416/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.5052\n",
            "Epoch 416: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7344 - loss: 0.5052 - val_accuracy: 0.6598 - val_loss: 0.6038 - learning_rate: 7.0671e-04\n",
            "Epoch 417/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6663 - loss: 0.5798\n",
            "Epoch 417: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6671 - loss: 0.5796 - val_accuracy: 0.6766 - val_loss: 0.5930 - learning_rate: 7.0621e-04\n",
            "Epoch 418/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7656 - loss: 0.5227\n",
            "Epoch 418: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7656 - loss: 0.5227 - val_accuracy: 0.6598 - val_loss: 0.6035 - learning_rate: 7.0572e-04\n",
            "Epoch 419/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6801 - loss: 0.5663\n",
            "Epoch 419: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6801 - loss: 0.5667 - val_accuracy: 0.6710 - val_loss: 0.5963 - learning_rate: 7.0522e-04\n",
            "Epoch 420/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5821\n",
            "Epoch 420: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5821 - val_accuracy: 0.6617 - val_loss: 0.5930 - learning_rate: 7.0472e-04\n",
            "Epoch 421/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6910 - loss: 0.5571\n",
            "Epoch 421: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6909 - loss: 0.5574 - val_accuracy: 0.6430 - val_loss: 0.6129 - learning_rate: 7.0423e-04\n",
            "Epoch 422/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.6243\n",
            "Epoch 422: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.6243 - val_accuracy: 0.6953 - val_loss: 0.5965 - learning_rate: 7.0373e-04\n",
            "Epoch 423/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7067 - loss: 0.5526\n",
            "Epoch 423: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.7055 - loss: 0.5536 - val_accuracy: 0.6692 - val_loss: 0.6029 - learning_rate: 7.0323e-04\n",
            "Epoch 424/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5671\n",
            "Epoch 424: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6953 - loss: 0.5671 - val_accuracy: 0.6916 - val_loss: 0.6014 - learning_rate: 7.0274e-04\n",
            "Epoch 425/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6972 - loss: 0.5698\n",
            "Epoch 425: val_loss did not improve from 0.58693\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6970 - loss: 0.5695 - val_accuracy: 0.6280 - val_loss: 0.6387 - learning_rate: 7.0225e-04\n",
            "Epoch 426/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.6405\n",
            "Epoch 426: val_loss improved from 0.58693 to 0.58598, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6484 - loss: 0.6405 - val_accuracy: 0.6748 - val_loss: 0.5860 - learning_rate: 7.0175e-04\n",
            "Epoch 427/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.7065 - loss: 0.5452\n",
            "Epoch 427: val_loss did not improve from 0.58598\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.7058 - loss: 0.5459 - val_accuracy: 0.6561 - val_loss: 0.5992 - learning_rate: 7.0126e-04\n",
            "Epoch 428/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6406 - loss: 0.6124\n",
            "Epoch 428: val_loss did not improve from 0.58598\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.6124 - val_accuracy: 0.6617 - val_loss: 0.5954 - learning_rate: 7.0077e-04\n",
            "Epoch 429/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6872 - loss: 0.5671\n",
            "Epoch 429: val_loss did not improve from 0.58598\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.6865 - loss: 0.5675 - val_accuracy: 0.6897 - val_loss: 0.5955 - learning_rate: 7.0028e-04\n",
            "Epoch 430/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 0.5847\n",
            "Epoch 430: val_loss did not improve from 0.58598\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6484 - loss: 0.5847 - val_accuracy: 0.6617 - val_loss: 0.5988 - learning_rate: 6.9979e-04\n",
            "Epoch 431/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6826 - loss: 0.5722\n",
            "Epoch 431: val_loss improved from 0.58598 to 0.58565, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6827 - loss: 0.5720 - val_accuracy: 0.6692 - val_loss: 0.5856 - learning_rate: 6.9930e-04\n",
            "Epoch 432/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5370\n",
            "Epoch 432: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5370 - val_accuracy: 0.6636 - val_loss: 0.5964 - learning_rate: 6.9881e-04\n",
            "Epoch 433/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6866 - loss: 0.5579\n",
            "Epoch 433: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6860 - loss: 0.5580 - val_accuracy: 0.6617 - val_loss: 0.6023 - learning_rate: 6.9832e-04\n",
            "Epoch 434/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6950\n",
            "Epoch 434: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.6950 - val_accuracy: 0.6804 - val_loss: 0.5980 - learning_rate: 6.9784e-04\n",
            "Epoch 435/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6552 - loss: 0.5826\n",
            "Epoch 435: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6558 - loss: 0.5822 - val_accuracy: 0.6673 - val_loss: 0.5945 - learning_rate: 6.9735e-04\n",
            "Epoch 436/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5263\n",
            "Epoch 436: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7266 - loss: 0.5263 - val_accuracy: 0.6579 - val_loss: 0.6097 - learning_rate: 6.9686e-04\n",
            "Epoch 437/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6782 - loss: 0.5751\n",
            "Epoch 437: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6784 - loss: 0.5748 - val_accuracy: 0.6523 - val_loss: 0.6071 - learning_rate: 6.9638e-04\n",
            "Epoch 438/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5357\n",
            "Epoch 438: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5357 - val_accuracy: 0.6710 - val_loss: 0.6096 - learning_rate: 6.9589e-04\n",
            "Epoch 439/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6600 - loss: 0.5803\n",
            "Epoch 439: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6608 - loss: 0.5798 - val_accuracy: 0.7028 - val_loss: 0.5858 - learning_rate: 6.9541e-04\n",
            "Epoch 440/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7422 - loss: 0.5077\n",
            "Epoch 440: val_loss did not improve from 0.58565\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7422 - loss: 0.5077 - val_accuracy: 0.6673 - val_loss: 0.6041 - learning_rate: 6.9493e-04\n",
            "Epoch 441/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6901 - loss: 0.5580\n",
            "Epoch 441: val_loss improved from 0.58565 to 0.58214, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.6893 - loss: 0.5589 - val_accuracy: 0.6822 - val_loss: 0.5821 - learning_rate: 6.9444e-04\n",
            "Epoch 442/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 0.5403\n",
            "Epoch 442: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.5403 - val_accuracy: 0.6785 - val_loss: 0.5951 - learning_rate: 6.9396e-04\n",
            "Epoch 443/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7016 - loss: 0.5560\n",
            "Epoch 443: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.7016 - loss: 0.5561 - val_accuracy: 0.6841 - val_loss: 0.5891 - learning_rate: 6.9348e-04\n",
            "Epoch 444/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6328 - loss: 0.5743\n",
            "Epoch 444: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6328 - loss: 0.5743 - val_accuracy: 0.6953 - val_loss: 0.5878 - learning_rate: 6.9300e-04\n",
            "Epoch 445/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6978 - loss: 0.5546\n",
            "Epoch 445: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6975 - loss: 0.5555 - val_accuracy: 0.6748 - val_loss: 0.5949 - learning_rate: 6.9252e-04\n",
            "Epoch 446/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5472\n",
            "Epoch 446: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7109 - loss: 0.5472 - val_accuracy: 0.6710 - val_loss: 0.5907 - learning_rate: 6.9204e-04\n",
            "Epoch 447/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6895 - loss: 0.5707\n",
            "Epoch 447: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6895 - loss: 0.5707 - val_accuracy: 0.6785 - val_loss: 0.5960 - learning_rate: 6.9156e-04\n",
            "Epoch 448/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.5854\n",
            "Epoch 448: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6719 - loss: 0.5854 - val_accuracy: 0.6748 - val_loss: 0.5875 - learning_rate: 6.9109e-04\n",
            "Epoch 449/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6828 - loss: 0.5764\n",
            "Epoch 449: val_loss did not improve from 0.58214\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6825 - loss: 0.5763 - val_accuracy: 0.6692 - val_loss: 0.6043 - learning_rate: 6.9061e-04\n",
            "Epoch 450/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7031 - loss: 0.5300\n",
            "Epoch 450: val_loss improved from 0.58214 to 0.58065, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7031 - loss: 0.5300 - val_accuracy: 0.6972 - val_loss: 0.5807 - learning_rate: 6.9013e-04\n",
            "Epoch 451/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6986 - loss: 0.5571\n",
            "Epoch 451: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6979 - loss: 0.5575 - val_accuracy: 0.6766 - val_loss: 0.6028 - learning_rate: 6.8966e-04\n",
            "Epoch 452/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5524\n",
            "Epoch 452: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.5524 - val_accuracy: 0.6841 - val_loss: 0.5887 - learning_rate: 6.8918e-04\n",
            "Epoch 453/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6854 - loss: 0.5617\n",
            "Epoch 453: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6856 - loss: 0.5616 - val_accuracy: 0.6579 - val_loss: 0.5883 - learning_rate: 6.8871e-04\n",
            "Epoch 454/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5869\n",
            "Epoch 454: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6641 - loss: 0.5869 - val_accuracy: 0.6673 - val_loss: 0.5938 - learning_rate: 6.8823e-04\n",
            "Epoch 455/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6605 - loss: 0.5713\n",
            "Epoch 455: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.6617 - loss: 0.5708 - val_accuracy: 0.6879 - val_loss: 0.5899 - learning_rate: 6.8776e-04\n",
            "Epoch 456/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5637\n",
            "Epoch 456: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5637 - val_accuracy: 0.6523 - val_loss: 0.6012 - learning_rate: 6.8729e-04\n",
            "Epoch 457/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6877 - loss: 0.5641\n",
            "Epoch 457: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6876 - loss: 0.5644 - val_accuracy: 0.6804 - val_loss: 0.5930 - learning_rate: 6.8681e-04\n",
            "Epoch 458/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.6120\n",
            "Epoch 458: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6406 - loss: 0.6120 - val_accuracy: 0.6710 - val_loss: 0.6055 - learning_rate: 6.8634e-04\n",
            "Epoch 459/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6831 - loss: 0.5588\n",
            "Epoch 459: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6832 - loss: 0.5591 - val_accuracy: 0.6617 - val_loss: 0.5884 - learning_rate: 6.8587e-04\n",
            "Epoch 460/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.5922\n",
            "Epoch 460: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5938 - loss: 0.5922 - val_accuracy: 0.6879 - val_loss: 0.5951 - learning_rate: 6.8540e-04\n",
            "Epoch 461/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7022 - loss: 0.5489\n",
            "Epoch 461: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.7017 - loss: 0.5494 - val_accuracy: 0.6673 - val_loss: 0.5953 - learning_rate: 6.8493e-04\n",
            "Epoch 462/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.5753\n",
            "Epoch 462: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.5753 - val_accuracy: 0.6542 - val_loss: 0.6013 - learning_rate: 6.8446e-04\n",
            "Epoch 463/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6888 - loss: 0.5614\n",
            "Epoch 463: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 274ms/step - accuracy: 0.6879 - loss: 0.5618 - val_accuracy: 0.6953 - val_loss: 0.5983 - learning_rate: 6.8399e-04\n",
            "Epoch 464/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6406 - loss: 0.5995\n",
            "Epoch 464: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.5995 - val_accuracy: 0.6523 - val_loss: 0.5952 - learning_rate: 6.8353e-04\n",
            "Epoch 465/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6722 - loss: 0.5599\n",
            "Epoch 465: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.6733 - loss: 0.5605 - val_accuracy: 0.6692 - val_loss: 0.6179 - learning_rate: 6.8306e-04\n",
            "Epoch 466/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7742 - loss: 0.5508\n",
            "Epoch 466: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7742 - loss: 0.5508 - val_accuracy: 0.7121 - val_loss: 0.5830 - learning_rate: 6.8259e-04\n",
            "Epoch 467/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6877 - loss: 0.5682\n",
            "Epoch 467: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6875 - loss: 0.5679 - val_accuracy: 0.6972 - val_loss: 0.5853 - learning_rate: 6.8213e-04\n",
            "Epoch 468/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7109 - loss: 0.5935\n",
            "Epoch 468: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.5935 - val_accuracy: 0.6935 - val_loss: 0.5938 - learning_rate: 6.8166e-04\n",
            "Epoch 469/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.6743 - loss: 0.5612\n",
            "Epoch 469: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6744 - loss: 0.5614 - val_accuracy: 0.7084 - val_loss: 0.5889 - learning_rate: 6.8120e-04\n",
            "Epoch 470/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7344 - loss: 0.5578\n",
            "Epoch 470: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7344 - loss: 0.5578 - val_accuracy: 0.6692 - val_loss: 0.5934 - learning_rate: 6.8074e-04\n",
            "Epoch 471/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6964 - loss: 0.5558\n",
            "Epoch 471: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6955 - loss: 0.5565 - val_accuracy: 0.6710 - val_loss: 0.5932 - learning_rate: 6.8027e-04\n",
            "Epoch 472/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5448\n",
            "Epoch 472: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6953 - loss: 0.5448 - val_accuracy: 0.6710 - val_loss: 0.5970 - learning_rate: 6.7981e-04\n",
            "Epoch 473/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6913 - loss: 0.5574\n",
            "Epoch 473: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6919 - loss: 0.5572 - val_accuracy: 0.6916 - val_loss: 0.5881 - learning_rate: 6.7935e-04\n",
            "Epoch 474/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.5679\n",
            "Epoch 474: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5679 - val_accuracy: 0.6841 - val_loss: 0.6016 - learning_rate: 6.7889e-04\n",
            "Epoch 475/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6848 - loss: 0.5569\n",
            "Epoch 475: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6850 - loss: 0.5566 - val_accuracy: 0.6654 - val_loss: 0.6073 - learning_rate: 6.7843e-04\n",
            "Epoch 476/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.6804\n",
            "Epoch 476: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.6804 - val_accuracy: 0.7065 - val_loss: 0.5953 - learning_rate: 6.7797e-04\n",
            "Epoch 477/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6812 - loss: 0.5647\n",
            "Epoch 477: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6808 - loss: 0.5652 - val_accuracy: 0.7084 - val_loss: 0.5932 - learning_rate: 6.7751e-04\n",
            "Epoch 478/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7266 - loss: 0.5512\n",
            "Epoch 478: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7266 - loss: 0.5512 - val_accuracy: 0.6916 - val_loss: 0.5940 - learning_rate: 6.7705e-04\n",
            "Epoch 479/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6808 - loss: 0.5764\n",
            "Epoch 479: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6808 - loss: 0.5757 - val_accuracy: 0.6617 - val_loss: 0.5980 - learning_rate: 6.7659e-04\n",
            "Epoch 480/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 0.5514\n",
            "Epoch 480: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5514 - val_accuracy: 0.7047 - val_loss: 0.5925 - learning_rate: 6.7613e-04\n",
            "Epoch 481/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6821 - loss: 0.5719\n",
            "Epoch 481: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6824 - loss: 0.5710 - val_accuracy: 0.6804 - val_loss: 0.5907 - learning_rate: 6.7568e-04\n",
            "Epoch 482/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6562 - loss: 0.5392\n",
            "Epoch 482: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.5392 - val_accuracy: 0.6748 - val_loss: 0.5894 - learning_rate: 6.7522e-04\n",
            "Epoch 483/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.6842 - loss: 0.5575\n",
            "Epoch 483: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.6850 - loss: 0.5576 - val_accuracy: 0.6748 - val_loss: 0.5898 - learning_rate: 6.7476e-04\n",
            "Epoch 484/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5551\n",
            "Epoch 484: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5551 - val_accuracy: 0.7065 - val_loss: 0.5905 - learning_rate: 6.7431e-04\n",
            "Epoch 485/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7134 - loss: 0.5444\n",
            "Epoch 485: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.7125 - loss: 0.5448 - val_accuracy: 0.6897 - val_loss: 0.5990 - learning_rate: 6.7385e-04\n",
            "Epoch 486/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6953 - loss: 0.5808\n",
            "Epoch 486: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6953 - loss: 0.5808 - val_accuracy: 0.6841 - val_loss: 0.5860 - learning_rate: 6.7340e-04\n",
            "Epoch 487/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6831 - loss: 0.5651\n",
            "Epoch 487: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6838 - loss: 0.5649 - val_accuracy: 0.7028 - val_loss: 0.5823 - learning_rate: 6.7295e-04\n",
            "Epoch 488/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5723\n",
            "Epoch 488: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.5723 - val_accuracy: 0.6542 - val_loss: 0.6057 - learning_rate: 6.7249e-04\n",
            "Epoch 489/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.6705 - loss: 0.5761\n",
            "Epoch 489: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6710 - loss: 0.5754 - val_accuracy: 0.6579 - val_loss: 0.6060 - learning_rate: 6.7204e-04\n",
            "Epoch 490/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5327\n",
            "Epoch 490: val_loss did not improve from 0.58065\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6641 - loss: 0.5327 - val_accuracy: 0.6748 - val_loss: 0.5915 - learning_rate: 6.7159e-04\n",
            "Epoch 491/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6665 - loss: 0.5872\n",
            "Epoch 491: val_loss improved from 0.58065 to 0.57359, saving model to model_3_benmal_best.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.6669 - loss: 0.5866 - val_accuracy: 0.6804 - val_loss: 0.5736 - learning_rate: 6.7114e-04\n",
            "Epoch 492/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6641 - loss: 0.5745\n",
            "Epoch 492: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5745 - val_accuracy: 0.7047 - val_loss: 0.5793 - learning_rate: 6.7069e-04\n",
            "Epoch 493/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.6870 - loss: 0.5659\n",
            "Epoch 493: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 273ms/step - accuracy: 0.6870 - loss: 0.5653 - val_accuracy: 0.6505 - val_loss: 0.6144 - learning_rate: 6.7024e-04\n",
            "Epoch 494/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.6151\n",
            "Epoch 494: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6797 - loss: 0.6151 - val_accuracy: 0.6860 - val_loss: 0.5970 - learning_rate: 6.6979e-04\n",
            "Epoch 495/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.7055 - loss: 0.5578\n",
            "Epoch 495: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 272ms/step - accuracy: 0.7051 - loss: 0.5579 - val_accuracy: 0.6972 - val_loss: 0.5889 - learning_rate: 6.6934e-04\n",
            "Epoch 496/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6641 - loss: 0.5814\n",
            "Epoch 496: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6641 - loss: 0.5814 - val_accuracy: 0.6804 - val_loss: 0.5946 - learning_rate: 6.6890e-04\n",
            "Epoch 497/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6851 - loss: 0.5632\n",
            "Epoch 497: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.6852 - loss: 0.5631 - val_accuracy: 0.6879 - val_loss: 0.5899 - learning_rate: 6.6845e-04\n",
            "Epoch 498/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.4812\n",
            "Epoch 498: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.4812 - val_accuracy: 0.6505 - val_loss: 0.6248 - learning_rate: 6.6800e-04\n",
            "Epoch 499/500\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.6832 - loss: 0.5665\n",
            "Epoch 499: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 271ms/step - accuracy: 0.6838 - loss: 0.5661 - val_accuracy: 0.6748 - val_loss: 0.5859 - learning_rate: 6.6756e-04\n",
            "Epoch 500/500\n",
            "\u001b[1m 1/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6797 - loss: 0.5481\n",
            "Epoch 500: val_loss did not improve from 0.57359\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.5481 - val_accuracy: 0.6636 - val_loss: 0.6032 - learning_rate: 6.6711e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# History of accuracy and loss\n",
        "tra_loss_3 = history_3.history['loss']\n",
        "tra_acc_3 = history_3.history['accuracy']\n",
        "val_loss_3 = history_3.history['val_loss']\n",
        "val_acc_3 = history_3.history['val_accuracy']\n",
        "\n",
        "# Total number of epochs training\n",
        "epochs_3 = range(1, len(tra_acc_3) + 1)\n",
        "end_epoch_3 = len(tra_acc_3)\n",
        "\n",
        "# Epoch when reached the validation loss minimum\n",
        "opt_epoch_3 = val_loss_3.index(min(val_loss_3)) + 1\n",
        "\n",
        "# Loss and accuracy on the validation set\n",
        "end_val_loss_3 = val_loss_3[-1]\n",
        "end_val_acc_3 = val_acc_3[-1]\n",
        "opt_val_loss_3 = val_loss_3[opt_epoch_3 - 1]\n",
        "opt_val_acc_3 = val_acc_3[opt_epoch_3 - 1]\n",
        "\n",
        "# Load the best model\n",
        "opt_model_3 = models.load_model('model_3_benmal_best.keras')\n",
        "\n",
        "# Loss and accuracy on the test set\n",
        "test_loss_3, test_acc_3 = model_3.evaluate(test_images, test_labels, verbose=False)\n",
        "opt_test_loss_3, opt_test_acc_3 = opt_model_3.evaluate(test_images, test_labels, verbose=False)\n",
        "\n",
        "# Get predictions (Only pass test_images, not test_labels)\n",
        "opt_pred_3 = opt_model_3.predict(test_images)\n",
        "pred_classes_3 = np.rint(opt_pred_3)  # Round predictions to get binary labels (0 or 1)\n",
        "\n",
        "# Print results\n",
        "print(\"Model 3\\n\")\n",
        "print(\"Epoch [end]: %d\" % end_epoch_3)\n",
        "print(\"Epoch [opt]: %d\" % opt_epoch_3)\n",
        "print(\"Valid accuracy [end]: %.4f\" % end_val_acc_3)\n",
        "print(\"Valid accuracy [opt]: %.4f\" % opt_val_acc_3)\n",
        "print(\"Test accuracy [end]:  %.4f\" % test_acc_3)\n",
        "print(\"Test accuracy [opt]:  %.4f\" % opt_test_acc_3)\n",
        "print(\"Valid loss [end]: %.4f\" % end_val_loss_3)\n",
        "print(\"Valid loss [opt]: %.4f\" % opt_val_loss_3)\n",
        "print(\"Test loss [end]:  %.4f\" % test_loss_3)\n",
        "print(\"Test loss [opt]:  %.4f\" % opt_test_loss_3)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(test_labels, pred_classes_3, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MPSDOiGrQvF",
        "outputId": "55b52eae-d47c-4ece-bb02-83f28a0ac6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
            "Model 3\n",
            "\n",
            "Epoch [end]: 500\n",
            "Epoch [opt]: 491\n",
            "Valid accuracy [end]: 0.6636\n",
            "Valid accuracy [opt]: 0.6804\n",
            "Test accuracy [end]:  0.6935\n",
            "Test accuracy [opt]:  0.6786\n",
            "Valid loss [end]: 0.6032\n",
            "Valid loss [opt]: 0.5736\n",
            "Test loss [end]:  0.5779\n",
            "Test loss [opt]:  0.6037\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7424    0.7763    0.7589       219\n",
            "           1     0.5421    0.4957    0.5179       117\n",
            "\n",
            "    accuracy                         0.6786       336\n",
            "   macro avg     0.6422    0.6360    0.6384       336\n",
            "weighted avg     0.6726    0.6786    0.6750       336\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model accuracy plot\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 3 accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.plot(epochs_3, tra_acc_3, 'r', label='Training set')\n",
        "plt.plot(epochs_3, val_acc_3, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_3, val_acc_3[opt_epoch_3-1], 'go',  markersize=8, label='Optimal Epoch')  # Highlight optimal epoch\n",
        "plt.vlines(opt_epoch_3, min(val_acc_3), opt_val_acc_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_acc_3, 1, opt_epoch_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Model loss plot\n",
        "plt.figure(figsize=(7, 7), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.title('Model 3 loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.48, 0.9)  # Adjust the y-axis limits for clarity\n",
        "plt.plot(epochs_3, tra_loss_3, 'r', label='Training set')\n",
        "plt.plot(epochs_3, val_loss_3, 'g', label='Validation set')\n",
        "plt.plot(opt_epoch_3, val_loss_3[opt_epoch_3-1], 'go', markersize=8, label='Optimal Epoch')  # Highlight optimal epoch\n",
        "plt.vlines(opt_epoch_3, min(val_loss_3), opt_val_loss_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.hlines(opt_val_loss_3, 1, opt_epoch_3, linestyle=\"dashed\", color='g', linewidth=1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YafolqjwrQta",
        "outputId": "9e22026f-9e00-4fc7-f0c9-aba928ae5642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 560x560 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}